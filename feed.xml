<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.7.4">Jekyll</generator><link href="/feed.xml" rel="self" type="application/atom+xml" /><link href="/" rel="alternate" type="text/html" /><updated>2019-03-30T17:58:00-06:00</updated><id>/feed.xml</id><entry><title type="html">Initial Reconaissance for Bug-Bounty</title><link href="/posts/2019-3-30-hackerrecon" rel="alternate" type="text/html" title="Initial Reconaissance for Bug-Bounty" /><published>2019-03-30T00:00:00-06:00</published><updated>2019-03-30T00:00:00-06:00</updated><id>/posts/hackerrecon</id><content type="html" xml:base="/posts/2019-3-30-hackerrecon">&lt;h2&gt;Domain-Name Collection&lt;/h2&gt;
&lt;h5&gt;March 30, 2019&lt;/h5&gt;
&lt;p class=&quot;lead&quot;&gt;Reading cyber-security articles, and specifically the investigative aspects of vulnerability testing, one begins to get a sense for the steps that would be needed to perform this task. When a company puts their primary website (and all subdomains) into scope for a &lt;u&gt;bug-bounty&lt;/u&gt;, the logical first question is just exactly how would you enumerate all the company properties under that primary website? This seems so obvious, but it is a crucial first step, and for a long time security analysts were using very crude, brute-force types of tools that were running dictionary-type scans using large lists of words.&lt;/p&gt;

&lt;p&gt;It's only been the last 2-3 years (to my knowledge) that tools began to appear which used alternate approaches, such as historical DNS lookups, domain-names on security certificates, other archived data sources, as well as actually spidering a site to collect domain-names from URLs. Some of the latest tools are using dozens of external sources to gather a comprehensive list. While this is probably the most thorough approach, it often leads to &lt;u&gt;massive lists of unused domain-names&lt;/u&gt;, some of which date back decades.&lt;/p&gt;

&lt;p&gt;In all honesty I have not tried any of the older dictionary-scanning tools, with recognizable names such as &lt;b&gt;SubBrute&lt;/b&gt; and &lt;b&gt;Sublist3r&lt;/b&gt;. About a year ago I read many people talking about a tool called &lt;b&gt;Aquatone&lt;/b&gt;. I tried the tool, and indeed it did an admirable job of producing a large list of domain-names. Shortly after I tried it, the author announced &lt;a href=&quot;https://twitter.com/michenriksen/status/1010859541960056832&quot; target=&quot;_blank&quot;&gt;he may discontinue development of this functionality&lt;/a&gt;, and he recommended another tool called &lt;b&gt;Amass&lt;/b&gt; which he said did an even better job at this particular task. The OWASP &lt;b&gt;Amass&lt;/b&gt; project's stated goal is to fill in gaps and data-sources that other tools had missed. Recently I was testing several enumeration tools, and after seeing the list produced by Amass I basically stopped looking at the other tools.&lt;/p&gt;

&lt;h3&gt;OWASP Amass&lt;/h3&gt;
&lt;p&gt;I think people were turned off initially by &lt;b&gt;Amass&lt;/b&gt; because it uses the Go interpreter, a relative new-comer in the Linux world, and many people get tired of learning yet another language and system which works essentially the same as existing ones. Go is new for sure, but after installing it I found it really is not difficult to use. Actually &lt;b&gt;Amass&lt;/b&gt; offers several options, including Snap, Docker images, and pre-compiled binaries. Since I tend to be a purist I went with the compile-from-source option, which involved installing the &lt;a href=&quot;https://golang.org/doc/install&quot; target=&quot;_blank&quot;&gt;Go library&lt;/a&gt; first, and then installing &lt;b&gt;Amass&lt;/b&gt;. The instructions are on &lt;a href=&quot;https://github.com/OWASP/Amass&quot; target=&quot;_blank&quot;&gt;the Amass github repo&lt;/a&gt;. The most important part seemed to be getting the path set correctly. I added the following to the end of my &lt;u&gt;.bashrc file&lt;/u&gt; so things work on every reboot: &lt;/p&gt;

&lt;pre&gt;export GOROOT=/root/go
export GOPATH=/usr/local/go/bin:/root/go/bin
export PATH=$PATH:$GOPATH&lt;/pre&gt;

&lt;p&gt;I've seen some odd bug-bounty programs where this kind of search is not called for, and a few where the company simply doesn't want more than one or two specific domains to be probed, but the large majority of companies out there want most or all of their assets to be reviewed for vulnerability. After installing &lt;u&gt;Go and Amass&lt;/u&gt;, and ensuring that &lt;b&gt;Amass&lt;/b&gt; runs, the next step is looking at configuration settings. With &lt;b&gt;Amass&lt;/b&gt; you can skip all the command-line arguments and simply put them into a single amass_config.ini file. It's even easier, since they provide you an example config file, and you can often just uncomment a few lines. Here is the &lt;a href=&quot;https://github.com/OWASP/Amass/blob/master/doc/user_guide.md&quot; target=&quot;_blank&quot;&gt;primary Amass help page&lt;/a&gt; with all the details. I have a single folder for all my bug-bounty ops, and I put the &lt;u&gt;amass_config.ini&lt;/u&gt; file into the root of that folder. Here are some command configuration settings:&lt;/p&gt;

&lt;pre&gt;# Basic settings related to brute forcing
brute_forcing = true
recursive_brute_forcing = true

# Number of discoveries made in a subdomain before performing recursive brute forcing
minimum_for_recursive = 1

# Specify the path of the wordlist file that should be used during brute forcing
wordlist_file = /root/go/src/github.com/OWASP/Amass/wordlists/subdomains.lst

# Would you like to permute resolved names?
alterations = true

# Would you like to use more active techniques, such as pulling certificates from discovered IP addresses?
mode = active

# Ports used when pulling certificates
port = 443

# Would you like unresolved names to be included in the output?
include_unresolvable = true

# Root domain names used in the enumeration
[domains]
domain = sometargetcompany.net

# DNS resolvers used globally by the amass package
[resolvers]
resolver = 1.1.1.1 ; Cloudflare
resolver = 8.8.8.8 ; Google
resolver = 77.88.8.8 ; Yandex.DNS
resolver = 1.0.0.1 ; Cloudflare Secondary
resolver = 8.8.4.4 ; Google Secondary
resolver = 77.88.8.1 ; Yandex.DNS Secondary&lt;/pre&gt;

&lt;p&gt;Then just start Amass with a command like this&lt;/p&gt;

&lt;pre&gt;&amp;gt; amass -config /Ops/amass_config.ini | tee ./amass_subdomainsearch.txt&lt;/pre&gt;

&lt;p&gt;I initially included unresolvable domain-names in the search (since I'm an airhead and I like wasting time). The truth is you don't need those as an external tester. If you can't get an IP address, then you have no use for the domain-name.&lt;/p&gt;

&lt;p&gt;Another consideration is that some of these small to medium companies can return millions of domain-names, so it is recommended using a tool like &lt;b&gt;GKrelM&lt;/b&gt; to ensure you still have network activity with some of the long-running scans. There are mysterious forces out there which will knock you offline if you demonstrate an intention to perform &lt;u&gt;comprehensive domain or port scans&lt;/u&gt;. &lt;/p&gt;

&lt;h3&gt;NMAP and List Processing&lt;/h3&gt;
&lt;p&gt;If you do end up with a ton of inactive domain-names, you can filter them with a forward-DNS search using &lt;b&gt;NMAP&lt;/b&gt; and then remove unresolvable lines with &lt;b&gt;BASH&lt;/b&gt; as follows: &lt;/p&gt;

&lt;pre&gt;&amp;gt; nmap -iL amass_subdomainsearch.txt -sL -sn -oN - --dns-servers 8.8.8.8,8.8.4.4 &amp;gt; amass_activehosts_raw.txt
&amp;gt; sed -i '/Failed to resolve/d' amass_activehosts_raw.txt
&amp;gt; sed -i '/Other addresses/d' amass_activehosts_raw.txt&lt;/pre&gt;

&lt;p&gt;That's an &lt;b&gt;NMAP&lt;/b&gt; host-discovery scan, with a simple list-scan option (DNS-resolve and simply list the target), then disable follow-on port scanning. Those are the &lt;u&gt;Google DNS-servers&lt;/u&gt; listed, since they're fast and well connected on the network. Stealth is irrelevant here since we're not even touching the targets themselves, and &lt;b&gt;NMAP&lt;/b&gt; offers options to view output and simultaneously send it to a file.&lt;/p&gt;

&lt;p&gt;&lt;b&gt;Sed&lt;/b&gt; is great for modifying files in-place. Those commands above will delete lines containing 'Failed to resolve' and 'Other addresses'. You may have to remove a couple meta-information lines from the start and end, but the rest will be resolvable domain-names, and you can get a clean list of these with the following commands: &lt;/p&gt;

&lt;pre&gt;&amp;gt; awk '{print $5}' amass_activehosts_raw.txt &amp;gt; amass_activehosts.txt
&amp;gt; rm amass_activehosts_raw.txt&lt;/pre&gt;

&lt;p&gt;One scan I performed recently on a &lt;u&gt;medium-sized business&lt;/u&gt; started with 2 to 3 million (mostly unused) domain-names, and resulted in about 1300 active, resolvable domain-names. At this stage you have the option to scan all these resolvable domain-names (it can take a long time to get through 65,535 ports on 1300 domain-names). What I did was simply &lt;u&gt;focus on browser-based services&lt;/u&gt;, such as those used on port 443, since the large majority of company business and useful activity will be web-based. I did an &lt;b&gt;NMAP&lt;/b&gt; scan on these with slightly more stealth, because some WAFs or firewalls may detect &lt;b&gt;NMAP&lt;/b&gt; and drop or block your packets. In truth they can always detect what you're doing if they have modern defenses, but if the company is doing business on these ports/servers they won't block everything. Here is the scan I used: &lt;/p&gt;

&lt;pre&gt;&amp;gt; nmap -iL ./amass_activehostips.txt -sT -f -p80,8080,443,8443,8181 -Pn --data-length 140 --host-timeout 30m --scan-delay 1500ms --initial-rtt-timeout 1100ms --max-retries 2 --script http-enum --script-args http.useragent=&quot;Hi There&quot; target_ip&lt;/pre&gt;

&lt;p&gt;The above specifies IP fragmentation, non-standard values for --data-length, --host-timeout, --scan-delay, --initial-rtt-timeout, useragent header, and the TCP-connect scan which tends to be a little less identifiable than the Syn-scan. Also we're skipping host-discovery here, and if you use IP addresses then there won't be any DNS lookup. My system got through 1300 scans on 5 ports in about 50 minutes, and resulted in roughly 90 IP addresses which have interesting web-based activity going on. Once you've identified &lt;u&gt;host-IPs with open ports&lt;/u&gt;, you can perform more detailed scans and really start using the NMAP databases. Here is an example: &lt;/p&gt;

&lt;pre&gt;&amp;gt; nmap -O -v -sV -sC -p80,8080,443,8443,8181 -Pn --reason target_ip&lt;/pre&gt;

&lt;p&gt;This command runs all the 'default' NMAP scripts, along with providing its best guess for operating system, and service/version information. Any lines that say 'Filtered' should be discarded since the server isn't responding on that port. The resulting information should be enough to start poking at some of these endpoints with other tools, such as &lt;u&gt;spidering proxies and fuzzers&lt;/u&gt;.&lt;/p&gt;

&lt;h3&gt;Last Words and Other Useful Stuff&lt;/h3&gt;
&lt;p&gt;&lt;b&gt;NMAP&lt;/b&gt; requires some time spent with it to become familiar with many of the features, so reviewing available documentation is recommended. Below I've listed a few NMAP webpages which I found useful.
  &lt;ul style=&quot;list-style-type: none;&quot;&gt;
    &lt;li&gt;&lt;a href=&quot;https://nmap.org/book/toc.html&quot; target=&quot;_blank&quot;&gt;Top-Level Online Documentation&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;https://nmap.org/book/man-briefoptions.html&quot; target=&quot;_blank&quot;&gt;Command-Line Options Summary&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;https://nmap.org/book/man-host-discovery.html&quot; target=&quot;_blank&quot;&gt;Host Discovery&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;https://nmap.org/book/man-port-scanning-techniques.html&quot; target=&quot;_blank&quot;&gt;Port Scanning Techniques&lt;/a&gt;&lt;/li&gt;
  &lt;/ul&gt;
&lt;/p&gt;

&lt;p&gt;Many &lt;b&gt;BASH&lt;/b&gt; tools require time spent as well, so aside from the brief explanations already provided, I won't go into much more detail on those. I recommend the reader explore each of those tools further on their own.&lt;/p&gt;

&lt;p&gt;I did run into a script (which I modified slightly) to perform forward-DNS lookups on a domain-name list, then output several useful items into a multi-column CSV file. The columns contain domain-name first, then an IP address (or the first IP found in case round-robin load-balancing is being used), followed by zero or more name-servers used by that domain. Some may find it helpful, so I've presented the script below.&lt;/p&gt;

&lt;pre&gt;#!/bin/bash
# Input: A single file containing a list of domain-names, one per line
# Output: A csv containing domain-name, IP address, and Nameservers in each column

# Give each column the relevant header titles
echo &quot;Domain Name,IP Address,Nameserver,Nameserver,Nameserver,Nameserver,Nameserver&quot; &amp;gt; &quot;${1%%.*}_exp.csv&quot;

while read domain
do
  # Get IP address defined in domain's root A-record (only grab the very last one returned)
  ipaddress=`dig $domain +short | tail -n1`

  # Get list of all nameservers
  ns=`dig ns $domain +short| sort | tr '\n' ','`

  echo &quot;$domain&quot;
  echo &quot;IP Address:  $ipaddress&quot;
  echo &quot;Nameservers: $ns&quot;
  echo &quot; &quot;
  
  # Prints all the values fetched into the CSV file
  echo -e &quot;$domain,$ipaddress,$ns&quot; &amp;gt;&amp;gt; &quot;${1%%.*}_exp.csv&quot;

# Defines the text file from which to read domain names
done &amp;lt; $1&lt;/pre&gt;

&lt;p&gt;If I named the script &lt;u&gt;dnslu.sh&lt;/u&gt; then it could be used in the following way, passing a file containing domain-names: &lt;/p&gt;

&lt;pre&gt;&amp;gt; ~/Scripts/dnslu.sh amass_activehosts.txt&lt;/pre&gt;

&lt;p&gt;The output in this case would be a file named &lt;u&gt;amass_activehosts_exp.csv&lt;/u&gt; . Now to get a list of unique IP addresses and copy them to another file, I could use a command like the following: &lt;/p&gt;

&lt;pre&gt;&amp;gt; csvtool col 2 amass_activehosts_exp.csv &amp;#x7c; uniq -u &amp;gt; amass_activehostips.txt &amp;amp;&amp;amp; sed -i '1d' amass_activehostips.txt &lt;/pre&gt;

&lt;p&gt;The reason the above can come in handy is that &lt;b&gt;NMAP&lt;/b&gt; scans often run much quicker when you separate &lt;u&gt;host-discovery&lt;/u&gt; from &lt;u&gt;port scanning&lt;/u&gt;, and also when or if you perform DNS lookups.&lt;/p&gt;

&lt;div&gt;&amp;nbsp;&lt;/div&gt;
&lt;p&gt;-R. Foreman&lt;/p&gt;
&lt;div&gt;&amp;nbsp;&lt;/div&gt;</content><author><name></name></author><summary type="html">Domain-Name Collection March 30, 2019 Reading cyber-security articles, and specifically the investigative aspects of vulnerability testing, one begins to get a sense for the steps that would be needed to perform this task. When a company puts their primary website (and all subdomains) into scope for a bug-bounty, the logical first question is just exactly how would you enumerate all the company properties under that primary website? This seems so obvious, but it is a crucial first step, and for a long time security analysts were using very crude, brute-force types of tools that were running dictionary-type scans using large lists of words. It's only been the last 2-3 years (to my knowledge) that tools began to appear which used alternate approaches, such as historical DNS lookups, domain-names on security certificates, other archived data sources, as well as actually spidering a site to collect domain-names from URLs. Some of the latest tools are using dozens of external sources to gather a comprehensive list. While this is probably the most thorough approach, it often leads to massive lists of unused domain-names, some of which date back decades. In all honesty I have not tried any of the older dictionary-scanning tools, with recognizable names such as SubBrute and Sublist3r. About a year ago I read many people talking about a tool called Aquatone. I tried the tool, and indeed it did an admirable job of producing a large list of domain-names. Shortly after I tried it, the author announced he may discontinue development of this functionality, and he recommended another tool called Amass which he said did an even better job at this particular task. The OWASP Amass project's stated goal is to fill in gaps and data-sources that other tools had missed. Recently I was testing several enumeration tools, and after seeing the list produced by Amass I basically stopped looking at the other tools. OWASP Amass I think people were turned off initially by Amass because it uses the Go interpreter, a relative new-comer in the Linux world, and many people get tired of learning yet another language and system which works essentially the same as existing ones. Go is new for sure, but after installing it I found it really is not difficult to use. Actually Amass offers several options, including Snap, Docker images, and pre-compiled binaries. Since I tend to be a purist I went with the compile-from-source option, which involved installing the Go library first, and then installing Amass. The instructions are on the Amass github repo. The most important part seemed to be getting the path set correctly. I added the following to the end of my .bashrc file so things work on every reboot: export GOROOT=/root/go export GOPATH=/usr/local/go/bin:/root/go/bin export PATH=$PATH:$GOPATH I've seen some odd bug-bounty programs where this kind of search is not called for, and a few where the company simply doesn't want more than one or two specific domains to be probed, but the large majority of companies out there want most or all of their assets to be reviewed for vulnerability. After installing Go and Amass, and ensuring that Amass runs, the next step is looking at configuration settings. With Amass you can skip all the command-line arguments and simply put them into a single amass_config.ini file. It's even easier, since they provide you an example config file, and you can often just uncomment a few lines. Here is the primary Amass help page with all the details. I have a single folder for all my bug-bounty ops, and I put the amass_config.ini file into the root of that folder. Here are some command configuration settings: # Basic settings related to brute forcing brute_forcing = true recursive_brute_forcing = true # Number of discoveries made in a subdomain before performing recursive brute forcing minimum_for_recursive = 1 # Specify the path of the wordlist file that should be used during brute forcing wordlist_file = /root/go/src/github.com/OWASP/Amass/wordlists/subdomains.lst # Would you like to permute resolved names? alterations = true # Would you like to use more active techniques, such as pulling certificates from discovered IP addresses? mode = active # Ports used when pulling certificates port = 443 # Would you like unresolved names to be included in the output? include_unresolvable = true # Root domain names used in the enumeration [domains] domain = sometargetcompany.net # DNS resolvers used globally by the amass package [resolvers] resolver = 1.1.1.1 ; Cloudflare resolver = 8.8.8.8 ; Google resolver = 77.88.8.8 ; Yandex.DNS resolver = 1.0.0.1 ; Cloudflare Secondary resolver = 8.8.4.4 ; Google Secondary resolver = 77.88.8.1 ; Yandex.DNS Secondary Then just start Amass with a command like this &amp;gt; amass -config /Ops/amass_config.ini | tee ./amass_subdomainsearch.txt I initially included unresolvable domain-names in the search (since I'm an airhead and I like wasting time). The truth is you don't need those as an external tester. If you can't get an IP address, then you have no use for the domain-name. Another consideration is that some of these small to medium companies can return millions of domain-names, so it is recommended using a tool like GKrelM to ensure you still have network activity with some of the long-running scans. There are mysterious forces out there which will knock you offline if you demonstrate an intention to perform comprehensive domain or port scans. NMAP and List Processing If you do end up with a ton of inactive domain-names, you can filter them with a forward-DNS search using NMAP and then remove unresolvable lines with BASH as follows: &amp;gt; nmap -iL amass_subdomainsearch.txt -sL -sn -oN - --dns-servers 8.8.8.8,8.8.4.4 &amp;gt; amass_activehosts_raw.txt &amp;gt; sed -i '/Failed to resolve/d' amass_activehosts_raw.txt &amp;gt; sed -i '/Other addresses/d' amass_activehosts_raw.txt That's an NMAP host-discovery scan, with a simple list-scan option (DNS-resolve and simply list the target), then disable follow-on port scanning. Those are the Google DNS-servers listed, since they're fast and well connected on the network. Stealth is irrelevant here since we're not even touching the targets themselves, and NMAP offers options to view output and simultaneously send it to a file. Sed is great for modifying files in-place. Those commands above will delete lines containing 'Failed to resolve' and 'Other addresses'. You may have to remove a couple meta-information lines from the start and end, but the rest will be resolvable domain-names, and you can get a clean list of these with the following commands: &amp;gt; awk '{print $5}' amass_activehosts_raw.txt &amp;gt; amass_activehosts.txt &amp;gt; rm amass_activehosts_raw.txt One scan I performed recently on a medium-sized business started with 2 to 3 million (mostly unused) domain-names, and resulted in about 1300 active, resolvable domain-names. At this stage you have the option to scan all these resolvable domain-names (it can take a long time to get through 65,535 ports on 1300 domain-names). What I did was simply focus on browser-based services, such as those used on port 443, since the large majority of company business and useful activity will be web-based. I did an NMAP scan on these with slightly more stealth, because some WAFs or firewalls may detect NMAP and drop or block your packets. In truth they can always detect what you're doing if they have modern defenses, but if the company is doing business on these ports/servers they won't block everything. Here is the scan I used: &amp;gt; nmap -iL ./amass_activehostips.txt -sT -f -p80,8080,443,8443,8181 -Pn --data-length 140 --host-timeout 30m --scan-delay 1500ms --initial-rtt-timeout 1100ms --max-retries 2 --script http-enum --script-args http.useragent=&quot;Hi There&quot; target_ip The above specifies IP fragmentation, non-standard values for --data-length, --host-timeout, --scan-delay, --initial-rtt-timeout, useragent header, and the TCP-connect scan which tends to be a little less identifiable than the Syn-scan. Also we're skipping host-discovery here, and if you use IP addresses then there won't be any DNS lookup. My system got through 1300 scans on 5 ports in about 50 minutes, and resulted in roughly 90 IP addresses which have interesting web-based activity going on. Once you've identified host-IPs with open ports, you can perform more detailed scans and really start using the NMAP databases. Here is an example: &amp;gt; nmap -O -v -sV -sC -p80,8080,443,8443,8181 -Pn --reason target_ip This command runs all the 'default' NMAP scripts, along with providing its best guess for operating system, and service/version information. Any lines that say 'Filtered' should be discarded since the server isn't responding on that port. The resulting information should be enough to start poking at some of these endpoints with other tools, such as spidering proxies and fuzzers. Last Words and Other Useful Stuff NMAP requires some time spent with it to become familiar with many of the features, so reviewing available documentation is recommended. Below I've listed a few NMAP webpages which I found useful. Top-Level Online Documentation Command-Line Options Summary Host Discovery Port Scanning Techniques Many BASH tools require time spent as well, so aside from the brief explanations already provided, I won't go into much more detail on those. I recommend the reader explore each of those tools further on their own. I did run into a script (which I modified slightly) to perform forward-DNS lookups on a domain-name list, then output several useful items into a multi-column CSV file. The columns contain domain-name first, then an IP address (or the first IP found in case round-robin load-balancing is being used), followed by zero or more name-servers used by that domain. Some may find it helpful, so I've presented the script below. #!/bin/bash # Input: A single file containing a list of domain-names, one per line # Output: A csv containing domain-name, IP address, and Nameservers in each column # Give each column the relevant header titles echo &quot;Domain Name,IP Address,Nameserver,Nameserver,Nameserver,Nameserver,Nameserver&quot; &amp;gt; &quot;${1%%.*}_exp.csv&quot; while read domain do # Get IP address defined in domain's root A-record (only grab the very last one returned) ipaddress=`dig $domain +short | tail -n1` # Get list of all nameservers ns=`dig ns $domain +short| sort | tr '\n' ','` echo &quot;$domain&quot; echo &quot;IP Address: $ipaddress&quot; echo &quot;Nameservers: $ns&quot; echo &quot; &quot; # Prints all the values fetched into the CSV file echo -e &quot;$domain,$ipaddress,$ns&quot; &amp;gt;&amp;gt; &quot;${1%%.*}_exp.csv&quot; # Defines the text file from which to read domain names done &amp;lt; $1 If I named the script dnslu.sh then it could be used in the following way, passing a file containing domain-names: &amp;gt; ~/Scripts/dnslu.sh amass_activehosts.txt The output in this case would be a file named amass_activehosts_exp.csv . Now to get a list of unique IP addresses and copy them to another file, I could use a command like the following: &amp;gt; csvtool col 2 amass_activehosts_exp.csv &amp;#x7c; uniq -u &amp;gt; amass_activehostips.txt &amp;amp;&amp;amp; sed -i '1d' amass_activehostips.txt The reason the above can come in handy is that NMAP scans often run much quicker when you separate host-discovery from port scanning, and also when or if you perform DNS lookups. &amp;nbsp; -R. Foreman &amp;nbsp;</summary></entry><entry><title type="html">Hello again.. Good to be back</title><link href="/posts/2019-3-4-helloagain" rel="alternate" type="text/html" title="Hello again.. Good to be back" /><published>2019-03-04T00:00:00-07:00</published><updated>2019-03-04T00:00:00-07:00</updated><id>/posts/helloagain</id><content type="html" xml:base="/posts/2019-3-4-helloagain">&lt;h2&gt;Hello again, World&lt;/h2&gt;
&lt;h5&gt;March 3, 2019&lt;/h5&gt;
&lt;p class=&quot;lead&quot;&gt;Recently I found myself with extra time on my hands (about 2 weeks ago), due to an employer separation. It was opportune timing, since I was being attacked by a flu-virus which was only getting worse. Hey, they don't call this the cold and flu season for nothing. It was actually more than opportune, since my (former) employer Ascenda often required people to submit a doctor note when they were out sick for more than a couple days, and at the same time the pay was so low that most people in there could not afford health-care coverage. Those were the kind of shitty things going on at Ascenda, so I can't say I'm sorry to be completely disassociated from that company.&lt;/p&gt;

&lt;p&gt;My actual work was on &lt;b&gt;Airbnb&lt;/b&gt; customer accounts, and my feelings toward that organization are very positive. &lt;b&gt;Airbnb&lt;/b&gt; runs one of the more cutting-edge web portals, and although I didn't meet many of them, I am certain they employ some of the very best software engineers and business strategists. The very fact they went from conception to global presence in such a short timeframe (a few years) is testimony to how dynamic and beneficial &lt;b&gt;Airbnb&lt;/b&gt; is to everyone involved, and although they have yet to become a public company I am certain that private investors are lining up to give them investment money. I thoroughly enjoyed the work I was doing on their web platform, and &lt;u&gt;I learned much about account security and online fraud that I hadn't known before&lt;/u&gt;. Still the environment and tools were limiting for someone like myself who has used hundreds of different systems, languages, and tools, so our parting of ways may have been for the best.&lt;/p&gt;

&lt;h3&gt;Moving to Linux&lt;/h3&gt;
&lt;p&gt;Aside from updating my resume and job-board links, I used my new-found freedom to tackle a couple personal projects which I simply hadn't had time to fully address. The first was &lt;u&gt;moving all my computer activities from MS Windows 7 over to Linux&lt;/u&gt;. This had been in the planning for a while, but there were just too many moving parts to get it all done over one or two weekends. With the Windows 7 end of service life less than a year away, this move was inevitable (and for other reasons I won't continue using Microsoft Windows going forward, except perhaps testing in a virtual machine). After reviewing several Linux distros &lt;u&gt;I arrived at Ubuntu-Mate as the most likely candidate for my new system&lt;/u&gt;, due to its widespread adoption and support, and the low-demand desktop environment. Ubuntu is derived from Debian, which is also solidly supported and unlikely to go away anytime soon. Since I have collected and organized hundreds of thousands of hyperlinks, some care had to be taken, and a new scheme for managing hyperlinks had to be arrived at. To maintain online privacy and keep from becoming a victim of XSS hacking I also had to devise a new browser scheme, since Linux doesn't run any of the Microsoft browsers. &lt;u&gt;At this point in time I am running Chrome, Brave Browser, and Firefox&lt;/u&gt;, with specific division of workload between them, and specially crafted launch commands to cache files onto an in-memory disk drive for speed and performance. Another part of this task was decryption and auto-mounting of &lt;b&gt;Veracrypt volumes&lt;/b&gt;, the auto-mounting of various other &lt;b&gt;NTFS volumes&lt;/b&gt;, and the creation (and mounting) of a &lt;b&gt;ram-disk&lt;/b&gt;. I think I have over a dozen disk-drives, so this was not a trivial task. For a time I struggled with &lt;b&gt;DNS settings&lt;/b&gt;, since &lt;u&gt;I run DNSCrypt and OpenVPN&lt;/u&gt;, with all (most of) my traffic running through a &lt;u&gt;leak-proof encrypted tunnel&lt;/u&gt;, and with the help of a specially built &lt;u&gt;iptables firewall&lt;/u&gt;. This all may seem overly complex, but it works to keep me safe from some of the psychopaths (in government, organized crime, and corporate exploit) who like to surveil peoples' online activities. There were a few other setup odds and ends, but I am happy to say that after a week of work I was no longer booting this computer into Windows 7.&lt;/p&gt;

&lt;h3&gt;Blogging with Jekyll, the Static-Site Generator&lt;/h3&gt;
&lt;p&gt;The other big project standing in my way, was &lt;u&gt;converting this personal blog over to use a static site generator&lt;/u&gt;. It just seemed reasonable that anything I might do in the future may involve blogging about it afterward. The static site generator I had in mind is called &lt;b&gt;Jekyll&lt;/b&gt;, and after a week of effort all I can say is this is a real &lt;u&gt;convoluted mess&lt;/u&gt;, involving Git, Ruby and several related tools, HTML, CSS, and some Javascript, Liquid markdown (Kramdown), YAML, and a little bit of BASH ninja knowledge. Nonetheless it is a mess which I am willing to suffer, given that it works and it's free, the alternative is an even bigger convoluted mess involving web servers, databases, server-side script, and potentially severely vulnerable (as in complete remote take-over) blogging packages, and finally I just can't see myself maintaining by hand a roll-your-own blog of any more than a dozen or so posts. When I first built this site 2 years ago I used only Git, Bootstrap, and hand-rolled HTML/CSS, and after a dozen articles it was already becoming burdensome to maintain little details by hand. Having a tool which can scale easily to dozens or hundreds of blog-posts, with minimal effort, is &lt;u&gt;the tool I was looking for when I started&lt;/u&gt;. For all the expletives uttered about &lt;b&gt;Jekyll&lt;/b&gt; over the past week, at this point &lt;b&gt;Jekyll&lt;/b&gt; is just ok by me. Finally I had to compose this blog-post, just to say hello again and to say that &lt;u&gt;the rumors of my demise have been greatly exaggerated&lt;/u&gt;. I haven't posted in the past 2 years because I have been quite busy with my job, and for that other reason I just described (too many blog-posts on a hand-built site is not easy to do).&lt;/p&gt;

&lt;h3&gt;EBikes and Legal Hacking&lt;/h3&gt;
&lt;p&gt;Now that I have my two big projects out of the way, and my flu is starting to subside, I am looking forward to moving on with my life, finding another interesting job, and doing a few other personal activities. I spent the past 8 months &lt;u&gt;installing an ebike conversion kit onto my mountain-bike&lt;/u&gt;, and at this point I'm just waiting for some nicer weather to do further work and testing (if you can really call riding an ebike around to be work). The 'kit' consisted of a 3 Kilo-Watt DC Brushless motor, some mounting brackets, bottom-bracket, and front chain-ring. I also needed a hefty LiPo battery and a throttle. Since this was my first attempt at this sort of thing, I also required a bicycle maintenance stand, a few additional parts (chains, derailers, cables, shifters, grease, crank-arms and pedals, etc), and some specialized bicycle tools. &lt;u&gt;This was a very fun project&lt;/u&gt;, and I think I will be blogging more about this subject as time passes. In between sending job applications and reading current event articles, I plan to experiment with vulnerability testing (&lt;b&gt;bug-bounty hunting&lt;/b&gt;) and possibly &lt;b&gt;malware analysis&lt;/b&gt;, using a secondary Kali-Linux box I have set up. I can't possibly specialize in everything and I certainly don't expect that I will, but I would like to test some of the tools I have encountered in my reading activities, just to see where it leads. I am not new to the subject of &lt;b&gt;cyber-security&lt;/b&gt;, so I know the broad categories of tools and what they're for, and I also received excellent network training several years ago when I earned CompTIA certifications in Network+ and Security+. Anyway, the future looks bright. Hopefully we won't fall into post-industrial apocalypse before I get a chance to play with some of the best toys offered by modern technology. Best regards to all.&lt;/p&gt;
&lt;div&gt;&amp;nbsp;&lt;/div&gt;
&lt;p&gt;-R. Foreman&lt;/p&gt;
&lt;div&gt;&amp;nbsp;&lt;/div&gt;</content><author><name></name></author><summary type="html">Hello again, World March 3, 2019 Recently I found myself with extra time on my hands (about 2 weeks ago), due to an employer separation. It was opportune timing, since I was being attacked by a flu-virus which was only getting worse. Hey, they don't call this the cold and flu season for nothing. It was actually more than opportune, since my (former) employer Ascenda often required people to submit a doctor note when they were out sick for more than a couple days, and at the same time the pay was so low that most people in there could not afford health-care coverage. Those were the kind of shitty things going on at Ascenda, so I can't say I'm sorry to be completely disassociated from that company.</summary></entry><entry><title type="html">Create Shell Launch Menus in the Gnome3 Desktop</title><link href="/posts/2017-2-13-gnome3extension" rel="alternate" type="text/html" title="Create Shell Launch Menus in the Gnome3 Desktop" /><published>2017-02-13T00:00:00-07:00</published><updated>2017-02-13T00:00:00-07:00</updated><id>/posts/gnome3extension</id><content type="html" xml:base="/posts/2017-2-13-gnome3extension">&lt;h2&gt;Shell Launch Menus in Gnome3&lt;/h2&gt;
&lt;h5&gt;February 13, 2017&lt;/h5&gt;
&lt;p class=&quot;lead&quot;&gt;Linux shares some of the same failings as MSWindows, in that it can be difficult to create menus, buttons, and icons for launching programs. Desktop icons in Linux are accomplished by creating a specific file, with a specific extension, containing specific lines of text, and placing it in a specific folder. Icons aren't too difficult. The Gnome Shell uses something called a desktop topbar (similar to the Macintosh), where the accepted approach to customization is via a so-called Shell Extension, and this very nearly requires a Computer Science degree to create one. I will outline my experiences in learning these techniques, and provide a template for creating a shell extension in Gnome3.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;a name=&quot;DebuggingGnome3Extensions&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Debugging Gnome3 Extensions&lt;/h3&gt;
&lt;p&gt;Gnome provides some basic debugging capability through a program called &lt;b&gt;lookingglass&lt;/b&gt;. One very useful tool I found to assist in debugging is an extension which opens &lt;b&gt;lookingglass&lt;/b&gt; from the topbar, and it also restarts the gnome shell by right-clicking the button. These are two tasks that must be performed over and over as you are building a gnome extension. &lt;a href=&quot;https://extensions.gnome.org/extension/682/lgloader/&quot; target=&quot;_blank&quot;&gt;The utility extension I described here is called LGLoader.&lt;/a&gt; When running, the &lt;b&gt;LGLoader&lt;/b&gt; button sits in the middle of the topbar, and displays as yellow text.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/GnomeShellExtImg1.jpg&quot; alt=&quot;LGLoader in the TopBar&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;

&lt;p&gt;To install this, create a folder here.&lt;/p&gt;
&lt;pre&gt;/root/.local/share/gnome-shell/extensions/lgLoader@zhw2101024&lt;/pre&gt;

&lt;p&gt;Download all the extension files, and place them into that folder. Open the file &lt;u&gt;metadata.json&lt;/u&gt; and add your shell's version number (you can find this by typing &lt;b&gt;gnome-shell --version&lt;/b&gt; at a command terminal).&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/GnomeShellExtImg2.jpg&quot; alt=&quot;Finding Shell Version Number at the Command-Line&quot; /&gt;
&lt;img src=&quot;/images/GnomeShellExtImg3.jpg&quot; alt=&quot;Adding Shell Version Number in Metadata.Json&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;

&lt;p&gt;Close and save &lt;u&gt;metadata.json&lt;/u&gt; , and then restart the gnome shell. The manual way to restart the gnome shell (when you don't have &lt;b&gt;LGLoader&lt;/b&gt; available to you) is to type alt-F2 , type the 'r' key, and then hit enter. Once &lt;b&gt;LGLoader&lt;/b&gt; is running, you can restart the gnome shell any time by just right-clicking on the button.&lt;/p&gt;

&lt;p&gt;The final piece to the puzzle is to enable the extension. This can be done with something called the &lt;u&gt;dconf editor&lt;/u&gt; (sort of like the registry editor in MSWindows). A far easier way to enable the extension is to install a program called &lt;b&gt;gnome-tweak-tool&lt;/b&gt;.&lt;/p&gt;
&lt;pre&gt;&amp;gt; apt-get install gnome-tweak-tool&lt;/pre&gt;

&lt;p&gt;Launch the &lt;b&gt;gnome-tweak-tool&lt;/b&gt; from a command line by uttering its name. Navigate to the Extensions tab, and use the button-sliders to enable or disable individual extensions.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/GnomeShellExtImg4.jpg&quot; alt=&quot;Gnome Tweak Tool, Enable Shell Extensions&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;

&lt;p&gt;I found that a small correction to the original code for &lt;b&gt;LGLoader&lt;/b&gt; was necessary to make it work properly. To correct the problem code, do the following. Open the file &lt;u&gt;extension.js&lt;/u&gt; and find the section of code which appears as follows.&lt;/p&gt;
&lt;pre&gt;
&lt;span class=&quot;c&quot;&gt;//let statusArea = Main.panel.statusArea; &lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt;(name &lt;span class=&quot;k&quot;&gt;in&lt;/span&gt; statusArea) { 
  statusEvents[name] &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; statusArea[name].menu.connect(&lt;span class=&quot;s&quot;&gt;&amp;#39;open-state-changed&amp;#39;&lt;/span&gt;, &lt;span class=&quot;k&quot;&gt;function&lt;/span&gt;(menu, isOpen) { 
    statusArea.lgLoader.actor.can_focus &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;isOpen; 
  }); 
}
&lt;/pre&gt;

&lt;p&gt;Replace the above code with the block appearing below.&lt;/p&gt;
&lt;pre&gt;
&lt;span class=&quot;c&quot;&gt;//let statusArea = Main.panel.statusArea; &lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt;(name &lt;span class=&quot;k&quot;&gt;in&lt;/span&gt; statusArea) {
  &lt;span class=&quot;k&quot;&gt;try&lt;/span&gt;  {
    statusEvents[name] &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; statusArea[name].menu.connect(&lt;span class=&quot;s&quot;&gt;&amp;#39;open-state-changed&amp;#39;&lt;/span&gt;, &lt;span class=&quot;k&quot;&gt;function&lt;/span&gt;(menu, isOpen) {
      statusArea.lgLoader.actor.can_focus &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;isOpen;
    });
  }
  &lt;span class=&quot;k&quot;&gt;catch&lt;/span&gt;(TypeError) {
  }
}
&lt;/pre&gt;

&lt;p&gt;Finally, restart the gnome shell, and the errant behavior will be corrected. I have made this fix and collected the &lt;b&gt;LGLoader&lt;/b&gt; files into a single downloadable zip file, &lt;a href=&quot;/images/lgLoader@zhw2101024.zip&quot; target=&quot;_blank&quot;&gt;which you can find here&lt;/a&gt;. &lt;b&gt;LGLoader&lt;/b&gt; is a highly useful utility for working with Gnome3 extensions, and is well worth the time taken to set it up.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;a name=&quot;BuildingAGnome3Extension&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Building a Gnome3 Extension&lt;/h3&gt;
&lt;p&gt;If you begin researching Gnome Shell extensions, you'll find a good deal of information. The documentation I found was spread over such a lengthy timeframe that it not only includes Gnome2 Panel applets (an older technology, from a prior version of Gnome), but it also displays classes and techniques which are either deprecated or have been removed altogether from the shell libraries. In short, the web documentation and help articles are kind of a mess. Rather than go into detail about things I've encountered, I will simply demonstrate the process for creating an extension, and then provide a working code-template for creating a topbar drop-down menu, and how to respond to menu-item clicks. Finally I'll talk briefly about the Gnome Shell libraries, and how to find documentation for the various objects and function calls.&lt;/p&gt;

&lt;p&gt;The latest and greatest version of Gnome, the Gnome3 Shell, has a &lt;u&gt;web-centric model&lt;/u&gt;. That is to say, it relies more heavily on new web-based technologies (such as &lt;u&gt;javascript&lt;/u&gt;) than prior versions. As such, the paradigm used to create shell extensions is to build them using &lt;u&gt;javascript&lt;/u&gt;. I suppose it's still possible to build a shell extension using an object-code language like C++, but I'm not personally aware of anyone who is doing it that way. The folks behind Gnome Shell have created a small program to build starter extensions, which is invoked like this.&lt;/p&gt;
&lt;pre&gt;&amp;gt; gnome-shell-extension-tool --create-extension&lt;/pre&gt;

&lt;p&gt;You will be prompted for some basic information, such as a &lt;u&gt;name&lt;/u&gt;, &lt;u&gt;description&lt;/u&gt;, and &lt;u&gt;email address&lt;/u&gt;. Then the skeleton is created for you under this folder.&lt;/p&gt;
&lt;pre&gt;/root/.local/share/gnome-shell/extensions/yourextensionname&lt;/pre&gt;

&lt;p&gt;&lt;img src=&quot;/images/GnomeShellExtImg5.jpg&quot; alt=&quot;Running gnome-shell-extension-tool to Create a New Extension&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;

&lt;p&gt;The create script will then open the file &lt;u&gt;extension.js&lt;/u&gt; for you, so you may begin editing.&lt;/p&gt;

&lt;p&gt;You can see quite a lot of example code over at &lt;a href=&quot;https://extensions.gnome.org&quot; target=&quot;_blank&quot;&gt;https://extensions.gnome.org&lt;/a&gt; (here is &lt;a href=&quot;https://extensions.gnome.org/review/4892&quot; target=&quot;_blank&quot;&gt;one particular example project&lt;/a&gt;) , and you'll notice there are just slight differences in how they are set up, structurally. What has happened is that the javascript language has changed over time, and more code constructs have been added to the gnome libraries, allowing more advanced, higher-level functionality. Also, the Gnome Shell extension API has changed over time, so the interface calling convention is different depending on how old the extension is that you're looking at.&lt;/p&gt;

&lt;p&gt;Here is the code template I arrived at, which I believe represents the most current standard for the Gnome3 extension.&lt;/p&gt;

&lt;pre&gt;&lt;span class=&quot;k&quot;&gt;const&lt;/span&gt; Main &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; imports.ui.main;
&lt;span class=&quot;k&quot;&gt;const&lt;/span&gt; Lang &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; imports.lang;
&lt;span class=&quot;k&quot;&gt;const&lt;/span&gt; PanelMenu &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; imports.ui.panelMenu;
&lt;span class=&quot;k&quot;&gt;const&lt;/span&gt; PopupMenu &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; imports.ui.popupMenu;
&lt;span class=&quot;k&quot;&gt;const&lt;/span&gt; St &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; imports.gi.St;
&lt;span class=&quot;k&quot;&gt;const&lt;/span&gt; Gio &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; imports.gi.Gio;
&lt;span class=&quot;c&quot;&gt;//const Gtk = imports.gi.Gtk;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;const&lt;/span&gt; GLib &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; imports.gi.GLib;
&lt;span class=&quot;k&quot;&gt;const&lt;/span&gt; Clutter &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; imports.gi.Clutter;
&lt;span class=&quot;k&quot;&gt;const&lt;/span&gt; Shell &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; imports.gi.Shell;
&lt;span class=&quot;k&quot;&gt;const&lt;/span&gt; Util &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; imports.misc.util;

&lt;span class=&quot;k&quot;&gt;const&lt;/span&gt; MyPanelObject&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; Lang.Class({
  Name&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;#39;MyPanelObject&amp;#39;&lt;/span&gt;,
  Extends&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; PanelMenu.Button,

  _init&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;function&lt;/span&gt;() {
    &lt;span class=&quot;c&quot;&gt;//Call the super-class&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;.parent(St.Align.START);

    &lt;span class=&quot;c&quot;&gt;//Add the label actor&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;.buttonText &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; St.Label({ text&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;quot;MyShellExt&amp;quot;&lt;/span&gt; });
    &lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;.actor.add_actor(&lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;.buttonText);

    &lt;span class=&quot;c&quot;&gt;//Add first menu item, with action&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;.menu.addAction(&lt;span class=&quot;s&quot;&gt;&amp;quot;First Menu Item&amp;quot;&lt;/span&gt;, &lt;span class=&quot;k&quot;&gt;function&lt;/span&gt;(event) {
      Main.Util.trySpawnCommandLine(&lt;span class=&quot;s&quot;&gt;&amp;#39;xdg-open https://extensions.gnome.org/&amp;#39;&lt;/span&gt;);
    });

    &lt;span class=&quot;c&quot;&gt;//Add second menu item, with no action&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;.menu.addMenuItem(&lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; PopupMenu.PopupMenuItem(&lt;span class=&quot;s&quot;&gt;&amp;quot;Second Menu Item&amp;quot;&lt;/span&gt;));

    &lt;span class=&quot;c&quot;&gt;//Add a separator&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;.menu.addMenuItem(&lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; PopupMenu.PopupSeparatorMenuItem());

    &lt;span class=&quot;c&quot;&gt;//Add a submenu as the 3rd item, and submenu item with no action&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;.MySubMenu &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; PopupMenu.PopupSubMenuMenuItem(&lt;span class=&quot;s&quot;&gt;&amp;quot;SubMenu&amp;quot;&lt;/span&gt;);
    &lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;.menu.addMenuItem(&lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;.MySubMenu);
    &lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;.MySubMenu.menu.addMenuItem(&lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; PopupMenu.PopupMenuItem(&lt;span class=&quot;s&quot;&gt;&amp;quot;submenu value&amp;quot;&lt;/span&gt;));

    &lt;span class=&quot;c&quot;&gt;//Add fourth menu item, with action&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;.menu.addAction(&lt;span class=&quot;s&quot;&gt;&amp;quot;Gnome Tweak Tool&amp;quot;&lt;/span&gt;, &lt;span class=&quot;k&quot;&gt;function&lt;/span&gt;(event) {
      &lt;span class=&quot;k&quot;&gt;let&lt;/span&gt; bashStr &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;quot;bash -c &amp;#39;gnome-tweak-tool;bash&amp;#39;&amp;quot;&lt;/span&gt;;
      Util.spawn([&lt;span class=&quot;s&quot;&gt;&amp;#39;gnome-terminal&amp;#39;&lt;/span&gt;, &lt;span class=&quot;s&quot;&gt;&amp;#39;--tab&amp;#39;&lt;/span&gt;, &lt;span class=&quot;s&quot;&gt;&amp;#39;--geometry=168x48+74+0&amp;#39;&lt;/span&gt;, &lt;span class=&quot;s&quot;&gt;&amp;#39;--title=MyPC&amp;#39;&lt;/span&gt;, &lt;span class=&quot;s&quot;&gt;&amp;#39;-e&amp;#39;&lt;/span&gt;, bashStr, &lt;span class=&quot;s&quot;&gt;&amp;#39;--working-directory=/bin&amp;#39;&lt;/span&gt;]);
    });

    &lt;span class=&quot;c&quot;&gt;//Add fifth menu item, with action. This works with external function _TermLaunch, but only if you call menuItem.connect separately.&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;let&lt;/span&gt; menuItem &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; PopupMenu.PopupMenuItem(&lt;span class=&quot;s&quot;&gt;&amp;quot;Fifth Menu Item&amp;quot;&lt;/span&gt;);
    &lt;span class=&quot;k&quot;&gt;let&lt;/span&gt; myruncmd &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;quot;cd /bin; ls -la&amp;quot;&lt;/span&gt;;
    menuItem.connect(&lt;span class=&quot;s&quot;&gt;&amp;#39;activate&amp;#39;&lt;/span&gt;, Lang.bind(&lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;, &lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;._TermLaunch, myruncmd));
    &lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;.menu.addMenuItem(menuItem);
  },

  _TermLaunch&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;function&lt;/span&gt;(actor, event, runcmd) {
    &lt;span class=&quot;c&quot;&gt;//Util.spawn([&amp;#39;gnome-terminal&amp;#39;, &amp;#39;--tab&amp;#39;, &amp;#39;--geometry=168x48+74+0&amp;#39;, &amp;#39;--title=MyPC&amp;#39;, &amp;#39;-e&amp;#39;, &amp;quot;bash -c &amp;#39;ls -la;bash&amp;#39;&amp;quot;, &amp;#39;--working-directory=/bin&amp;#39;]);&lt;/span&gt;
    Util.spawn([&lt;span class=&quot;s&quot;&gt;&amp;#39;gnome-terminal&amp;#39;&lt;/span&gt;, &lt;span class=&quot;s&quot;&gt;&amp;#39;--tab&amp;#39;&lt;/span&gt;, &lt;span class=&quot;s&quot;&gt;&amp;#39;--geometry=168x48+74+0&amp;#39;&lt;/span&gt;, &lt;span class=&quot;s&quot;&gt;&amp;#39;--title=MyPC&amp;#39;&lt;/span&gt;, &lt;span class=&quot;s&quot;&gt;&amp;#39;-e&amp;#39;&lt;/span&gt;, &lt;span class=&quot;s&quot;&gt;&amp;quot;bash -c &amp;#39;&amp;quot;&lt;/span&gt;  &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; runcmd &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;quot;;bash&amp;#39;&amp;quot;&lt;/span&gt;, &lt;span class=&quot;s&quot;&gt;&amp;#39;--working-directory=/bin&amp;#39;&lt;/span&gt;]);
  }

});

&lt;span class=&quot;k&quot;&gt;function&lt;/span&gt; init()  {
}

&lt;span class=&quot;k&quot;&gt;let&lt;/span&gt; MyObject;

&lt;span class=&quot;k&quot;&gt;function&lt;/span&gt; enable()  {
  MyObject &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; MyPanelObject();
  Main.panel.addToStatusArea(&lt;span class=&quot;s&quot;&gt;&amp;#39;SamplePanelButton&amp;#39;&lt;/span&gt;, MyObject);
}

&lt;span class=&quot;k&quot;&gt;function&lt;/span&gt; disable()  {
  &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; (MyObject) {
    MyObject.destroy();
    MyObject &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;null&lt;/span&gt;;
  }
}
&lt;/pre&gt;

&lt;p&gt;&lt;u&gt;init()&lt;/u&gt; is called once when the extension is added to the shell. &lt;u&gt;enable()&lt;/u&gt; / &lt;u&gt;disable()&lt;/u&gt; are called each time the extension is activated or deactivated by the user (for example, in the &lt;b&gt;gnome-tweak-tool&lt;/b&gt;). The above example code shows 3 differents ways to launch terminals and run programs. It's a pretty straightforward file once you stop looking at the older variations. This is simple javascript, and about the most difficult task is finding decent documentation for the various objects and functions.&lt;/p&gt;

&lt;p&gt;You can browse through source code for some of the installed Gnome3 components. For example, the application menu on the topbar is simply an extension located here.&lt;/p&gt;
&lt;pre&gt;/usr/share/gnome-shell/extensions/apps-menu@gnome-shell-extensions.gcampax.github.com&lt;/pre&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;a name=&quot;DocumentationForGnome3Extensions&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h4&gt;&lt;u&gt;Documentation for Gnome3 Extensions&lt;/u&gt;&lt;/h4&gt;
&lt;p&gt;With regard to finding documentation for the various classes, global variables, and functions, this is where things get more bizarre and difficult. Part of the Gnome libraries exist as javascript, and part of them are compiled (C or C++) object code. Wherever you see the acronym &lt;u&gt;GJS&lt;/u&gt;, you should imagine that code existing as javascript. When you see the term &lt;u&gt;GIR&lt;/u&gt; you should imagine XML files which reference C-language functions that are callable from javascript.&lt;/p&gt;

&lt;p&gt;You'll find a lot of information at the &lt;a href=&quot;https://developer.gnome.org/guides&quot; target=&quot;_blank&quot;&gt;Gnome developer wiki&lt;/a&gt;. However much of it doesn't apply to shell extensions, and when you do finally drill down to function and class references which are used by extensions, you'll find they use C-language representation, and often the names are slightly different than what you use in practice. Some of the best information can be gotten from the source code itself. Prior to Gnome 3.12 all the javascript source files were installed on the system as individual files, but after that version these files were wrapped up into a shared library (two or more in fact). Here are two shared libraries that I am aware of which contain this javascript source code.&lt;/p&gt;
&lt;pre&gt;/usr/lib/gnome-shell/libgnome-shell.so
/usr/lib/libgjs.so.0&lt;/pre&gt;

&lt;p&gt;If you wish to extract the source files, I have written a &lt;u&gt;BASH script&lt;/u&gt; to do that. Open a terminal and execute this script.&lt;/p&gt;
&lt;pre&gt;&lt;span class=&quot;nn&quot;&gt;#!/bin/sh&lt;/span&gt;

&lt;span class=&quot;vi&quot;&gt;gs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;/usr/lib/gnome-shell/libgnome-shell.so

&lt;span class=&quot;nb&quot;&gt;mkdir&lt;/span&gt; &lt;span class=&quot;vi&quot;&gt;$HOME&lt;/span&gt;/Downloads/gnome-shell-js
&lt;span class=&quot;nb&quot;&gt;cd&lt;/span&gt; &lt;span class=&quot;vi&quot;&gt;$HOME&lt;/span&gt;/Downloads/gnome-shell-js

&lt;span class=&quot;nb&quot;&gt;mkdir&lt;/span&gt; -p ui/components ui/status misc perf portalHelper extensionPrefs gdm

&lt;span class=&quot;k&quot;&gt;for &lt;/span&gt;r in `gresource list &lt;span class=&quot;vi&quot;&gt;$gs&lt;/span&gt;`; &lt;span class=&quot;k&quot;&gt;do&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;  &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;gresource&lt;/span&gt; extract &lt;span class=&quot;vi&quot;&gt;$gs&lt;/span&gt; &lt;span class=&quot;vi&quot;&gt;$r&lt;/span&gt; &amp;gt; &lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;vi&quot;&gt;r&lt;/span&gt;#/org/gnome/shell/&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;done&lt;/span&gt;

&lt;span class=&quot;vi&quot;&gt;gjs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;/usr/lib/libgjs.so.0
&lt;span class=&quot;nb&quot;&gt;mkdir&lt;/span&gt; -p modules/overrides modules/tweener

&lt;span class=&quot;k&quot;&gt;for &lt;/span&gt;r in `gresource list &lt;span class=&quot;vi&quot;&gt;$gjs&lt;/span&gt;`; &lt;span class=&quot;k&quot;&gt;do&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;  &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;gresource&lt;/span&gt; extract &lt;span class=&quot;vi&quot;&gt;$gjs&lt;/span&gt; &lt;span class=&quot;vi&quot;&gt;$r&lt;/span&gt; &amp;gt; &lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;vi&quot;&gt;r&lt;/span&gt;#/org/gnome/gjs/&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;done&lt;/span&gt;
&lt;/pre&gt;

&lt;p&gt;The resulting collection of javascript files will get you maybe 80% of the references you will need to do most common kinds of programming, but it's really difficult for me to say for sure. Much of &lt;u&gt;GLib&lt;/u&gt;, &lt;u&gt;GIO&lt;/u&gt;, and &lt;u&gt;GObject&lt;/u&gt; is still C-language source code. &lt;a href=&quot;https://people.gnome.org/~gcampagna/docs/&quot; target=&quot;_blank&quot;&gt;Here is another reference&lt;/a&gt; put together a couple years ago, which provides a (nearly complete) set of API references. I'm sure I'll provide more example code over time, but this is enough to put up a topbar menu for launching programs.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/GnomeShellExtImg6.jpg&quot; alt=&quot;Final TopBar Menu Being Displayed&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;

&lt;div&gt;&amp;nbsp;&lt;/div&gt;
&lt;p&gt;-R. Foreman&lt;/p&gt;
&lt;div&gt;&amp;nbsp;&lt;/div&gt;</content><author><name></name></author><summary type="html">Shell Launch Menus in Gnome3 February 13, 2017 Linux shares some of the same failings as MSWindows, in that it can be difficult to create menus, buttons, and icons for launching programs. Desktop icons in Linux are accomplished by creating a specific file, with a specific extension, containing specific lines of text, and placing it in a specific folder. Icons aren't too difficult. The Gnome Shell uses something called a desktop topbar (similar to the Macintosh), where the accepted approach to customization is via a so-called Shell Extension, and this very nearly requires a Computer Science degree to create one. I will outline my experiences in learning these techniques, and provide a template for creating a shell extension in Gnome3. Debugging Gnome3 Extensions Gnome provides some basic debugging capability through a program called lookingglass. One very useful tool I found to assist in debugging is an extension which opens lookingglass from the topbar, and it also restarts the gnome shell by right-clicking the button. These are two tasks that must be performed over and over as you are building a gnome extension. The utility extension I described here is called LGLoader. When running, the LGLoader button sits in the middle of the topbar, and displays as yellow text. &amp;nbsp; To install this, create a folder here. /root/.local/share/gnome-shell/extensions/lgLoader@zhw2101024 Download all the extension files, and place them into that folder. Open the file metadata.json and add your shell's version number (you can find this by typing gnome-shell --version at a command terminal). &amp;nbsp; Close and save metadata.json , and then restart the gnome shell. The manual way to restart the gnome shell (when you don't have LGLoader available to you) is to type alt-F2 , type the 'r' key, and then hit enter. Once LGLoader is running, you can restart the gnome shell any time by just right-clicking on the button. The final piece to the puzzle is to enable the extension. This can be done with something called the dconf editor (sort of like the registry editor in MSWindows). A far easier way to enable the extension is to install a program called gnome-tweak-tool. &amp;gt; apt-get install gnome-tweak-tool Launch the gnome-tweak-tool from a command line by uttering its name. Navigate to the Extensions tab, and use the button-sliders to enable or disable individual extensions. &amp;nbsp; I found that a small correction to the original code for LGLoader was necessary to make it work properly. To correct the problem code, do the following. Open the file extension.js and find the section of code which appears as follows. //let statusArea = Main.panel.statusArea; for(name in statusArea) { statusEvents[name] = statusArea[name].menu.connect(&amp;#39;open-state-changed&amp;#39;, function(menu, isOpen) { statusArea.lgLoader.actor.can_focus = !isOpen; }); } Replace the above code with the block appearing below. //let statusArea = Main.panel.statusArea; for(name in statusArea) { try { statusEvents[name] = statusArea[name].menu.connect(&amp;#39;open-state-changed&amp;#39;, function(menu, isOpen) { statusArea.lgLoader.actor.can_focus = !isOpen; }); } catch(TypeError) { } } Finally, restart the gnome shell, and the errant behavior will be corrected. I have made this fix and collected the LGLoader files into a single downloadable zip file, which you can find here. LGLoader is a highly useful utility for working with Gnome3 extensions, and is well worth the time taken to set it up. Building a Gnome3 Extension If you begin researching Gnome Shell extensions, you'll find a good deal of information. The documentation I found was spread over such a lengthy timeframe that it not only includes Gnome2 Panel applets (an older technology, from a prior version of Gnome), but it also displays classes and techniques which are either deprecated or have been removed altogether from the shell libraries. In short, the web documentation and help articles are kind of a mess. Rather than go into detail about things I've encountered, I will simply demonstrate the process for creating an extension, and then provide a working code-template for creating a topbar drop-down menu, and how to respond to menu-item clicks. Finally I'll talk briefly about the Gnome Shell libraries, and how to find documentation for the various objects and function calls. The latest and greatest version of Gnome, the Gnome3 Shell, has a web-centric model. That is to say, it relies more heavily on new web-based technologies (such as javascript) than prior versions. As such, the paradigm used to create shell extensions is to build them using javascript. I suppose it's still possible to build a shell extension using an object-code language like C++, but I'm not personally aware of anyone who is doing it that way. The folks behind Gnome Shell have created a small program to build starter extensions, which is invoked like this. &amp;gt; gnome-shell-extension-tool --create-extension You will be prompted for some basic information, such as a name, description, and email address. Then the skeleton is created for you under this folder. /root/.local/share/gnome-shell/extensions/yourextensionname &amp;nbsp; The create script will then open the file extension.js for you, so you may begin editing. You can see quite a lot of example code over at https://extensions.gnome.org (here is one particular example project) , and you'll notice there are just slight differences in how they are set up, structurally. What has happened is that the javascript language has changed over time, and more code constructs have been added to the gnome libraries, allowing more advanced, higher-level functionality. Also, the Gnome Shell extension API has changed over time, so the interface calling convention is different depending on how old the extension is that you're looking at. Here is the code template I arrived at, which I believe represents the most current standard for the Gnome3 extension. const Main = imports.ui.main; const Lang = imports.lang; const PanelMenu = imports.ui.panelMenu; const PopupMenu = imports.ui.popupMenu; const St = imports.gi.St; const Gio = imports.gi.Gio; //const Gtk = imports.gi.Gtk; const GLib = imports.gi.GLib; const Clutter = imports.gi.Clutter; const Shell = imports.gi.Shell; const Util = imports.misc.util; const MyPanelObject= new Lang.Class({ Name: &amp;#39;MyPanelObject&amp;#39;, Extends: PanelMenu.Button, _init: function() { //Call the super-class this.parent(St.Align.START); //Add the label actor this.buttonText = new St.Label({ text: &amp;quot;MyShellExt&amp;quot; }); this.actor.add_actor(this.buttonText); //Add first menu item, with action this.menu.addAction(&amp;quot;First Menu Item&amp;quot;, function(event) { Main.Util.trySpawnCommandLine(&amp;#39;xdg-open https://extensions.gnome.org/&amp;#39;); }); //Add second menu item, with no action this.menu.addMenuItem(new PopupMenu.PopupMenuItem(&amp;quot;Second Menu Item&amp;quot;)); //Add a separator this.menu.addMenuItem(new PopupMenu.PopupSeparatorMenuItem()); //Add a submenu as the 3rd item, and submenu item with no action this.MySubMenu = new PopupMenu.PopupSubMenuMenuItem(&amp;quot;SubMenu&amp;quot;); this.menu.addMenuItem(this.MySubMenu); this.MySubMenu.menu.addMenuItem(new PopupMenu.PopupMenuItem(&amp;quot;submenu value&amp;quot;)); //Add fourth menu item, with action this.menu.addAction(&amp;quot;Gnome Tweak Tool&amp;quot;, function(event) { let bashStr = &amp;quot;bash -c &amp;#39;gnome-tweak-tool;bash&amp;#39;&amp;quot;; Util.spawn([&amp;#39;gnome-terminal&amp;#39;, &amp;#39;--tab&amp;#39;, &amp;#39;--geometry=168x48+74+0&amp;#39;, &amp;#39;--title=MyPC&amp;#39;, &amp;#39;-e&amp;#39;, bashStr, &amp;#39;--working-directory=/bin&amp;#39;]); }); //Add fifth menu item, with action. This works with external function _TermLaunch, but only if you call menuItem.connect separately. let menuItem = new PopupMenu.PopupMenuItem(&amp;quot;Fifth Menu Item&amp;quot;); let myruncmd = &amp;quot;cd /bin; ls -la&amp;quot;; menuItem.connect(&amp;#39;activate&amp;#39;, Lang.bind(this, this._TermLaunch, myruncmd)); this.menu.addMenuItem(menuItem); }, _TermLaunch: function(actor, event, runcmd) { //Util.spawn([&amp;#39;gnome-terminal&amp;#39;, &amp;#39;--tab&amp;#39;, &amp;#39;--geometry=168x48+74+0&amp;#39;, &amp;#39;--title=MyPC&amp;#39;, &amp;#39;-e&amp;#39;, &amp;quot;bash -c &amp;#39;ls -la;bash&amp;#39;&amp;quot;, &amp;#39;--working-directory=/bin&amp;#39;]); Util.spawn([&amp;#39;gnome-terminal&amp;#39;, &amp;#39;--tab&amp;#39;, &amp;#39;--geometry=168x48+74+0&amp;#39;, &amp;#39;--title=MyPC&amp;#39;, &amp;#39;-e&amp;#39;, &amp;quot;bash -c &amp;#39;&amp;quot; + runcmd + &amp;quot;;bash&amp;#39;&amp;quot;, &amp;#39;--working-directory=/bin&amp;#39;]); } }); function init() { } let MyObject; function enable() { MyObject = new MyPanelObject(); Main.panel.addToStatusArea(&amp;#39;SamplePanelButton&amp;#39;, MyObject); } function disable() { if (MyObject) { MyObject.destroy(); MyObject = null; } } init() is called once when the extension is added to the shell. enable() / disable() are called each time the extension is activated or deactivated by the user (for example, in the gnome-tweak-tool). The above example code shows 3 differents ways to launch terminals and run programs. It's a pretty straightforward file once you stop looking at the older variations. This is simple javascript, and about the most difficult task is finding decent documentation for the various objects and functions. You can browse through source code for some of the installed Gnome3 components. For example, the application menu on the topbar is simply an extension located here. /usr/share/gnome-shell/extensions/apps-menu@gnome-shell-extensions.gcampax.github.com Documentation for Gnome3 Extensions With regard to finding documentation for the various classes, global variables, and functions, this is where things get more bizarre and difficult. Part of the Gnome libraries exist as javascript, and part of them are compiled (C or C++) object code. Wherever you see the acronym GJS, you should imagine that code existing as javascript. When you see the term GIR you should imagine XML files which reference C-language functions that are callable from javascript. You'll find a lot of information at the Gnome developer wiki. However much of it doesn't apply to shell extensions, and when you do finally drill down to function and class references which are used by extensions, you'll find they use C-language representation, and often the names are slightly different than what you use in practice. Some of the best information can be gotten from the source code itself. Prior to Gnome 3.12 all the javascript source files were installed on the system as individual files, but after that version these files were wrapped up into a shared library (two or more in fact). Here are two shared libraries that I am aware of which contain this javascript source code. /usr/lib/gnome-shell/libgnome-shell.so /usr/lib/libgjs.so.0 If you wish to extract the source files, I have written a BASH script to do that. Open a terminal and execute this script. #!/bin/sh gs=/usr/lib/gnome-shell/libgnome-shell.so mkdir $HOME/Downloads/gnome-shell-js cd $HOME/Downloads/gnome-shell-js mkdir -p ui/components ui/status misc perf portalHelper extensionPrefs gdm for r in `gresource list $gs`; do gresource extract $gs $r &amp;gt; ${r#/org/gnome/shell/} done gjs=/usr/lib/libgjs.so.0 mkdir -p modules/overrides modules/tweener for r in `gresource list $gjs`; do gresource extract $gjs $r &amp;gt; ${r#/org/gnome/gjs/} done The resulting collection of javascript files will get you maybe 80% of the references you will need to do most common kinds of programming, but it's really difficult for me to say for sure. Much of GLib, GIO, and GObject is still C-language source code. Here is another reference put together a couple years ago, which provides a (nearly complete) set of API references. I'm sure I'll provide more example code over time, but this is enough to put up a topbar menu for launching programs. &amp;nbsp; &amp;nbsp; -R. Foreman &amp;nbsp;</summary></entry><entry><title type="html">Linux Live USB and Clonezilla for Disaster Recovery</title><link href="/posts/2017-2-6-kalilinuxbackup" rel="alternate" type="text/html" title="Linux Live USB and Clonezilla for Disaster Recovery" /><published>2017-02-06T00:00:00-07:00</published><updated>2017-02-06T00:00:00-07:00</updated><id>/posts/kalilinuxbackup</id><content type="html" xml:base="/posts/2017-2-6-kalilinuxbackup">&lt;h2&gt;Kali Linux OS Backup-Restore&lt;/h2&gt;
&lt;h5&gt;February 6, 2017&lt;/h5&gt;
&lt;p class=&quot;lead&quot;&gt;If you play around most operating systems long enough, you will eventually encounter &lt;u&gt;a tragic, irreversible event where your primary boot drive is damaged beyond repair&lt;/u&gt;. It might even be the result of malware, or some other external factor beyond your control. I've had this misfortune a couple times with MSWindows over the years. It usually takes &lt;u&gt;a good deal of time and effort to reinstall the operating system&lt;/u&gt; just to get back to a basic working platform, not to mention that &lt;u&gt;some personal documents may be lost forever&lt;/u&gt; after such an event. After installing Kali Linux recently, I realized it would be fairly simple to set up a process to perform regular backups of the entire boot drive. In this article I will detail the following steps.
	&lt;ol&gt;
		&lt;li&gt;&lt;b&gt;Create a Linux live USB drive&lt;/b&gt;&lt;/li&gt;
		&lt;li&gt;&lt;b&gt;Make the live USB drive persistent&lt;/b&gt; so you can install software on it&lt;/li&gt;
		&lt;li&gt;&lt;b&gt;Install and use Clonezilla&lt;/b&gt; for backup/restore of the boot drive&lt;/li&gt;
		&lt;li&gt;Review &lt;b&gt;the process of backing-up and restoring&lt;/b&gt; a disk drive&lt;/li&gt;
	&lt;/ol&gt;
&lt;/p&gt;

&lt;hr /&gt;

&lt;h3&gt;Writing the Linux Image to USB&lt;/h3&gt;
&lt;p&gt;&lt;a name=&quot;WritingLinuxImageToUSB&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The first step is to download a copy of Kali Linux, and write the live distribution image to a USB disk. The folks at kali.org have a webpage describing this process, &lt;a href=&quot;http://docs.kali.org/downloading/kali-linux-live-usb-install&quot; target=&quot;_blank&quot;&gt;located here&lt;/a&gt;. Their approach involves use of a &lt;u&gt;.img&lt;/u&gt; Kali image, and a program called &lt;u&gt;Win32DiskImager&lt;/u&gt;. The only problem with their approach is that Win32DiskImager only works with .img files (not the more common .iso file) , and the .img Kali image is produced in far less variety than .iso builds are. The particular build I wanted only came as a .iso file, so I had to find another program to perform the USB write. The program I chose is named &lt;u&gt;Rufus&lt;/u&gt;, and it has a &lt;b&gt;good reputation for reliability&lt;/b&gt;.&lt;/p&gt;

&lt;p&gt;First &lt;a href=&quot;https://archive.kali.org/kali-images/kali-weekly/&quot; target=&quot;_blank&quot;&gt;download Kali Linux&lt;/a&gt; (I picked the amd64-bit build, &lt;u&gt;.iso&lt;/u&gt; file). &lt;b&gt;Picking a really recent build at this stage avoids a lengthy software update after applying persistence&lt;/b&gt;. I like the weekly builds here because they provide a SHA1 checksum to verify you got a good download. Next &lt;a href=&quot;http://rufus.akeo.ie/&quot; target=&quot;_blank&quot;&gt;download Rufus image writer&lt;/a&gt;. Rufus doesn't require an installation - just run the executable. Rufus also doesn't require that you preformat the disk. It will recognize an unformatted, unlabelled USB disk and provide them in a list - just pick your USB disk by size (if you don't how big your USB drive is, then you've got other issues). You can give it a label (New Volume Label), but I left everything else as default. You need to select an image to write, using the little disk icon button (I circled this in the image). After selecting your &lt;u&gt;.iso&lt;/u&gt; image, click Start.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/LinuxBackupRecoverImg1.jpg&quot; alt=&quot;Rufus USB Imager Dialog&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;

&lt;p&gt;Before starting, Rufus will prompt you to select an image write mode. &lt;b&gt;It's important to select 'Write in DD Image Mode'&lt;/b&gt;, or else when you boot the USB disk to perform an installation it will go into an infinite loop looking for the CD-drive (and it will never find it because this is a USB disk, not a CD). Click Ok to the next dialog which acknowledges the disk will be overwritten, then let the image writer complete the job, and then close Rufus. The resulting USB stick will be unrecognizable from MSWindows because it has a Linux ext4 partition on it.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/LinuxBackupRecoverImg2.jpg&quot; alt=&quot;Rufus USB Imager, DD Image Mode Selection&quot; /&gt;
&lt;img src=&quot;/images/LinuxBackupRecoverImg3.jpg&quot; alt=&quot;Rufus USB Imager, Performing Image Write&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;

&lt;hr /&gt;

&lt;h3&gt;Kali Live USB, Adding Persistence&lt;/h3&gt;
&lt;p&gt;&lt;a name=&quot;KaliLiveUSBAddPersistence&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Now that you have the USB live (bootable) disk, you can boot into it from a new computer. If you haven't installed Kali Linux to a hard-drive, you should do that next, although I won't be covering that process. To add persistence to the Kali Live USB disk, &lt;u&gt;first boot into a full Kali hard-drive installation&lt;/u&gt; and access the USB stick from there. Once again, the people at kali.org have provided instructions for doing this, &lt;a href=&quot;http://docs.kali.org/downloading/kali-linux-live-usb-persistence&quot; target=&quot;_blank&quot;&gt;located here&lt;/a&gt;. Instead of following those instructions exactly, I took a shortcut by just doing everything within the program gparted, which is a graphical front-end for the parted partition editor.&lt;/p&gt;

&lt;p&gt;My copy of Kali had gparted already installed, but if yours doesn't then it's easy enough to install with the following command.&lt;/p&gt;
&lt;pre&gt;&amp;gt; apt-get install gparted&lt;/pre&gt;

&lt;p&gt;&lt;b&gt;Gparted&lt;/b&gt; can be launched from the &lt;u&gt;topbar Applications menu&lt;/u&gt;, under &lt;u&gt;Usual applications&lt;/u&gt; &amp;#124; &lt;u&gt;System tools&lt;/u&gt; &amp;#124; &lt;u&gt;Administration&lt;/u&gt;. Once it launches you can select the USB device with the drop-down menu (upper-right corner). Right-click the Unallocated space in the USB drive, and select New. Change the filesystem type to ext3 and give it the label of '&lt;b&gt;persistence&lt;/b&gt;', and click Ok. Now click the green checkmark button in the menubar to apply the changes. After the new partition is created, close out of gparted.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/LinuxBackupRecoverImg4.jpg&quot; alt=&quot;GParted Application Launch&quot; /&gt;
&lt;img src=&quot;/images/LinuxBackupRecoverImg5.jpg&quot; alt=&quot;GParted Image1&quot; /&gt;
&lt;img src=&quot;/images/LinuxBackupRecoverImg6.jpg&quot; alt=&quot;GParted Image2&quot; /&gt;
&lt;img src=&quot;/images/LinuxBackupRecoverImg7.jpg&quot; alt=&quot;GParted Image3&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;

&lt;p&gt;Rather than try to fiddle with mounting the new partition, I found it easier just to &lt;u&gt;reboot and let the system mount it for me&lt;/u&gt;. Once I reboot, the persistence partition appears as an icon on my Kali desktop, and I can open it in the file browser just by double-clicking on the icon. Once it opens in the Nautilus file browser, I right-click and open a terminal, for the purpose of creating a single file in the partition. When the terminal opens, enter the following command.&lt;/p&gt;
&lt;pre&gt;&amp;gt; echo &quot;/ union&quot; &amp;gt; ./persistence.conf&lt;/pre&gt;

&lt;p&gt;That's it. Close the terminal, close the file browser, and reboot into the Kali Live USB device. Since it now has persistence, it's now possible to install software and have it saved to the disk. To boot into the Kali Live USB disk, at your computer boot menu you should &lt;u&gt;select the 2nd partition on the Live USB stick&lt;/u&gt; (where the GRUB menu is at), then when the GRUB menu appears &lt;u&gt;select the 'Live USB with Persistence' option&lt;/u&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/LinuxBackupRecoverImg8.jpg&quot; alt=&quot;GRUB Boot Menu, Select Kali Live Persistence&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;

&lt;hr /&gt;

&lt;h3&gt;Backup-Restore Using Clonezilla&lt;/h3&gt;
&lt;p&gt;&lt;a name=&quot;BackupRestoreWithClonezilla&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Once you are booted into your Kali Live USB Gnome3 desktop, the first task with any new system is to perform software updates, with the following commands.&lt;/p&gt;
&lt;pre&gt;&amp;gt; apt-get update
&amp;gt; apt-get upgrade
&amp;gt; apt-get dist-upgrade
&amp;gt; apt-get autoremove
&lt;/pre&gt;

&lt;p&gt;If you chose a recent build of Kali, then this step will be a very short process (less than 5 minutes). &lt;b&gt;Clonezilla&lt;/b&gt; is an easy installation, with this next command.&lt;/p&gt;
&lt;pre&gt;&amp;gt; apt-get install clonezilla&lt;/pre&gt;

&lt;p&gt;I have a couple platter-based Western Digital Velociraptors installed in this computer, so my plan was to store the backup images on one of these. In my experience with &lt;b&gt;disk-drive calamities&lt;/b&gt;, the tragedy always occurs with boot drives, and essentially never happens to secondary storage drives. &lt;/p&gt;

&lt;hr /&gt;

&lt;h4&gt;&lt;u&gt;Performing the Backup&lt;/u&gt;&lt;/h4&gt;
&lt;p&gt;&lt;a name=&quot;PerformingTheBackup&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Clonezilla&lt;/b&gt; is a &lt;u&gt;text-based program&lt;/u&gt; (using a development library called ncurses), so you launch it from a terminal just by typing its name 'clonezilla', and &lt;u&gt;navigate around using tabs, arrows, and the space key&lt;/u&gt;. This is a very easy program to use, so I won't go through a lot of detail here. Of course we're cloning from disk to an image file, and you select the disk you wish to image as well as a save location. For nearly every option I was choosing the default, so for me this process was a sequence of enter keys. At one point Clonezilla needs to identify the likely places to store the backup, and &lt;b&gt;if one of your drives is not being recognized, then you have to make sure to dismount them&lt;/b&gt; (see next image).&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/LinuxBackupRecoverImg9.jpg&quot; alt=&quot;Nautilus File Manager, Unmounting a Volume&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;

&lt;p&gt;The actual backup went very quickly. On a 205 Gigabyte SSD with 17 Gigabyte being used, it took just under 4 minutes, and the resulting set of backup files comprised about 6.5 Gigabyte of data. During the process, &lt;b&gt;Clonezilla&lt;/b&gt; mounted the volume where data was to be saved, at the following location.&lt;/p&gt;
&lt;pre&gt;/home/partimag/backupname&lt;/pre&gt;

&lt;p&gt;Afte completion I unmounted this using &lt;b&gt;GParted&lt;/b&gt;, and the disk volume was immediately viewable in &lt;b&gt;Nautilus&lt;/b&gt;, containing the backup folder with all its data. I performed a full-disk backup, so all partitions on the disk were saved, however it is possible to perform the backup on a single partition. Clonezilla also offered to check the data to determine if a restore could be performed, and this was successful. I also learned during this process that I can back up a MSWindows system just as easily, although I haven't tried this.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/LinuxBackupRecoverImg10.jpg&quot; alt=&quot;Clonezilla, Selecting Backup Location&quot; /&gt;
&lt;img src=&quot;/images/LinuxBackupRecoverImg11.jpg&quot; alt=&quot;Clonezilla, Operation to Perform&quot; /&gt;
&lt;img src=&quot;/images/LinuxBackupRecoverImg12.jpg&quot; alt=&quot;Clonezilla, Selecting Disk to Backup&quot; /&gt;
&lt;img src=&quot;/images/LinuxBackupRecoverImg13.jpg&quot; alt=&quot;Clonezilla, Backing up Partition&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;

&lt;hr /&gt;

&lt;h4&gt;&lt;u&gt;Restoring Backed-Up Data to Disk&lt;/u&gt;&lt;/h4&gt;
&lt;p&gt;&lt;a name=&quot;RestoringBackupToDisk&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;This procedure wouldn't be complete without testing to see if I could restore from the saved data, and successfully boot into the restored disk. Booted into the Kali Live USB environment, I used &lt;b&gt;GParted&lt;/b&gt; to delete all partitions on the disk that I had backed up. Next I used &lt;b&gt;Clonezilla&lt;/b&gt; to restore the disk partitions using the backed up data. I then rebooted into the SSD which had just been restored, and this all occurred without any errors. At this point I'm satisfied that my Kali Live USB with persistence can be used to recover from boot drive disaster.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/LinuxBackupRecoverImg14.jpg&quot; alt=&quot;Clonezilla, Operation to Perform&quot; /&gt;
&lt;img src=&quot;/images/LinuxBackupRecoverImg15.jpg&quot; alt=&quot;Clonezilla, Selecting Data to Restore From&quot; /&gt;
&lt;img src=&quot;/images/LinuxBackupRecoverImg16.jpg&quot; alt=&quot;Clonezilla, Select Disk to Restore To&quot; /&gt;&lt;/p&gt;

&lt;div&gt;&amp;nbsp;&lt;/div&gt;
&lt;p&gt;-R. Foreman&lt;/p&gt;
&lt;div&gt;&amp;nbsp;&lt;/div&gt;</content><author><name></name></author><summary type="html">Kali Linux OS Backup-Restore February 6, 2017 If you play around most operating systems long enough, you will eventually encounter a tragic, irreversible event where your primary boot drive is damaged beyond repair. It might even be the result of malware, or some other external factor beyond your control. I've had this misfortune a couple times with MSWindows over the years. It usually takes a good deal of time and effort to reinstall the operating system just to get back to a basic working platform, not to mention that some personal documents may be lost forever after such an event. After installing Kali Linux recently, I realized it would be fairly simple to set up a process to perform regular backups of the entire boot drive. In this article I will detail the following steps. Create a Linux live USB drive Make the live USB drive persistent so you can install software on it Install and use Clonezilla for backup/restore of the boot drive Review the process of backing-up and restoring a disk drive Writing the Linux Image to USB The first step is to download a copy of Kali Linux, and write the live distribution image to a USB disk. The folks at kali.org have a webpage describing this process, located here. Their approach involves use of a .img Kali image, and a program called Win32DiskImager. The only problem with their approach is that Win32DiskImager only works with .img files (not the more common .iso file) , and the .img Kali image is produced in far less variety than .iso builds are. The particular build I wanted only came as a .iso file, so I had to find another program to perform the USB write. The program I chose is named Rufus, and it has a good reputation for reliability. First download Kali Linux (I picked the amd64-bit build, .iso file). Picking a really recent build at this stage avoids a lengthy software update after applying persistence. I like the weekly builds here because they provide a SHA1 checksum to verify you got a good download. Next download Rufus image writer. Rufus doesn't require an installation - just run the executable. Rufus also doesn't require that you preformat the disk. It will recognize an unformatted, unlabelled USB disk and provide them in a list - just pick your USB disk by size (if you don't how big your USB drive is, then you've got other issues). You can give it a label (New Volume Label), but I left everything else as default. You need to select an image to write, using the little disk icon button (I circled this in the image). After selecting your .iso image, click Start. &amp;nbsp; Before starting, Rufus will prompt you to select an image write mode. It's important to select 'Write in DD Image Mode', or else when you boot the USB disk to perform an installation it will go into an infinite loop looking for the CD-drive (and it will never find it because this is a USB disk, not a CD). Click Ok to the next dialog which acknowledges the disk will be overwritten, then let the image writer complete the job, and then close Rufus. The resulting USB stick will be unrecognizable from MSWindows because it has a Linux ext4 partition on it. &amp;nbsp; Kali Live USB, Adding Persistence Now that you have the USB live (bootable) disk, you can boot into it from a new computer. If you haven't installed Kali Linux to a hard-drive, you should do that next, although I won't be covering that process. To add persistence to the Kali Live USB disk, first boot into a full Kali hard-drive installation and access the USB stick from there. Once again, the people at kali.org have provided instructions for doing this, located here. Instead of following those instructions exactly, I took a shortcut by just doing everything within the program gparted, which is a graphical front-end for the parted partition editor. My copy of Kali had gparted already installed, but if yours doesn't then it's easy enough to install with the following command. &amp;gt; apt-get install gparted Gparted can be launched from the topbar Applications menu, under Usual applications &amp;#124; System tools &amp;#124; Administration. Once it launches you can select the USB device with the drop-down menu (upper-right corner). Right-click the Unallocated space in the USB drive, and select New. Change the filesystem type to ext3 and give it the label of 'persistence', and click Ok. Now click the green checkmark button in the menubar to apply the changes. After the new partition is created, close out of gparted. &amp;nbsp; Rather than try to fiddle with mounting the new partition, I found it easier just to reboot and let the system mount it for me. Once I reboot, the persistence partition appears as an icon on my Kali desktop, and I can open it in the file browser just by double-clicking on the icon. Once it opens in the Nautilus file browser, I right-click and open a terminal, for the purpose of creating a single file in the partition. When the terminal opens, enter the following command. &amp;gt; echo &quot;/ union&quot; &amp;gt; ./persistence.conf That's it. Close the terminal, close the file browser, and reboot into the Kali Live USB device. Since it now has persistence, it's now possible to install software and have it saved to the disk. To boot into the Kali Live USB disk, at your computer boot menu you should select the 2nd partition on the Live USB stick (where the GRUB menu is at), then when the GRUB menu appears select the 'Live USB with Persistence' option. &amp;nbsp; Backup-Restore Using Clonezilla Once you are booted into your Kali Live USB Gnome3 desktop, the first task with any new system is to perform software updates, with the following commands. &amp;gt; apt-get update &amp;gt; apt-get upgrade &amp;gt; apt-get dist-upgrade &amp;gt; apt-get autoremove If you chose a recent build of Kali, then this step will be a very short process (less than 5 minutes). Clonezilla is an easy installation, with this next command. &amp;gt; apt-get install clonezilla I have a couple platter-based Western Digital Velociraptors installed in this computer, so my plan was to store the backup images on one of these. In my experience with disk-drive calamities, the tragedy always occurs with boot drives, and essentially never happens to secondary storage drives. Performing the Backup Clonezilla is a text-based program (using a development library called ncurses), so you launch it from a terminal just by typing its name 'clonezilla', and navigate around using tabs, arrows, and the space key. This is a very easy program to use, so I won't go through a lot of detail here. Of course we're cloning from disk to an image file, and you select the disk you wish to image as well as a save location. For nearly every option I was choosing the default, so for me this process was a sequence of enter keys. At one point Clonezilla needs to identify the likely places to store the backup, and if one of your drives is not being recognized, then you have to make sure to dismount them (see next image). &amp;nbsp; The actual backup went very quickly. On a 205 Gigabyte SSD with 17 Gigabyte being used, it took just under 4 minutes, and the resulting set of backup files comprised about 6.5 Gigabyte of data. During the process, Clonezilla mounted the volume where data was to be saved, at the following location. /home/partimag/backupname Afte completion I unmounted this using GParted, and the disk volume was immediately viewable in Nautilus, containing the backup folder with all its data. I performed a full-disk backup, so all partitions on the disk were saved, however it is possible to perform the backup on a single partition. Clonezilla also offered to check the data to determine if a restore could be performed, and this was successful. I also learned during this process that I can back up a MSWindows system just as easily, although I haven't tried this. &amp;nbsp; Restoring Backed-Up Data to Disk This procedure wouldn't be complete without testing to see if I could restore from the saved data, and successfully boot into the restored disk. Booted into the Kali Live USB environment, I used GParted to delete all partitions on the disk that I had backed up. Next I used Clonezilla to restore the disk partitions using the backed up data. I then rebooted into the SSD which had just been restored, and this all occurred without any errors. At this point I'm satisfied that my Kali Live USB with persistence can be used to recover from boot drive disaster. &amp;nbsp; -R. Foreman &amp;nbsp;</summary></entry><entry><title type="html">ESP8266 Microcontroller, Getting Started</title><link href="/posts/2017-1-30-esp8266-post1" rel="alternate" type="text/html" title="ESP8266 Microcontroller, Getting Started" /><published>2017-01-30T00:00:00-07:00</published><updated>2017-01-30T00:00:00-07:00</updated><id>/posts/esp8266_post1</id><content type="html" xml:base="/posts/2017-1-30-esp8266-post1">&lt;h2&gt;ESP8266 Microcontroller Board with PlatformIO&lt;/h2&gt;
&lt;h5&gt;January 30, 2017&lt;/h5&gt;
&lt;p class=&quot;lead&quot;&gt;One of the hottest microcontroller boards I've read about recently is the ESP8266. The reason it's popular is that it has a built-in full TCP/IP stack, along with a wifi antenna onboard. Also there is enough interest and awareness that it is programmable in several languages, including the Arduino API. I've seen several articles and videos on the ESP8266 recently, &lt;a href=&quot;https://www.youtube.com/watch?v=AEQCABQGZNw#t=13m45s&quot; target=&quot;_blank&quot;&gt;such as this one&lt;/a&gt;, and it definitely caught my interest. After briefly researching this online, I went ahead and purchased a recent incarnation of the ESP8266, &lt;a href=&quot;https://www.adafruit.com/product/2821&quot; target=&quot;_blank&quot;&gt;the Adafruit Huzzah&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;I'll give a little background and details for this chip before I relay my experiences on how to program it. There is a lot to like about the ESP8266, but early boards didn't have any voltage regulation, so people were frying the board as a first order of business when they received it (lol.. read some of &lt;a href=&quot;https://www.sparkfun.com/products/13678&quot; target=&quot;_blank&quot;&gt;the comments on this page&lt;/a&gt;). Adafruit came along and fixed that with the Huzzah, by adding a voltage regulator circuit. They also added a JST-PH port for mobile battery power, and the micro-USB connector will also charge any LiPo battery you have plugged in. This model also has the latest serial chip, the CP2104, for high-speed data uploads, as well as more flash memory (4Mb) than previous boards. Upcoming incarnations might even see onboard SD cards, and I think adding mass storage would be a smart direction to move since there currently is no device like this at such a small scale and price-point.&lt;/p&gt;

&lt;hr /&gt;

&lt;h3&gt;ESP8266 Development Frameworks&lt;/h3&gt;
&lt;p&gt;&lt;a name=&quot;ESP8266DevFrameworks&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The &lt;u&gt;ESP8266&lt;/u&gt; chip is made by a company called Espressif, and of course they put out an SDK, as well as examples of programming their device. You can download and read through some of their &lt;a href=&quot;https://espressif.com/en/support/download/sdks-demos&quot; target=&quot;_blank&quot;&gt;example code here&lt;/a&gt; , and &lt;a href=&quot;https://github.com/espressif/ESP8266_RTOS_SDK&quot; target=&quot;_blank&quot;&gt;here as well&lt;/a&gt;. The Espressif native code library appears (to me) somewhat unfriendly and difficult to follow for the average user. It's basic C-language code, but definitely not user-friendly. Some Russian guy with an outfit called MicrocontrollerKits put together &lt;a href=&quot;http://microcontrollerkits.blogspot.com/2015/12/esp8266-eclipse-development.html&quot; target=&quot;_blank&quot;&gt;a setup for the Eclipse IDE&lt;/a&gt;. This is basically the Espressif native code library, using MinGW gcc toolchains, and packaged into a series of Eclipse projects for C/C++. This appears to work, but in the end you're still looking at the same Espressif code which uses function and variable names that are not very descriptive, and hence the whole approach is difficult to work with. Here is the &lt;a href=&quot;https://www.youtube.com/watch?v=tYU1O3mk3Yg&quot; target=&quot;_blank&quot;&gt;video describing this package&lt;/a&gt; in case anyone is interested.&lt;/p&gt;

&lt;p&gt;You may have already noticed that Adafruit makes available a programming environment called &lt;u&gt;microPython&lt;/u&gt; which can be used with the Huzzah board. From what I can tell it is basically Python language with the Arduino API, and I'm sure it's easy to use, although this was not the avenue I pursued. One thing that is also sure is that Python will not run as fast as C compiled object-code running on the microcontroller, and speed could be an issue on such a low-power device. There is another organization out there whose purpose is to make programming the whole ecosystem of microcontrollers much easier for the average user, and this initiative is called &lt;b&gt;PlatformIO&lt;/b&gt;.&lt;/p&gt;

&lt;hr /&gt;

&lt;h3&gt;ESP8266 Development Tools, PlatformIO and Visual Studio&lt;/h3&gt;
&lt;p&gt;&lt;a name=&quot;ESP8266DevTools&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The PlatformIO website is platformio.org , and to get started you should follow &lt;a href=&quot;http://docs.platformio.org/en/latest/ide/atom.html#installation&quot; target=&quot;_blank&quot;&gt;their installation guide&lt;/a&gt; as I did. The setup requires the following 3 packages.

&lt;ul style=&quot;list-style-type: none;&quot;&gt;
	&lt;li&gt;Some 2.7xx version of Python&lt;/li&gt;
	&lt;li&gt;CLang, aka LLVM (low-level Virtual Machine)&lt;/li&gt;
	&lt;li&gt;The PlatformIO IDE. It's basically a plugin for the Atom text-editor&lt;/li&gt;
&lt;/ul&gt;
Here is &lt;a href=&quot;https://atom.io/packages/platformio-ide&quot; target=&quot;_blank&quot;&gt;more background on PlatformIO&lt;/a&gt;. The PlatformIO IDE requires that Python be on your system path, so you may need a reboot after installing Python and before doing the PlatformIO install. The only link you need to start PlaformIO is one that looks like this.&lt;/p&gt;
&lt;pre&gt;&amp;gt; C:\Users\YourUserName\AppData\Local\atom\app-1.13.0\atom.exe&lt;/pre&gt;

&lt;p&gt;&lt;img src=&quot;/images/ESP8266Post1Img1.jpg&quot; alt=&quot;PlatformIO Startup Window&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;

&lt;p&gt;Of course substitute whatever is your current version of atom in the above shortcut link (and also use your own username). When you launch PlatformIO it will automatically update the installed plugins and packages. If the &lt;b&gt;PlatformIO Core&lt;/b&gt; doesn't update correctly, you can do it by downloading the file&lt;/p&gt;
&lt;pre&gt;https://raw.githubusercontent.com/platformio/platformio/master/scripts/get-platformio.py&lt;/pre&gt;

&lt;p&gt;into your Python directory, and then running the command&lt;/p&gt;
&lt;pre&gt;&amp;gt; python get-platformio.py&lt;/pre&gt;

&lt;p&gt;PlatformIO still has a few kinks to work out, but at the 30,000-ft view this is by far the &lt;u&gt;easiest&lt;/u&gt; and &lt;u&gt;best way&lt;/u&gt; to program these microcontroller boards. The remainder of the &lt;a href=&quot;http://docs.platformio.org/en/latest/ide/atom.html#installation&quot; target=&quot;_blank&quot;&gt;installation guide&lt;/a&gt; gives good details on navigating the Atom user interface, as well as the PlatformIO plugin. &lt;b&gt;What's important to know&lt;/b&gt; is that the PlatformIO IDE is good for managing code packages, as well as flashing your microcontroller board, but the programming editor is not that great. I looked around to find the best way to actually work with the Arduino API C-language code, and for MSWindows it turns out the community version of &lt;u&gt;Microsoft Visual Studio&lt;/u&gt; works the best.&lt;/p&gt;

&lt;p&gt;Here are the &lt;a href=&quot;http://docs.platformio.org/en/latest/ide/visualstudio.html&quot; target=&quot;_blank&quot;&gt;instructions for installing Visual Studio&lt;/a&gt;. When the instructions talk about adding &lt;b&gt;platformio&lt;/b&gt; to your path, what they're referring to is the file &lt;em&gt;pio.exe&lt;/em&gt; located in your &lt;u&gt;python2.7xx/scripts&lt;/u&gt; directory (this should already be on your path from when you installed Python). Visual Studio gives you &lt;u&gt;Syntax Highlighting&lt;/u&gt;, &lt;u&gt;Code-folding&lt;/u&gt;, &lt;u&gt;Intellisense&lt;/u&gt;, and a number of other very useful tools. For example, you can generate a header dependency graph (in case you can't figure out where certain variables or functions are coming from) just by placing your cursor on a include-file name, then right-clicking and selecting 'Generate Graph of Include Files'. For anyone who is REALLY new to this, Intellisense is like a database of functions, variables, types, and objects that the editor 'knows about'. You can do things like hover your mouse over some piece of code and get information about it, and it will also provide a list of options when you start typing.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/ESP8266Post1Img2.jpg&quot; alt=&quot;Visual Studio, Generate Graph of Include Files&quot; /&gt;
&lt;img src=&quot;/images/ESP8266Post1Img3.jpg&quot; alt=&quot;Header Files Dependency Graph&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;

&lt;p&gt;These tools become more important as you start to deal with multiple libraries, including the Arduino API library itself, since it's not always clear where certain functions and variables are coming from. For all the bad things people say about Microsoft, one thing they have become very good at is programming languages and compilers, and Visual Studio is one of the best C/C++ development environments out there. Fortunately for us it's free now, because they used to charge thousands of dollars for it.&lt;/p&gt;

&lt;p&gt;When you use PlatformIO, it installs all the necessary code files in order to program your board. It's not necessary to install the Arduino IDE, since the Arduino API files are all provided for you by PlatformIO. You can create your projects from within the PlatformIO IDE (the graphical interface program), but I've found that it's just as easy to do it from a command-line. First create a directory, then open a command prompt (a DOS box) within that directory and issue a command like this.&lt;/p&gt;
&lt;pre&gt;&amp;gt; platformio init --ide visualstudio --board huzzah&lt;/pre&gt;

&lt;p&gt;In the above command, platformio is an executable that was installed inside your &lt;u&gt;python2.7xx/scripts&lt;/u&gt; directory when you installed PlatformIO (that's why having Python on your system path was important when you installed PlatformIO). The above command tells PlatformIO to create a project for the Huzzah board and the Visual Studio IDE. You can find your board's Id by looking &lt;a href=&quot;http://platformio.org/boards&quot; target=&quot;_blank&quot;&gt;on this page&lt;/a&gt;. Also, pio is a shorthand alias for platformio, so the following is an equivalent command.&lt;/p&gt;
&lt;pre&gt;&amp;gt; pio init --ide visualstudio --board huzzah&lt;/pre&gt;

&lt;p&gt;When you create a PlatformIO project like this, it places all the support files in the following location.&lt;/p&gt;
&lt;pre&gt;&amp;gt; C:\Users\YourUserName\.platformio\packages\&lt;/pre&gt;

&lt;p&gt;Any libraries you add to the project are also placed in the same location. After creating your PlatformIO project, assuming you have Visual Studio installed, you can open the project in Visual Studio just by double-clicking on the &lt;u&gt;.vcxproj&lt;/u&gt; file from Windows Explorer.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/ESP8266Post1Img4.jpg&quot; alt=&quot;Command-line Build of PlatformIO Project&quot; /&gt;
&lt;img src=&quot;/images/ESP8266Post1Img5.jpg&quot; alt=&quot;PlatformIO Project Files, Viewed from Windows Explorer&quot; /&gt;
&lt;img src=&quot;/images/ESP8266Post1Img6.jpg&quot; alt=&quot;Visual Studio Interface, with PlatformIO Project Open&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;

&lt;hr /&gt;

&lt;h3&gt;ESP8266 Flash and Code Execution&lt;/h3&gt;
&lt;p&gt;&lt;a name=&quot;FlashAndExecute&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Eventually I plan to explore advanced capabilities of the ESP8266, but for this first blog-post I'm going to keep it very simple. After inspection of &lt;a href=&quot;https://learn.adafruit.com/adafruit-feather-huzzah-esp8266/pinouts&quot; target=&quot;_blank&quot;&gt;the Huzzah pin-out here&lt;/a&gt;, I determined that pins 0 and 2 are connected to onboard Red and Blue LEDs, respectively, so I decided to use this for my initial testing. There is ample source-code in the public domain which show how to blink an LED using the Arduino API, so I worked up the following sample to blink the two LEDs in sequence.&lt;/p&gt;
&lt;pre&gt;
&lt;span class=&quot;k&quot;&gt;/**&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt; * Blink&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt; * Turns Red LED on for 1/2 second, then off.&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt; * Then turns Blue on for 1/2 second, then off. Repeats.&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt; */&lt;/span&gt;
&lt;span class=&quot;kp&quot;&gt;#include&lt;/span&gt; &amp;quot;Arduino.h&amp;quot;
&lt;span class=&quot;kp&quot;&gt;#define&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;RedPin&lt;/span&gt;    &lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;  &lt;span class=&quot;k&quot;&gt;// Connected to a Red LED&lt;/span&gt;
&lt;span class=&quot;kp&quot;&gt;#define&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;BluePin&lt;/span&gt;    &lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;  &lt;span class=&quot;k&quot;&gt;// Connected to a Blue LED&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;setup&lt;/span&gt;()
{
  &lt;span class=&quot;k&quot;&gt;// initialize LED digital pin as an output.&lt;/span&gt;
  pinMode(&lt;span class=&quot;no&quot;&gt;RedPin&lt;/span&gt;, &lt;span class=&quot;no&quot;&gt;OUTPUT&lt;/span&gt;);
  pinMode(&lt;span class=&quot;no&quot;&gt;BluePin&lt;/span&gt;, &lt;span class=&quot;no&quot;&gt;OUTPUT&lt;/span&gt;);
}

&lt;span class=&quot;k&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;loop&lt;/span&gt;()
{
  &lt;span class=&quot;k&quot;&gt;// turn Red LED on (HIGH is the voltage level)&lt;/span&gt;
  digitalWrite(&lt;span class=&quot;no&quot;&gt;RedPin&lt;/span&gt;, &lt;span class=&quot;no&quot;&gt;HIGH&lt;/span&gt;);
  &lt;span class=&quot;k&quot;&gt;// wait for half a second&lt;/span&gt;
  delay(&lt;span class=&quot;m&quot;&gt;500&lt;/span&gt;);
  &lt;span class=&quot;k&quot;&gt;// turn Red LED off by making the voltage LOW&lt;/span&gt;
  digitalWrite(&lt;span class=&quot;no&quot;&gt;RedPin&lt;/span&gt;, &lt;span class=&quot;no&quot;&gt;LOW&lt;/span&gt;);
  &lt;span class=&quot;k&quot;&gt;// turn Blue LED on (HIGH is the voltage level)&lt;/span&gt;
  digitalWrite(&lt;span class=&quot;no&quot;&gt;BluePin&lt;/span&gt;, &lt;span class=&quot;no&quot;&gt;HIGH&lt;/span&gt;);
   &lt;span class=&quot;k&quot;&gt;// wait for half a second&lt;/span&gt;
  delay(&lt;span class=&quot;m&quot;&gt;500&lt;/span&gt;);
  &lt;span class=&quot;k&quot;&gt;// turn Blue LED off by making the voltage LOW&lt;/span&gt;
  digitalWrite(&lt;span class=&quot;no&quot;&gt;BluePin&lt;/span&gt;, &lt;span class=&quot;no&quot;&gt;LOW&lt;/span&gt;);
}
&lt;/pre&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;

&lt;p&gt;Building the project from Visual Studio is as simple as right-clicking on the project name, and selecting Build.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/ESP8266Post1Img7.jpg&quot; alt=&quot;Visual Studio Interface, Building the Project&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;

&lt;p&gt;You can also build the project from the PlatformIO IDE, by clicking the Build button along the left-hand toolbar.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/ESP8266Post1Img8.jpg&quot; alt=&quot;PlatformIO Interface, Building the Project&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;

&lt;p&gt;With regard to &lt;u&gt;flashing the device&lt;/u&gt;, in order to communicate over USB you need to install one particular USB driver on your computer, which &lt;a href=&quot;https://www.silabs.com/products/mcu/Pages/USBtoUARTBridgeVCPDrivers.aspx&quot; target=&quot;_blank&quot;&gt;you can download here&lt;/a&gt;. Now when you plug your Adafruit Huzzah into the computer, a COM device should appear in the Device Manager.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/ESP8266Post1Img9.jpg&quot; alt=&quot;Windows7 Device Manager, Communications Device&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;

&lt;p&gt;Flashing your compiled code to the ESP8266 board is as simple as clicking the Upload button on the left-hand toolbar within the PlatformIO IDE.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/ESP8266Post1Img10.jpg&quot; alt=&quot;PlatformIO IDE, Upload Button&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;

&lt;p&gt;You'll see some text scroll by at the bottom of the IDE, and then the box may disappear. This is the default setting, that the 'Build Panel' closes automatically after completing, and it can be changed within the Packages settings. After the build completes, the microcontroller should start to perform the actions ascribed to it within the program. If yours doesn't, then try the flash again, and possibly power it off and on (with the USB connector). Here is an short animation of what it will look like when it runs correctly.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/ESP8266Post1Gif1.gif&quot; alt=&quot;Adafruit Huzzah, Program Executing&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;

&lt;div&gt;&amp;nbsp;&lt;/div&gt;
&lt;p&gt;-R. Foreman&lt;/p&gt;
&lt;div&gt;&amp;nbsp;&lt;/div&gt;</content><author><name></name></author><summary type="html">ESP8266 Microcontroller Board with PlatformIO January 30, 2017 One of the hottest microcontroller boards I've read about recently is the ESP8266. The reason it's popular is that it has a built-in full TCP/IP stack, along with a wifi antenna onboard. Also there is enough interest and awareness that it is programmable in several languages, including the Arduino API. I've seen several articles and videos on the ESP8266 recently, such as this one, and it definitely caught my interest. After briefly researching this online, I went ahead and purchased a recent incarnation of the ESP8266, the Adafruit Huzzah. I'll give a little background and details for this chip before I relay my experiences on how to program it. There is a lot to like about the ESP8266, but early boards didn't have any voltage regulation, so people were frying the board as a first order of business when they received it (lol.. read some of the comments on this page). Adafruit came along and fixed that with the Huzzah, by adding a voltage regulator circuit. They also added a JST-PH port for mobile battery power, and the micro-USB connector will also charge any LiPo battery you have plugged in. This model also has the latest serial chip, the CP2104, for high-speed data uploads, as well as more flash memory (4Mb) than previous boards. Upcoming incarnations might even see onboard SD cards, and I think adding mass storage would be a smart direction to move since there currently is no device like this at such a small scale and price-point. ESP8266 Development Frameworks The ESP8266 chip is made by a company called Espressif, and of course they put out an SDK, as well as examples of programming their device. You can download and read through some of their example code here , and here as well. The Espressif native code library appears (to me) somewhat unfriendly and difficult to follow for the average user. It's basic C-language code, but definitely not user-friendly. Some Russian guy with an outfit called MicrocontrollerKits put together a setup for the Eclipse IDE. This is basically the Espressif native code library, using MinGW gcc toolchains, and packaged into a series of Eclipse projects for C/C++. This appears to work, but in the end you're still looking at the same Espressif code which uses function and variable names that are not very descriptive, and hence the whole approach is difficult to work with. Here is the video describing this package in case anyone is interested. You may have already noticed that Adafruit makes available a programming environment called microPython which can be used with the Huzzah board. From what I can tell it is basically Python language with the Arduino API, and I'm sure it's easy to use, although this was not the avenue I pursued. One thing that is also sure is that Python will not run as fast as C compiled object-code running on the microcontroller, and speed could be an issue on such a low-power device. There is another organization out there whose purpose is to make programming the whole ecosystem of microcontrollers much easier for the average user, and this initiative is called PlatformIO. ESP8266 Development Tools, PlatformIO and Visual Studio The PlatformIO website is platformio.org , and to get started you should follow their installation guide as I did. The setup requires the following 3 packages. Some 2.7xx version of Python CLang, aka LLVM (low-level Virtual Machine) The PlatformIO IDE. It's basically a plugin for the Atom text-editor Here is more background on PlatformIO. The PlatformIO IDE requires that Python be on your system path, so you may need a reboot after installing Python and before doing the PlatformIO install. The only link you need to start PlaformIO is one that looks like this. &amp;gt; C:\Users\YourUserName\AppData\Local\atom\app-1.13.0\atom.exe &amp;nbsp; Of course substitute whatever is your current version of atom in the above shortcut link (and also use your own username). When you launch PlatformIO it will automatically update the installed plugins and packages. If the PlatformIO Core doesn't update correctly, you can do it by downloading the file https://raw.githubusercontent.com/platformio/platformio/master/scripts/get-platformio.py into your Python directory, and then running the command &amp;gt; python get-platformio.py PlatformIO still has a few kinks to work out, but at the 30,000-ft view this is by far the easiest and best way to program these microcontroller boards. The remainder of the installation guide gives good details on navigating the Atom user interface, as well as the PlatformIO plugin. What's important to know is that the PlatformIO IDE is good for managing code packages, as well as flashing your microcontroller board, but the programming editor is not that great. I looked around to find the best way to actually work with the Arduino API C-language code, and for MSWindows it turns out the community version of Microsoft Visual Studio works the best. Here are the instructions for installing Visual Studio. When the instructions talk about adding platformio to your path, what they're referring to is the file pio.exe located in your python2.7xx/scripts directory (this should already be on your path from when you installed Python). Visual Studio gives you Syntax Highlighting, Code-folding, Intellisense, and a number of other very useful tools. For example, you can generate a header dependency graph (in case you can't figure out where certain variables or functions are coming from) just by placing your cursor on a include-file name, then right-clicking and selecting 'Generate Graph of Include Files'. For anyone who is REALLY new to this, Intellisense is like a database of functions, variables, types, and objects that the editor 'knows about'. You can do things like hover your mouse over some piece of code and get information about it, and it will also provide a list of options when you start typing. &amp;nbsp; These tools become more important as you start to deal with multiple libraries, including the Arduino API library itself, since it's not always clear where certain functions and variables are coming from. For all the bad things people say about Microsoft, one thing they have become very good at is programming languages and compilers, and Visual Studio is one of the best C/C++ development environments out there. Fortunately for us it's free now, because they used to charge thousands of dollars for it. When you use PlatformIO, it installs all the necessary code files in order to program your board. It's not necessary to install the Arduino IDE, since the Arduino API files are all provided for you by PlatformIO. You can create your projects from within the PlatformIO IDE (the graphical interface program), but I've found that it's just as easy to do it from a command-line. First create a directory, then open a command prompt (a DOS box) within that directory and issue a command like this. &amp;gt; platformio init --ide visualstudio --board huzzah In the above command, platformio is an executable that was installed inside your python2.7xx/scripts directory when you installed PlatformIO (that's why having Python on your system path was important when you installed PlatformIO). The above command tells PlatformIO to create a project for the Huzzah board and the Visual Studio IDE. You can find your board's Id by looking on this page. Also, pio is a shorthand alias for platformio, so the following is an equivalent command. &amp;gt; pio init --ide visualstudio --board huzzah When you create a PlatformIO project like this, it places all the support files in the following location. &amp;gt; C:\Users\YourUserName\.platformio\packages\ Any libraries you add to the project are also placed in the same location. After creating your PlatformIO project, assuming you have Visual Studio installed, you can open the project in Visual Studio just by double-clicking on the .vcxproj file from Windows Explorer. &amp;nbsp; ESP8266 Flash and Code Execution Eventually I plan to explore advanced capabilities of the ESP8266, but for this first blog-post I'm going to keep it very simple. After inspection of the Huzzah pin-out here, I determined that pins 0 and 2 are connected to onboard Red and Blue LEDs, respectively, so I decided to use this for my initial testing. There is ample source-code in the public domain which show how to blink an LED using the Arduino API, so I worked up the following sample to blink the two LEDs in sequence. /** * Blink * Turns Red LED on for 1/2 second, then off. * Then turns Blue on for 1/2 second, then off. Repeats. */ #include &amp;quot;Arduino.h&amp;quot; #define RedPin 0 // Connected to a Red LED #define BluePin 2 // Connected to a Blue LED void setup() { // initialize LED digital pin as an output. pinMode(RedPin, OUTPUT); pinMode(BluePin, OUTPUT); } void loop() { // turn Red LED on (HIGH is the voltage level) digitalWrite(RedPin, HIGH); // wait for half a second delay(500); // turn Red LED off by making the voltage LOW digitalWrite(RedPin, LOW); // turn Blue LED on (HIGH is the voltage level) digitalWrite(BluePin, HIGH); // wait for half a second delay(500); // turn Blue LED off by making the voltage LOW digitalWrite(BluePin, LOW); } &amp;nbsp; Building the project from Visual Studio is as simple as right-clicking on the project name, and selecting Build. &amp;nbsp; You can also build the project from the PlatformIO IDE, by clicking the Build button along the left-hand toolbar. &amp;nbsp; With regard to flashing the device, in order to communicate over USB you need to install one particular USB driver on your computer, which you can download here. Now when you plug your Adafruit Huzzah into the computer, a COM device should appear in the Device Manager. &amp;nbsp; Flashing your compiled code to the ESP8266 board is as simple as clicking the Upload button on the left-hand toolbar within the PlatformIO IDE. &amp;nbsp; You'll see some text scroll by at the bottom of the IDE, and then the box may disappear. This is the default setting, that the 'Build Panel' closes automatically after completing, and it can be changed within the Packages settings. After the build completes, the microcontroller should start to perform the actions ascribed to it within the program. If yours doesn't, then try the flash again, and possibly power it off and on (with the USB connector). Here is an short animation of what it will look like when it runs correctly. &amp;nbsp; &amp;nbsp; -R. Foreman &amp;nbsp;</summary></entry><entry><title type="html">Computing Space</title><link href="/posts/2017-1-25-computingspace" rel="alternate" type="text/html" title="Computing Space" /><published>2017-01-25T00:00:00-07:00</published><updated>2017-01-25T00:00:00-07:00</updated><id>/posts/computingspace</id><content type="html" xml:base="/posts/2017-1-25-computingspace">&lt;h2&gt;Personal Computing Workspace&lt;/h2&gt;
&lt;h5&gt;January 25, 2017&lt;/h5&gt;
&lt;p class=&quot;lead&quot;&gt;Last summer I began a serious review of my personal computing arrangement, and a few things became painfully apparent to me. I had something of a messy computer workspace, with very little desk space, lots of dust and a mass of tangled wires on the floor behind the desk. If I ever hoped to start maintaining larger numbers of devices on my local area network, some changes would have to be made, if only to reduce the chaos and upkeep. The question then was just how to organize this area for the most effective use of free space, for the least amount of ongoing maintenance, and for easiest access to all the devices (potentially tablets, a smartphone, single-board computers, a laptop, and one or more desktop machines.. and also experiments with hardware reverse engineering).&lt;/p&gt;

&lt;p&gt;My solution to &lt;u&gt;maximizing computing efficiency&lt;/u&gt;, &lt;u&gt;usage of space&lt;/u&gt;, and &lt;u&gt;ease of access&lt;/u&gt;, with a &lt;u&gt;minimum of space available&lt;/u&gt;, was this. To keep wiring to a minimum everthing had to be within a few feet of the desk, so my solution was generally to begin moving things off the desk and onto the wall behind the desk (as well as underneath the desk).
	&lt;ul&gt;
		&lt;li&gt;I would &lt;b&gt;use the floor underneath the desk for some of the larger items&lt;/b&gt;, such as full-power computer cases.&lt;/li&gt;
		&lt;li&gt;A &lt;b&gt;length of shelving would eventually go onto the wall a few feet above the desk&lt;/b&gt;, and this would hold several of the smaller devices, such as tablets, single-board computers, and a laptop.&lt;/li&gt;
		&lt;li&gt;I also &lt;b&gt;affixed several thin plywood boards to the wall&lt;/b&gt;, with the intention of fixing other devices to them.. things such as a KVM Switch, Wifi Antennas, specialized electronics boards, SDR devices, etc.&lt;/li&gt;
	&lt;/ul&gt;
&lt;/p&gt;

&lt;h3&gt;Moving To The Third Dimension&lt;/h3&gt;
&lt;p&gt;Since I only screw the wall-boards into framing members of the house, this task involved a fair amount of measuring and testing for the locations of the house frame. Of course there was cutting, sanding, and drilling of holes to be done as well, and this all took a bit of time and detailed effort. The first board I put up was one that I termed a &lt;b&gt;power-board&lt;/b&gt;. On it I affixed 6 power-strips, each containing 6 power outlets. This gave me a total of 36 outlets which I estimated would be enough for the small computing lab I had in mind, and this power-board was positioned roughly equi-distant from all my computing devices.&lt;/p&gt;

&lt;p&gt;In the past I've had bad experiences with warm temperatures ruining some of my electronics equipment, so I decided to &lt;b&gt;mount two small fans against the wall&lt;/b&gt;, and have them point down in strategic directions to provide air-flow over some of my equipment. The arrangement of fans I came up with worked out perfectly for this application. In fact I'm thinking about mounting two more of the same fans on the ceiling, directed downward onto my primary desktop computer. I also placed a 20 inch box-fan on the floor, on medium speed, and blowing directly into the front of the computer cases I have sitting on the floor. At times in the past I recall several of the book-end devices on my desk being hot to the touch. After I had positioned a wall-mounted fan to blow air over these for a short while, they are now quite cool, and this testifies to the success of this approach.&lt;/p&gt;

&lt;p&gt;The third wall-board which I put up was to be dedicated for '&lt;b&gt;other devices&lt;/b&gt;'. I was constructing all this nearly at the same time that I was concocting the ideas, so there was ongoing brainstorming involved. I thought of having small shelves, or hooks, and eventually I just decided it would be easiest to use velcro to secure these small items to the wall-board. That way I could velcro the same items to the back of my laptop if I was working in the field somewhere. The velcro was the sticky kind, with the rough side stuck to the wall-board, and the soft fuzzy side stuck to the electronic device. After trying out the first one, I learned that the velcro comes loose from the electronics piece very easily, so I used needle and thread to secure that vecro in place. This solution seems to be working well, and I have used this approach to secure a couple USB3 hubs to the side of my computer case, to provide me ready access to any style of USB connector I might need at any given time.&lt;/p&gt;

&lt;p&gt;Images for Personal Computing Workspace
	&lt;ul style=&quot;list-style-type: none;&quot;&gt;
		&lt;li&gt;&lt;a href=&quot;/images/ComputeSpaceImg1.jpg&quot; target=&quot;_blank&quot;&gt;Computer Lab Workspace Image1&lt;/a&gt;&lt;/li&gt;
		&lt;li&gt;&lt;a href=&quot;/images/ComputeSpaceImg2.jpg&quot; target=&quot;_blank&quot;&gt;Computer Lab Workspace Image2&lt;/a&gt;&lt;/li&gt;
		&lt;li&gt;&lt;a href=&quot;/images/ComputeSpaceImg3.jpg&quot; target=&quot;_blank&quot;&gt;Computer Lab Workspace Image3&lt;/a&gt;&lt;/li&gt;
		&lt;li&gt;&lt;a href=&quot;/images/ComputeSpaceImg4.jpg&quot; target=&quot;_blank&quot;&gt;Computer Lab Workspace Image4&lt;/a&gt;&lt;/li&gt;
		&lt;li&gt;&lt;a href=&quot;/images/ComputeSpaceImg5.jpg&quot; target=&quot;_blank&quot;&gt;Computer Lab Workspace Image5&lt;/a&gt;&lt;/li&gt;
	&lt;/ul&gt;
&lt;/p&gt;

&lt;h3&gt;Conclusion&lt;/h3&gt;
&lt;p&gt;There really isn't a lot more to say about this. The amount of time I spent planning and brainstorming was apparently enough, because &lt;u&gt;the results are phenomenal&lt;/u&gt;. I can now hook a dozen or more devices to my lan, with easy access to power, and access any one of them by KVM Switch with only a modest amount of physical effort (previously I spent more than half my time hooking and unhooking wires to my keyboard/display/mouse if I ran into a serious configuration problem). What is more I now have a large area of unused desk, right next to 20+ open power outlets and any kind of USB connector I might need, for doing work with electronics boards (either dumping firmware via TTL/JTAG/SPI/I2C, or doing some other micro-controller project). Finally I also have far greater confidence in the longevity of my electronics devices, since the system of fans I put in place keeps everything quite cool. I seriously recommend investing some time in designing your personal computing workspace.&lt;/p&gt;

&lt;div&gt;&amp;nbsp;&lt;/div&gt;
&lt;p&gt;-R. Foreman&lt;/p&gt;
&lt;div&gt;&amp;nbsp;&lt;/div&gt;</content><author><name></name></author><summary type="html">Personal Computing Workspace January 25, 2017 Last summer I began a serious review of my personal computing arrangement, and a few things became painfully apparent to me. I had something of a messy computer workspace, with very little desk space, lots of dust and a mass of tangled wires on the floor behind the desk. If I ever hoped to start maintaining larger numbers of devices on my local area network, some changes would have to be made, if only to reduce the chaos and upkeep. The question then was just how to organize this area for the most effective use of free space, for the least amount of ongoing maintenance, and for easiest access to all the devices (potentially tablets, a smartphone, single-board computers, a laptop, and one or more desktop machines.. and also experiments with hardware reverse engineering). My solution to maximizing computing efficiency, usage of space, and ease of access, with a minimum of space available, was this. To keep wiring to a minimum everthing had to be within a few feet of the desk, so my solution was generally to begin moving things off the desk and onto the wall behind the desk (as well as underneath the desk). I would use the floor underneath the desk for some of the larger items, such as full-power computer cases. A length of shelving would eventually go onto the wall a few feet above the desk, and this would hold several of the smaller devices, such as tablets, single-board computers, and a laptop. I also affixed several thin plywood boards to the wall, with the intention of fixing other devices to them.. things such as a KVM Switch, Wifi Antennas, specialized electronics boards, SDR devices, etc. Moving To The Third Dimension Since I only screw the wall-boards into framing members of the house, this task involved a fair amount of measuring and testing for the locations of the house frame. Of course there was cutting, sanding, and drilling of holes to be done as well, and this all took a bit of time and detailed effort. The first board I put up was one that I termed a power-board. On it I affixed 6 power-strips, each containing 6 power outlets. This gave me a total of 36 outlets which I estimated would be enough for the small computing lab I had in mind, and this power-board was positioned roughly equi-distant from all my computing devices. In the past I've had bad experiences with warm temperatures ruining some of my electronics equipment, so I decided to mount two small fans against the wall, and have them point down in strategic directions to provide air-flow over some of my equipment. The arrangement of fans I came up with worked out perfectly for this application. In fact I'm thinking about mounting two more of the same fans on the ceiling, directed downward onto my primary desktop computer. I also placed a 20 inch box-fan on the floor, on medium speed, and blowing directly into the front of the computer cases I have sitting on the floor. At times in the past I recall several of the book-end devices on my desk being hot to the touch. After I had positioned a wall-mounted fan to blow air over these for a short while, they are now quite cool, and this testifies to the success of this approach. The third wall-board which I put up was to be dedicated for 'other devices'. I was constructing all this nearly at the same time that I was concocting the ideas, so there was ongoing brainstorming involved. I thought of having small shelves, or hooks, and eventually I just decided it would be easiest to use velcro to secure these small items to the wall-board. That way I could velcro the same items to the back of my laptop if I was working in the field somewhere. The velcro was the sticky kind, with the rough side stuck to the wall-board, and the soft fuzzy side stuck to the electronic device. After trying out the first one, I learned that the velcro comes loose from the electronics piece very easily, so I used needle and thread to secure that vecro in place. This solution seems to be working well, and I have used this approach to secure a couple USB3 hubs to the side of my computer case, to provide me ready access to any style of USB connector I might need at any given time. Images for Personal Computing Workspace Computer Lab Workspace Image1 Computer Lab Workspace Image2 Computer Lab Workspace Image3 Computer Lab Workspace Image4 Computer Lab Workspace Image5 Conclusion There really isn't a lot more to say about this. The amount of time I spent planning and brainstorming was apparently enough, because the results are phenomenal. I can now hook a dozen or more devices to my lan, with easy access to power, and access any one of them by KVM Switch with only a modest amount of physical effort (previously I spent more than half my time hooking and unhooking wires to my keyboard/display/mouse if I ran into a serious configuration problem). What is more I now have a large area of unused desk, right next to 20+ open power outlets and any kind of USB connector I might need, for doing work with electronics boards (either dumping firmware via TTL/JTAG/SPI/I2C, or doing some other micro-controller project). Finally I also have far greater confidence in the longevity of my electronics devices, since the system of fans I put in place keeps everything quite cool. I seriously recommend investing some time in designing your personal computing workspace. &amp;nbsp; -R. Foreman &amp;nbsp;</summary></entry><entry><title type="html">Multi-Computing</title><link href="/posts/2017-1-18-multicomputing" rel="alternate" type="text/html" title="Multi-Computing" /><published>2017-01-18T00:00:00-07:00</published><updated>2017-01-18T00:00:00-07:00</updated><id>/posts/multicomputing</id><content type="html" xml:base="/posts/2017-1-18-multicomputing">&lt;h2&gt;Multi-Computing&lt;/h2&gt;
&lt;h5&gt;January 18, 2017&lt;/h5&gt;
&lt;p class=&quot;lead&quot;&gt;For lack of a better term, I titled this post multi-computing. In computing jargon we have multi-tasking, which refers to doing multiple things on a single computer, and the title of this piece refers to using multiple computers in a generally seamless way to perform work. In the past I've had some limited experience with this, in the use of an old Windows7 machine over RDP (Microsoft Remote Desktop Protocol) from a newer Windows7 computer. Since then my knowledge has expanded quite a bit in this area, and I'd like to lay out some of these details in a single article.&lt;/p&gt;

&lt;p&gt;I personally think the advantages of having multiple computing devices are obvious, especially when you have lots of computing work to be done, so I won't belabor that with too much argument. The difficulty comes in moving between the computers with minimum effort. From my experience the best way to do this is using networking, having all your devices on a single network, having a router which is under your control, and using the proper network software and protocols. The networking approach may also require opening firewall ports if individual computers have their own firewall running. The second approach which is quite easy although not as scalable to many computers, is to use a KVM, or Keyboard-Video-Mouse switch. I'll provide some of my experiences and details for each of these approaches.&lt;/p&gt;

&lt;h3&gt;Networked Multi-Computing&lt;/h3&gt;
&lt;p&gt;&lt;a name=&quot;NetworkedMultiComp&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;If you use modern hardware, such as a store-bought consumer router, then you probably can adopt this strategy without much knowledge in the area of computer networking. If you hook up a computer to a router, things tend to 'just work' in that IP addresses are assigned automatically and computers are able to discover each other on the LAN (local area network) without any effort on your part. The complications come into play because there are so many different operating platforms, software programs, and network protocols which may be used to connect computers to each other.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;a name=&quot;Win2WinRDP&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h4&gt;&lt;u&gt;Windows to Windows using RDP&lt;/u&gt;&lt;/h4&gt;
&lt;p&gt;The environment most people are familiar with is &lt;b&gt;Microsoft Windows&lt;/b&gt;, and the traditional way of networked log-on here is using a protocol called RDP, or &lt;b&gt;Remote Desktop Protocol&lt;/b&gt;. The receiving end of that connection has to be running a server, so it has to be set up in a specific way. The connecting end runs the client, and all modern versions of MSWindows come equipped with a RDP client by default, which is located here.&lt;/p&gt;

&lt;pre&gt;&amp;gt; C:\Windows\System32\mstsc.exe&lt;/pre&gt;

&lt;p&gt;The &lt;a href=&quot;https://en.wikipedia.org/wiki/Remote_Desktop_Protocol&quot; target=&quot;_blank&quot;&gt;wiki page&lt;/a&gt; gives many more details on RDP. The server end (receiving the connection) must be set up with a user and password (password-less remote connections are not allowed by default, although &lt;a href=&quot;http://superuser.com/questions/106917/remote-desktop-without-a-password#answer-106922&quot; target=&quot;_blank&quot;&gt;this can be changed through the group policy editor&lt;/a&gt;), the &lt;a href=&quot;http://www.computerstepbystep.com/windows_firewall_service.html&quot; target=&quot;_blank&quot;&gt;firewall service must be running&lt;/a&gt; (the firewall itself can be shut off however), and &lt;a href=&quot;http://www.howtogeek.com/howto/windows-vista/turn-on-remote-desktop-in-windows-vista/#div-thetop1&quot; target=&quot;_blank&quot;&gt;remote connections must be enabled&lt;/a&gt;. Once those three requirements are met a remote RDP connection can be established by the client. Since security certificates are used, you can either set this up manually (copying a file from one computer to another using USB), or allow Windows to do this for you on first connect by agreeing that you 'trust' the connection. For switching between two MSWindows boxes, I definitely think RDP is the best approach, with smooth graphics, cryptographically secure connection, shared clipboard, printers, and redirection of local disk drives. The only exception is when one computer is a virtual machine, in which case I still believe the native VM Windowing system provides a superior user experience. Of course with MSWindows systems you can &lt;a href=&quot;http://www.pcadvisor.co.uk/how-to/windows/how-share-folders-without-homegroups-in-windows-7-3434911/&quot; target=&quot;_blank&quot;&gt;share folders between computers&lt;/a&gt; as well.&lt;/p&gt;

&lt;hr /&gt;

&lt;h4&gt;&lt;u&gt;Windows to Linux using VNC&lt;/u&gt;&lt;/h4&gt;
&lt;p&gt;&lt;a name=&quot;Win2LinVNC&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;On the &lt;b&gt;Linux&lt;/b&gt; side you see a protocol called VNC, or &lt;b&gt;Virtual Networked Computing&lt;/b&gt;. VNC works to some extent, but does not quite offer the seamless experience and shared resources as you have with RDP. When you think about it, this makes sense. Linux/Unix has traditionally been a &lt;u&gt;command-line computing environment&lt;/u&gt;. Most of the core of hardened Linux users and administrators use SSH, or some other text-based shell, to get into a remote system and perform updates. A complete graphical representation of a remote system, and sharing with the local system, was never a high priority.&lt;/p&gt;

&lt;p&gt;There are a few drawbacks to using VNC. VNC does not provide any type of transport security (you need to use another program such as SSH to encrypt the stream), while the latest version of RDP offers TLS encryption. Both protocols do provide security certificates and passwords for authentication however. There might be a half dozen or more independent implementations of VNC, while on Windows there really is only one RDP program - the one provided by Microsoft. I've already mentioned that VNC does not allow sharing of clipboard data, files, or virtualization of disk-drives, and this is a huge issue when you're trying to 'multi-compute'. Sharing of clipboard data might work between two Linux boxes (quite honestly I haven't tried it), but between a Windows VNC client and a Linux VNC server, it is sketchy at best, and it almost never works correctly in my experience. Given those drawbacks however, I would say the smoothness in the graphic interface is about comparable with what you find in RDP connections.&lt;/p&gt;

&lt;p&gt;VNC is not overly difficult to set up, and I've seen it used as a fall-back connection on rented hosts for times when you accidentally lock yourself out of the system (such as when you create a firewall rule which locks you out). There are a variety of VNC programs and implementations, so I'll just provide details on the one which I have experience with. I typically start a VNC server &lt;a href=&quot;http://www.karlrunge.com/x11vnc/&quot; target=&quot;_blank&quot;&gt;called x11vnc&lt;/a&gt; on the Linux box, and then in Windows I connect to the Linux box using a VNC client. To install x11vnc, issue the command below.&lt;/p&gt;
&lt;pre&gt;&amp;gt; apt-get install x11vnc&lt;/pre&gt;

&lt;p&gt;Before using the VNC server, you need to create a password, with the following commands.&lt;/p&gt;
&lt;pre&gt;
&amp;gt; mkdir ~/.vnc
&amp;gt; /usr/bin/x11vnc -storepasswd ~/.vnc/x11vnc.pass
&lt;/pre&gt;

&lt;p&gt;Assuming I'm the root user on a default Kali Linux installation, this next command starts the VNC server, and incoming connections attach to the currently running root session (with proper authentication of course).&lt;/p&gt;
&lt;pre&gt;&amp;gt; /usr/bin/x11vnc -xkb -auth /var/run/gdm3/root/:0 -noxrecord -noxfixes -noxdamage -rfbauth /root/.vnc/x11vnc.pass -forever -bg -rfbport 5901 -o /root/.vnc/x11vnc.log&lt;/pre&gt;

&lt;p&gt;You can confirm the server is up and listening, using the following command.&lt;/p&gt;
&lt;pre&gt;&amp;gt; netstat -lptu&lt;/pre&gt;

&lt;p&gt;You can stop the VNC server with this command.&lt;/p&gt;
&lt;pre&gt;&amp;gt; x11vnc -R stop&lt;/pre&gt;

&lt;p&gt;For the Windows VNC client, I use a &lt;a href=&quot;http://www.tightvnc.com/&quot; target=&quot;_blank&quot;&gt;program called tightvnc&lt;/a&gt;. If you install tightvnc, just be aware that it installs and starts a VNC server, so if you don't want that then you need to open your Windows services and stop the VNC server, and possibly disable it also. To connect to the Linux box, start the tightvnc client, enter the Linux machine's IP address, and add the port number which the VNC server is listening on. A window displaying the Linux desktop should appear.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/MultiComputingImg1.jpg&quot; alt=&quot;TightVNC Connection Dialog&quot; /&gt;
&lt;img src=&quot;/images/MultiComputingImg2.jpg&quot; alt=&quot;TightVNC Authentication Dialog&quot; /&gt;
&lt;img src=&quot;/images/MultiComputingImg3.jpg&quot; alt=&quot;TightVNC Display of Remote Linux Desktop&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;

&lt;hr /&gt;

&lt;h4&gt;&lt;u&gt;Linux to Windows using RDP&lt;/u&gt;&lt;/h4&gt;
&lt;p&gt;&lt;a name=&quot;Lin2WinRDP&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;There have been efforts on the Linux side to implement the RDP protocol. One Linux program which I have used, called Remmina, does a commendable job as a RDP client. To my understanding it is available in most Linux distribution repositories, so installation is as simple as this.&lt;/p&gt;
&lt;pre&gt;&amp;gt; apt-get install remmina&lt;/pre&gt;

&lt;p&gt;You can start remmina from the command-line like this.&lt;/p&gt;
&lt;pre&gt;&amp;gt; remmina &amp;amp;&lt;/pre&gt;

&lt;p&gt;Here is a sequence of clips showing Remmina running on my secondary (Linux) box, and connecting to a Windows7 virtual machine running as guest on my primary Windows7 desktop computer. The Win7 VM has IP address 192.168.1.241 .&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/MultiComputingImg4.jpg&quot; alt=&quot;Remmina Interface&quot; /&gt;
&lt;img src=&quot;/images/MultiComputingImg5.jpg&quot; alt=&quot;Remmina Connect Dialog&quot; /&gt;
&lt;img src=&quot;/images/MultiComputingImg6.jpg&quot; alt=&quot;Remmina Certificate Dialog&quot; /&gt;
&lt;img src=&quot;/images/MultiComputingImg7.jpg&quot; alt=&quot;Remmina Preferences Dialog&quot; /&gt;
&lt;img src=&quot;/images/MultiComputingImg8.jpg&quot; alt=&quot;Remmina Remote Host Window&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;

&lt;hr /&gt;

&lt;h4&gt;&lt;u&gt;Windows to Linux using RDP&lt;/u&gt;&lt;/h4&gt;
&lt;p&gt;&lt;a name=&quot;Win2LinRDP&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Another Linux initiative &lt;a href=&quot;https://github.com/neutrinolabs/xrdp&quot; target=&quot;_blank&quot;&gt;called XRDP&lt;/a&gt; aims to create a RDP server for Linux, but this has been problematic, primarily due to the wide array of desktop environments and session managers available on Linux. XRDP works for some desktops, but not for others. I personally prefer not to jump around too much between different desktop suites, and my preferred environment is the &lt;u&gt;Gnome Shell&lt;/u&gt;. Currently XRDP does not work with the Gnome Shell, so I am in a 'wait and see' mode with XRDP. I would love to use it, and when it works it works beautifully (&lt;a href=&quot;http://c-nergy.be/blog/?p=9285&quot; target=&quot;_blank&quot;&gt;see this blog for numerous working examples&lt;/a&gt;), with full resource sharing between local and remote host. XRDP is currently a work in progress, and I fully expect that within a year we will have RDP working between Windows and the Gnome Shell.&lt;/p&gt;

&lt;p&gt;&amp;nbsp;&lt;/p&gt;
&lt;p&gt;&lt;a name=&quot;HardWiredMultiComp&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Hard-Wired Multi-Computing&lt;/h3&gt;
&lt;p&gt;Back when I first started adding secondary devices to my personal network, the process involved physically unhooking my keyboard, mouse, and display from one computer, and then hooking them into another computer. If there was reference material I needed from the first computer, then I would have to physically unhook the keyboard, mouse, and display from the second computer, and hook them back into the first computer to get that information. This process of hooking and unhooking, connecting back and forth between computers can become burdensome. It's even worse if the computers are in difficult locations, such as the floor, behind objects, or in cabinets. The ideal solution is to access different machines using networking, but sometimes this isn't possible, such as when you're setting up or configuring a computer which doesn't have network access. The next best solution is to use something called a &lt;u&gt;KVM switch&lt;/u&gt;, which stands for Keyboard-Video-Mouse, and it allows you to use a single keyboard, mouse, and display set, and switch among multiple computers.&lt;/p&gt;

&lt;p&gt;A couple months ago I picked up &lt;a href=&quot;https://www.amazon.com/Syba-Port-HDMI-Switch-SY-KVM31034/dp/B00ANSVQPW/ref=pd_cp_147_2?_encoding=UTF8&amp;amp;psc=1&amp;amp;refRID=62E2929C25XZJ6TXPG8V&quot; target=&quot;_blank&quot;&gt;a small KVM switch from Amazon&lt;/a&gt;. It was my first experience with this kind of device. I did have high hopes, and in this case I wasn't disappointed. The KVM, like the washing-machine or the printing-press, is truly a &lt;b&gt;time and effort saving miracle&lt;/b&gt;. The one I purchased was a simple 2-port model, which means I can access two computers from my keyboard, mouse, and display. The exact means of switching is often slightly different from one KVM manufacturer to another, but usually you will have a physical switch on the device itself, as well as a software switch from your keyboard, that is, a key combination which will switch you from one computer to another. Another difference between devices is the type of connector. I have not had good experiences with USB3, so I steered away from that. All the computers I either own or am considering buying have HDMI video connectors, and even though these KVM models were a little more expensive and a little less common, this is the type of KVM switch that I went with.&lt;/p&gt;

&lt;p&gt;My &lt;b&gt;Syba 2-Port KVM&lt;/b&gt; came equipped with HDMI/USB3 cords (roughly 4ft in length) which attach to two computers, and I supplied the cords for connecting my keyboard, mouse, and display to the KVM device. This particular KVM uses a key combination of the scroll-lock key twice in succession to perform the switch. This was a problem for me initially, since modern keyboards don't have a scroll-lock key. However you can simulate a scroll-lock using the function key + break key. You can search that on Google Images to see the keys I am talking about. Another problem I ran into initially was that while the switch from MSWindows to Linux worked correctly, I was unable to perform the reverse, a switch from Linux back into MSWindows. I learned that my particular Linux distribution, a derivation of &lt;u&gt;Debian&lt;/u&gt;, did not create a keyboard mapping for the scroll-lock key. Of course other people have encountered this problem, and after a bit of searching I discovered both a temporary and a permanent fix. The permanent fix, &lt;a href=&quot;http://askubuntu.com/questions/764405/scroll-lock-does-not-work&quot; target=&quot;_blank&quot;&gt;which you can read about here&lt;/a&gt;, is a configuration update to create the scroll-lock keyboard mapping, and involves modifying the following file.&lt;/p&gt;
&lt;pre&gt;/usr/share/X11/xkb/symbols/us&lt;/pre&gt;

&lt;p&gt;I found that even with this fix, it still requires tapping the scroll-lock key &lt;b&gt;three times&lt;/b&gt; in succession, not just twice. I am willing to put up with this minor inconvenience in order to access two full size desktop machines with such ease. Still, the use of a KVM switch does have certain limitations, namely a simple way to share data between the two computers. One mechanism is to use a shared folder, and just copy files to that location, then switch to the other machines and access the files. I'll provide details later for setting up shared folders. This approach adds a bit of convenience but is still a little cumbersome, so I began searching for alternatives. It turns out there really are none, only ad-hoc approaches using various utilities. Again, other people have encountered this same problem, and one &lt;a href=&quot;https://help.ubuntu.com/community/SharedCopyAndPaste&quot; target=&quot;_blank&quot;&gt;reference I encountered here&lt;/a&gt; looked quite promising, so I decided to pursue it.&lt;/p&gt;

&lt;p&gt;Small utilities in both Linux and MSWindows will intercept various keystrokes and perform actions which you have ascribed to them. The idea I am pursuing here is to assign actions to a certain keystroke to copy clipboard data into a file in the shared folder, and then with another keystroke copy data from the shared file back into clipboard memory, and perform these actions on both the Linux and MSWindows systems, so you're effectively sharing the same data between two computers with a simple keystroke.&lt;/p&gt;

&lt;hr /&gt;

&lt;h4&gt;&lt;u&gt;Simulating Copy/Paste in MSWindows&lt;/u&gt;&lt;/h4&gt;
&lt;p&gt;&lt;a name=&quot;CopyPasteWin&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The obvious choice for this task in MSWindows is &lt;a href=&quot;https://autohotkey.com/&quot; target=&quot;_blank&quot;&gt;the widely used program AutoHotKey&lt;/a&gt;. I have used AutoHotkey for a decade or more, and it really does allow a level of customization which is unprecedented. The &lt;a href=&quot;https://autohotkey.com/download/&quot; target=&quot;_blank&quot;&gt;download location&lt;/a&gt; provides several options, including installers and a no-install zip file (I would choose this, since you don't need an installation). Create a script file with extension .ahk and locate it anywhere - the AutoHotkey.exe directory is a likely spot. Inside your script file, place the following lines, being sure to use the IP address and shared folder name corresponding to your own computer setup.&lt;/p&gt;
&lt;pre&gt;
;;;;;;
;Paste clipboard data to shared folder file
^#v::
        FileDelete, \\192.168.1.204\MySharedFolder\paste
        FileAppend, %clipboard%, \\192.168.1.204\MySharedFolder\paste
return
;Copy shared folder file into clipboard
^#c::
        FileRead, Clipboard, \\192.168.1.204\MySharedFolder\paste
return
;;;;;;
&lt;/pre&gt;

&lt;p&gt;I have tested the above autohotkey shortcuts, and they work successfully to copy and paste clipboard data to a shared file named 'paste'. Once you have those lines in your script, simply launch AutoHotkey.exe like this.&lt;/p&gt;
&lt;pre&gt;&amp;gt; C:\PathToAutoHotkey\AutoHotkey.exe C:\PathToScriptFile\MyScript.ahk&lt;/pre&gt;

&lt;p&gt;If it wasn't clear before, the shortcuts you use here are ctrl-win-c to Copy, and ctrl-win-v to Paste to/from your shared file. More information on AutoHotkey scripting &lt;a href=&quot;https://autohotkey.com/docs/AutoHotkey.htm&quot; target=&quot;_blank&quot;&gt;can be found here&lt;/a&gt;.&lt;/p&gt;

&lt;hr /&gt;

&lt;h4&gt;&lt;u&gt;Simulating Copy/Paste in Linux&lt;/u&gt;&lt;/h4&gt;
&lt;p&gt;&lt;a name=&quot;CopyPasteLin&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;I identified a couple of Linux utilities which implement the kind of functionality we need here, namely &lt;b&gt;xclip&lt;/b&gt; and &lt;b&gt;xbindkeys&lt;/b&gt;. The xclip program simply works with the operating system clipboard in the most intuitive fashion. First install it in the usual way.&lt;/p&gt;
&lt;pre&gt;&amp;gt; apt-get install xclip&lt;/pre&gt;

&lt;p&gt;Sending data to the clipboard is done like this.&lt;/p&gt;
&lt;pre&gt;&amp;gt; echo &quot;data to clipboard&quot; | xclip -selection c&lt;/pre&gt;

&lt;p&gt;Printing data from the clipboard to stdout is done like this.&lt;/p&gt;
&lt;pre&gt;&amp;gt; xclip -selection clipboard -o&lt;/pre&gt;

&lt;p&gt;After a brief amount of experimentation, I came up with the following two command sequences to Copy/Paste to the shared file (which is named paste).&lt;/p&gt;
&lt;pre&gt;
Paste from clipboard into the shared file
rm -f /opt/MySharedFolder/paste &amp;amp; echo &quot;$(xclip -selection clipboard -o)&quot; &amp;gt; /opt/MySharedFolder/paste

Copy from shared file into the clipboard
cat /opt/MySharedFolder/paste | xclip -selection c
&lt;/pre&gt;

&lt;p&gt;The &lt;b&gt;xbindkeys&lt;/b&gt; program implements keyboard shortcuts. Setup is fairly easy. First install it with your packaging manager.&lt;/p&gt;
&lt;pre&gt;&amp;gt; apt-get install xbindkeys&lt;/pre&gt;

&lt;p&gt;Next create a .xbindkeysrc configuration file.&lt;/p&gt;
&lt;pre&gt;&amp;gt; xbindkeys --defaults &amp;gt; /root/.xbindkeysrc&lt;/pre&gt;

&lt;p&gt;Finally, use xbindkeys to identify the key-codes for the shortcut you want. Issue the command below, and when the small window pops up, enter the shortcut keys you're trying to achieve. Then it tells you the key-codes (on the third line). I was trying to achieve ctrl+win+c and it returned Control+Mod4 + c.&lt;/p&gt;
&lt;pre&gt;&amp;gt; xbindkeys -k&lt;/pre&gt;

&lt;p&gt;Now enter the shortcut into your .xbindkeysrc configuration file.&lt;/p&gt;
&lt;pre&gt;&quot;gnome-terminal&quot;
  Control+Mod4 + c&lt;/pre&gt;

&lt;p&gt;Finally, launch xbindkeys.&lt;/p&gt;
&lt;pre&gt;&amp;gt; xbindkeys&lt;/pre&gt;

&lt;p&gt;Now if you click ctrl+win+c it will launch a gnome terminal. Of course we're after more than just launching the gnome terminal. To implement the Copy/Paste operations I've been talking about, I enter the following into my .xbindkeysrc file.&lt;/p&gt;
&lt;pre&gt;
#Copy from shared file into the clipboard
&quot;cat /opt/MySharedFolder/paste | xclip -selection c&quot;
  Control+Mod4 + c
#Paste from clipboard into the shared file&quot;
&quot;rm -f /opt/MySharedFolder/paste &amp;amp; echo &quot;$(xclip -selection clipboard -o)&quot; &amp;gt; /opt/MySharedFolder/paste&quot;
  Control+Mod4 + v
&lt;/pre&gt;

&lt;p&gt;Now restart xbindkeys and you're ready to move clipboard data to/from MSWindows and Linux. In fact, put xbindkeys into your .xinitrc file so it starts when your Linux boots up. I have to round out this section by talking about shared folders, since the use of a KVM switch means there probably are no other sharing options available to you. Copying a file into a shared folder may be the only way to transfer information from one computer to another (aside from say using a USB stick).&lt;/p&gt;

&lt;hr /&gt;

&lt;h4&gt;&lt;u&gt;Shared Folder Setup in Linux&lt;/u&gt;&lt;/h4&gt;
&lt;p&gt;&lt;a name=&quot;SharedFolderLin&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;As before, I'll talk about the setups which I am familiar with. For this I start on the Linux system, and set up something called a Samba file share. I install Samba as follows.&lt;/p&gt;
&lt;pre&gt;&amp;gt; apt-get install samba&lt;/pre&gt;

&lt;p&gt;Then set a samba password like this (assuming I'm the root user).&lt;/p&gt;
&lt;pre&gt;&amp;gt; smbpasswd -a root&lt;/pre&gt;

&lt;p&gt;Next create a directory to be shared. I often use something like /opt/myshare , but using a folder inside your profile directory is a good idea if you're in a multi-user system. Place a reference to this folder in the samba configuration file /etc/samba/smb.conf as follows.&lt;/p&gt;
&lt;pre&gt;
[MySharedFolder]
path = /opt/myshare
valid users = root
read only = no	
&lt;/pre&gt;

&lt;p&gt;Then if your startup system is SystemD, issue the following commands to enable and start the service.&lt;/p&gt;
&lt;pre&gt;
&amp;gt; systemctl enable smbd
&amp;gt; systemctl start smbd&lt;/pre&gt;

&lt;p&gt;Find the Linux IP address using the &lt;b&gt;ifconfig&lt;/b&gt; command, and use that IP in Windows Explorer to open the file share (and you may need a username/password for initial access).&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/images/MultiComputingImg9.jpg&quot; alt=&quot;Windows Explorer Folder Share with Linux&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;

&lt;p&gt;In MSWindows you can add/edit/remove all the credentials used throughout this article using the Credential Manager, which is found in the Control Panel.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/images/MultiComputingImg10.jpg&quot; alt=&quot;Windows Credential Manager&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;

&lt;hr /&gt;

&lt;h4&gt;&lt;u&gt;Shared Folder Setup in MSWindows&lt;/u&gt;&lt;/h4&gt;
&lt;p&gt;&lt;a name=&quot;SharedFolderWin&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Setting up a shared folder from MSWindows is straightforward as well. Using Windows Explorer, first create a folder for this, then navigate into it, right-click in the display window and from the menu select Share With | Specific People. If it's your own local network, I suppose it's ok to &lt;u&gt;share with Everyone&lt;/u&gt;. Then click the Share button. To make this work, ports 139 and 445 have to be open (on any computers involved), and the computer doing the sharing must have a password set up.. similar to how RDP works between Windows boxes. I'm not going to display the connection examples, but they work very much the same in Windows as on Linux, by using the IP address of the machine you're trying to connect to, and then supplying a username/password. In Linux from the Nautilus file manager application, if you open the Network connections area then you should see the Windows share, and to open it just supply a username/password for the MSWindows machine.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/MultiComputingImg11.jpg&quot; alt=&quot;Sharing a Folder&quot; /&gt;
&lt;img src=&quot;/images/MultiComputingImg12.jpg&quot; alt=&quot;File Sharing Dialog&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;

&lt;p&gt;To edit your Windows shared folders, right-click My Computer on your desktop, then select Manage. When the dialog opens, select Shared Folders. &lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/images/MultiComputingImg13.jpg&quot; alt=&quot;Shared Folders Management Dialog&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;

&lt;div&gt;&amp;nbsp;&lt;/div&gt;
&lt;p&gt;-R. Foreman&lt;/p&gt;
&lt;div&gt;&amp;nbsp;&lt;/div&gt;</content><author><name></name></author><summary type="html">Multi-Computing January 18, 2017 For lack of a better term, I titled this post multi-computing. In computing jargon we have multi-tasking, which refers to doing multiple things on a single computer, and the title of this piece refers to using multiple computers in a generally seamless way to perform work. In the past I've had some limited experience with this, in the use of an old Windows7 machine over RDP (Microsoft Remote Desktop Protocol) from a newer Windows7 computer. Since then my knowledge has expanded quite a bit in this area, and I'd like to lay out some of these details in a single article. I personally think the advantages of having multiple computing devices are obvious, especially when you have lots of computing work to be done, so I won't belabor that with too much argument. The difficulty comes in moving between the computers with minimum effort. From my experience the best way to do this is using networking, having all your devices on a single network, having a router which is under your control, and using the proper network software and protocols. The networking approach may also require opening firewall ports if individual computers have their own firewall running. The second approach which is quite easy although not as scalable to many computers, is to use a KVM, or Keyboard-Video-Mouse switch. I'll provide some of my experiences and details for each of these approaches. Networked Multi-Computing If you use modern hardware, such as a store-bought consumer router, then you probably can adopt this strategy without much knowledge in the area of computer networking. If you hook up a computer to a router, things tend to 'just work' in that IP addresses are assigned automatically and computers are able to discover each other on the LAN (local area network) without any effort on your part. The complications come into play because there are so many different operating platforms, software programs, and network protocols which may be used to connect computers to each other. Windows to Windows using RDP The environment most people are familiar with is Microsoft Windows, and the traditional way of networked log-on here is using a protocol called RDP, or Remote Desktop Protocol. The receiving end of that connection has to be running a server, so it has to be set up in a specific way. The connecting end runs the client, and all modern versions of MSWindows come equipped with a RDP client by default, which is located here. &amp;gt; C:\Windows\System32\mstsc.exe The wiki page gives many more details on RDP. The server end (receiving the connection) must be set up with a user and password (password-less remote connections are not allowed by default, although this can be changed through the group policy editor), the firewall service must be running (the firewall itself can be shut off however), and remote connections must be enabled. Once those three requirements are met a remote RDP connection can be established by the client. Since security certificates are used, you can either set this up manually (copying a file from one computer to another using USB), or allow Windows to do this for you on first connect by agreeing that you 'trust' the connection. For switching between two MSWindows boxes, I definitely think RDP is the best approach, with smooth graphics, cryptographically secure connection, shared clipboard, printers, and redirection of local disk drives. The only exception is when one computer is a virtual machine, in which case I still believe the native VM Windowing system provides a superior user experience. Of course with MSWindows systems you can share folders between computers as well. Windows to Linux using VNC On the Linux side you see a protocol called VNC, or Virtual Networked Computing. VNC works to some extent, but does not quite offer the seamless experience and shared resources as you have with RDP. When you think about it, this makes sense. Linux/Unix has traditionally been a command-line computing environment. Most of the core of hardened Linux users and administrators use SSH, or some other text-based shell, to get into a remote system and perform updates. A complete graphical representation of a remote system, and sharing with the local system, was never a high priority. There are a few drawbacks to using VNC. VNC does not provide any type of transport security (you need to use another program such as SSH to encrypt the stream), while the latest version of RDP offers TLS encryption. Both protocols do provide security certificates and passwords for authentication however. There might be a half dozen or more independent implementations of VNC, while on Windows there really is only one RDP program - the one provided by Microsoft. I've already mentioned that VNC does not allow sharing of clipboard data, files, or virtualization of disk-drives, and this is a huge issue when you're trying to 'multi-compute'. Sharing of clipboard data might work between two Linux boxes (quite honestly I haven't tried it), but between a Windows VNC client and a Linux VNC server, it is sketchy at best, and it almost never works correctly in my experience. Given those drawbacks however, I would say the smoothness in the graphic interface is about comparable with what you find in RDP connections. VNC is not overly difficult to set up, and I've seen it used as a fall-back connection on rented hosts for times when you accidentally lock yourself out of the system (such as when you create a firewall rule which locks you out). There are a variety of VNC programs and implementations, so I'll just provide details on the one which I have experience with. I typically start a VNC server called x11vnc on the Linux box, and then in Windows I connect to the Linux box using a VNC client. To install x11vnc, issue the command below. &amp;gt; apt-get install x11vnc Before using the VNC server, you need to create a password, with the following commands. &amp;gt; mkdir ~/.vnc &amp;gt; /usr/bin/x11vnc -storepasswd ~/.vnc/x11vnc.pass Assuming I'm the root user on a default Kali Linux installation, this next command starts the VNC server, and incoming connections attach to the currently running root session (with proper authentication of course). &amp;gt; /usr/bin/x11vnc -xkb -auth /var/run/gdm3/root/:0 -noxrecord -noxfixes -noxdamage -rfbauth /root/.vnc/x11vnc.pass -forever -bg -rfbport 5901 -o /root/.vnc/x11vnc.log You can confirm the server is up and listening, using the following command. &amp;gt; netstat -lptu You can stop the VNC server with this command. &amp;gt; x11vnc -R stop For the Windows VNC client, I use a program called tightvnc. If you install tightvnc, just be aware that it installs and starts a VNC server, so if you don't want that then you need to open your Windows services and stop the VNC server, and possibly disable it also. To connect to the Linux box, start the tightvnc client, enter the Linux machine's IP address, and add the port number which the VNC server is listening on. A window displaying the Linux desktop should appear. &amp;nbsp; Linux to Windows using RDP There have been efforts on the Linux side to implement the RDP protocol. One Linux program which I have used, called Remmina, does a commendable job as a RDP client. To my understanding it is available in most Linux distribution repositories, so installation is as simple as this. &amp;gt; apt-get install remmina You can start remmina from the command-line like this. &amp;gt; remmina &amp;amp; Here is a sequence of clips showing Remmina running on my secondary (Linux) box, and connecting to a Windows7 virtual machine running as guest on my primary Windows7 desktop computer. The Win7 VM has IP address 192.168.1.241 . &amp;nbsp; Windows to Linux using RDP Another Linux initiative called XRDP aims to create a RDP server for Linux, but this has been problematic, primarily due to the wide array of desktop environments and session managers available on Linux. XRDP works for some desktops, but not for others. I personally prefer not to jump around too much between different desktop suites, and my preferred environment is the Gnome Shell. Currently XRDP does not work with the Gnome Shell, so I am in a 'wait and see' mode with XRDP. I would love to use it, and when it works it works beautifully (see this blog for numerous working examples), with full resource sharing between local and remote host. XRDP is currently a work in progress, and I fully expect that within a year we will have RDP working between Windows and the Gnome Shell. &amp;nbsp; Hard-Wired Multi-Computing Back when I first started adding secondary devices to my personal network, the process involved physically unhooking my keyboard, mouse, and display from one computer, and then hooking them into another computer. If there was reference material I needed from the first computer, then I would have to physically unhook the keyboard, mouse, and display from the second computer, and hook them back into the first computer to get that information. This process of hooking and unhooking, connecting back and forth between computers can become burdensome. It's even worse if the computers are in difficult locations, such as the floor, behind objects, or in cabinets. The ideal solution is to access different machines using networking, but sometimes this isn't possible, such as when you're setting up or configuring a computer which doesn't have network access. The next best solution is to use something called a KVM switch, which stands for Keyboard-Video-Mouse, and it allows you to use a single keyboard, mouse, and display set, and switch among multiple computers. A couple months ago I picked up a small KVM switch from Amazon. It was my first experience with this kind of device. I did have high hopes, and in this case I wasn't disappointed. The KVM, like the washing-machine or the printing-press, is truly a time and effort saving miracle. The one I purchased was a simple 2-port model, which means I can access two computers from my keyboard, mouse, and display. The exact means of switching is often slightly different from one KVM manufacturer to another, but usually you will have a physical switch on the device itself, as well as a software switch from your keyboard, that is, a key combination which will switch you from one computer to another. Another difference between devices is the type of connector. I have not had good experiences with USB3, so I steered away from that. All the computers I either own or am considering buying have HDMI video connectors, and even though these KVM models were a little more expensive and a little less common, this is the type of KVM switch that I went with. My Syba 2-Port KVM came equipped with HDMI/USB3 cords (roughly 4ft in length) which attach to two computers, and I supplied the cords for connecting my keyboard, mouse, and display to the KVM device. This particular KVM uses a key combination of the scroll-lock key twice in succession to perform the switch. This was a problem for me initially, since modern keyboards don't have a scroll-lock key. However you can simulate a scroll-lock using the function key + break key. You can search that on Google Images to see the keys I am talking about. Another problem I ran into initially was that while the switch from MSWindows to Linux worked correctly, I was unable to perform the reverse, a switch from Linux back into MSWindows. I learned that my particular Linux distribution, a derivation of Debian, did not create a keyboard mapping for the scroll-lock key. Of course other people have encountered this problem, and after a bit of searching I discovered both a temporary and a permanent fix. The permanent fix, which you can read about here, is a configuration update to create the scroll-lock keyboard mapping, and involves modifying the following file. /usr/share/X11/xkb/symbols/us I found that even with this fix, it still requires tapping the scroll-lock key three times in succession, not just twice. I am willing to put up with this minor inconvenience in order to access two full size desktop machines with such ease. Still, the use of a KVM switch does have certain limitations, namely a simple way to share data between the two computers. One mechanism is to use a shared folder, and just copy files to that location, then switch to the other machines and access the files. I'll provide details later for setting up shared folders. This approach adds a bit of convenience but is still a little cumbersome, so I began searching for alternatives. It turns out there really are none, only ad-hoc approaches using various utilities. Again, other people have encountered this same problem, and one reference I encountered here looked quite promising, so I decided to pursue it. Small utilities in both Linux and MSWindows will intercept various keystrokes and perform actions which you have ascribed to them. The idea I am pursuing here is to assign actions to a certain keystroke to copy clipboard data into a file in the shared folder, and then with another keystroke copy data from the shared file back into clipboard memory, and perform these actions on both the Linux and MSWindows systems, so you're effectively sharing the same data between two computers with a simple keystroke. Simulating Copy/Paste in MSWindows The obvious choice for this task in MSWindows is the widely used program AutoHotKey. I have used AutoHotkey for a decade or more, and it really does allow a level of customization which is unprecedented. The download location provides several options, including installers and a no-install zip file (I would choose this, since you don't need an installation). Create a script file with extension .ahk and locate it anywhere - the AutoHotkey.exe directory is a likely spot. Inside your script file, place the following lines, being sure to use the IP address and shared folder name corresponding to your own computer setup. ;;;;;; ;Paste clipboard data to shared folder file ^#v:: FileDelete, \\192.168.1.204\MySharedFolder\paste FileAppend, %clipboard%, \\192.168.1.204\MySharedFolder\paste return ;Copy shared folder file into clipboard ^#c:: FileRead, Clipboard, \\192.168.1.204\MySharedFolder\paste return ;;;;;; I have tested the above autohotkey shortcuts, and they work successfully to copy and paste clipboard data to a shared file named 'paste'. Once you have those lines in your script, simply launch AutoHotkey.exe like this. &amp;gt; C:\PathToAutoHotkey\AutoHotkey.exe C:\PathToScriptFile\MyScript.ahk If it wasn't clear before, the shortcuts you use here are ctrl-win-c to Copy, and ctrl-win-v to Paste to/from your shared file. More information on AutoHotkey scripting can be found here. Simulating Copy/Paste in Linux I identified a couple of Linux utilities which implement the kind of functionality we need here, namely xclip and xbindkeys. The xclip program simply works with the operating system clipboard in the most intuitive fashion. First install it in the usual way. &amp;gt; apt-get install xclip Sending data to the clipboard is done like this. &amp;gt; echo &quot;data to clipboard&quot; | xclip -selection c Printing data from the clipboard to stdout is done like this. &amp;gt; xclip -selection clipboard -o After a brief amount of experimentation, I came up with the following two command sequences to Copy/Paste to the shared file (which is named paste). Paste from clipboard into the shared file rm -f /opt/MySharedFolder/paste &amp;amp; echo &quot;$(xclip -selection clipboard -o)&quot; &amp;gt; /opt/MySharedFolder/paste Copy from shared file into the clipboard cat /opt/MySharedFolder/paste | xclip -selection c The xbindkeys program implements keyboard shortcuts. Setup is fairly easy. First install it with your packaging manager. &amp;gt; apt-get install xbindkeys Next create a .xbindkeysrc configuration file. &amp;gt; xbindkeys --defaults &amp;gt; /root/.xbindkeysrc Finally, use xbindkeys to identify the key-codes for the shortcut you want. Issue the command below, and when the small window pops up, enter the shortcut keys you're trying to achieve. Then it tells you the key-codes (on the third line). I was trying to achieve ctrl+win+c and it returned Control+Mod4 + c. &amp;gt; xbindkeys -k Now enter the shortcut into your .xbindkeysrc configuration file. &quot;gnome-terminal&quot; Control+Mod4 + c Finally, launch xbindkeys. &amp;gt; xbindkeys Now if you click ctrl+win+c it will launch a gnome terminal. Of course we're after more than just launching the gnome terminal. To implement the Copy/Paste operations I've been talking about, I enter the following into my .xbindkeysrc file. #Copy from shared file into the clipboard &quot;cat /opt/MySharedFolder/paste | xclip -selection c&quot; Control+Mod4 + c #Paste from clipboard into the shared file&quot; &quot;rm -f /opt/MySharedFolder/paste &amp;amp; echo &quot;$(xclip -selection clipboard -o)&quot; &amp;gt; /opt/MySharedFolder/paste&quot; Control+Mod4 + v Now restart xbindkeys and you're ready to move clipboard data to/from MSWindows and Linux. In fact, put xbindkeys into your .xinitrc file so it starts when your Linux boots up. I have to round out this section by talking about shared folders, since the use of a KVM switch means there probably are no other sharing options available to you. Copying a file into a shared folder may be the only way to transfer information from one computer to another (aside from say using a USB stick). Shared Folder Setup in Linux As before, I'll talk about the setups which I am familiar with. For this I start on the Linux system, and set up something called a Samba file share. I install Samba as follows. &amp;gt; apt-get install samba Then set a samba password like this (assuming I'm the root user). &amp;gt; smbpasswd -a root Next create a directory to be shared. I often use something like /opt/myshare , but using a folder inside your profile directory is a good idea if you're in a multi-user system. Place a reference to this folder in the samba configuration file /etc/samba/smb.conf as follows. [MySharedFolder] path = /opt/myshare valid users = root read only = no Then if your startup system is SystemD, issue the following commands to enable and start the service. &amp;gt; systemctl enable smbd &amp;gt; systemctl start smbd Find the Linux IP address using the ifconfig command, and use that IP in Windows Explorer to open the file share (and you may need a username/password for initial access). &amp;nbsp; In MSWindows you can add/edit/remove all the credentials used throughout this article using the Credential Manager, which is found in the Control Panel. &amp;nbsp; Shared Folder Setup in MSWindows Setting up a shared folder from MSWindows is straightforward as well. Using Windows Explorer, first create a folder for this, then navigate into it, right-click in the display window and from the menu select Share With | Specific People. If it's your own local network, I suppose it's ok to share with Everyone. Then click the Share button. To make this work, ports 139 and 445 have to be open (on any computers involved), and the computer doing the sharing must have a password set up.. similar to how RDP works between Windows boxes. I'm not going to display the connection examples, but they work very much the same in Windows as on Linux, by using the IP address of the machine you're trying to connect to, and then supplying a username/password. In Linux from the Nautilus file manager application, if you open the Network connections area then you should see the Windows share, and to open it just supply a username/password for the MSWindows machine. &amp;nbsp; To edit your Windows shared folders, right-click My Computer on your desktop, then select Manage. When the dialog opens, select Shared Folders. &amp;nbsp; &amp;nbsp; -R. Foreman &amp;nbsp;</summary></entry><entry><title type="html">MyBook Drive Conversion from USB3 to SATA3</title><link href="/posts/2017-1-10-mybookdisassembly" rel="alternate" type="text/html" title="MyBook Drive Conversion from USB3 to SATA3" /><published>2017-01-10T00:00:00-07:00</published><updated>2017-01-10T00:00:00-07:00</updated><id>/posts/mybookdisassembly</id><content type="html" xml:base="/posts/2017-1-10-mybookdisassembly">&lt;h2&gt;MyBook Transformation, External USB3 to Internal SATA3&lt;/h2&gt;
&lt;h5&gt;January 10, 2017&lt;/h5&gt;
&lt;p class=&quot;lead&quot;&gt;External USB3 disk-drives have become popular in the last few years, primarily due to their low cost and high capacity. I speak from experience, as I own three of these, a 3TeraByte drive purchased about 5 years ago, another 4TeraByte drive purchased 3 years ago, and finally an 8TeraByte drive acquired within the last month. These work about as advertised, however there were two issues which over time began to become quite annoying. Eventually this situation led to rash measures, the destruction of the external protective casing of the Western Digital Mybook to expose the SATA3 internal disk-drive inside.&lt;/p&gt;

&lt;p&gt;&lt;u&gt;The first annoyance&lt;/u&gt; was a rather lengthy delay (10 seconds or more) to access the drive after some period of inactivity. Even with slow internal disk-drives you don't have to wait more than 1/2 second to get a response, &lt;u&gt;ever, under any circumstance&lt;/u&gt;. I've never actually learned the reason for this. The problem could my motherboard/CPU pair and the fact that they don't have any native USB3 support, and PCIe lanes are needed to create USB3 ports. It could also be the USB3-SATA3 circuit inside the MyBook has some kind of protection mechanism which prevents the drive from spinning up too fast, or perhaps they're kept at 0 RPM when not in use and require extra time to spin up to speed. I don't know what the issue was, and I never spent any time researching other peoples' experiences. However, I don't enjoy accessing a disk-drive and sitting for part of a minute watching nothing, because it makes me think something is very wrong with my computer hardware.&lt;/p&gt;

&lt;p&gt;The &lt;u&gt;second troubling circumstance&lt;/u&gt; was that adding so many USB3 connections began to cause operational problems with my motherboard. After I had added a couple PCIe expansion cards which created a total of 8 USB3 ports, other parts of the motherboard began to experience failures. For example sound stopped working, the USB3 headers stopped working, and the boot process began failing in random ways. After removing the USB3 expansion cards, the failures disappeared. In fact after going through the process I describe below, I can happily say that the computer boot speed has increased by a factor of 10 or more, and all the USB3 motherboard headers are now fully functional. I can only surmise that I had run into a PCIe lane limit, a limitation of the chipset and CPU being used.&lt;/p&gt;

&lt;h3&gt;The MyBook Dissassembly&lt;/h3&gt;
&lt;p&gt;&lt;a name=&quot;1stMyBookDisassembly&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;For the afore-mentioned reasons, I began to look at ways of eliminating my external USB3 devices (at least the powered ones, such as mass storage devices). A modest amount of research revealed that other people had deconstructed their MyBook cases and found an internal SATA3 drive. I got a wild hair one day and decided to just go ahead and do this, using my most recent purchase, the 8TeraByte drive. Be aware that trying this would probably void any warranty you might have on these external drives.&lt;/p&gt;

&lt;p&gt;Before beginning, I disconnected all cables (power and data) from the MyBook device, and used protective eyewear in case plastic pieces came flying up at my face. I began by prying at the fan vents along the edges, ever so gently so as not to damage the contents of the case. Eventually I simply broke the venting slats and tore them away, on both sides of the case. To do this I used a couple screw-drivers as prybars, and some pliers to tear away the plastic. After that I learned there was an internal plastic sleeve that was moving freely, and I slid this out and away from the case. Below I've posted photos at various stages of this process, and I know these aren't the most exciting pictures, but they may help someone going through this procedure at some point. After pulling the drive free from the case, I found there was rubber bumper material and retaining screws which could be removed. I also found that the USB3-SATA3 converter circuit board was held in place by a single screw, and once removed the drive itself was a simple 3.5 inch SATA platter-based disk-drive.
	&lt;ul style=&quot;list-style-type: none;&quot;&gt;
		&lt;li&gt;&lt;a href=&quot;/images/8TbImg1.jpg&quot; target=&quot;_blank&quot;&gt;WDMyBook 8Tb Image1&lt;/a&gt;&lt;/li&gt;
		&lt;li&gt;&lt;a href=&quot;/images/8TbImg2.jpg&quot; target=&quot;_blank&quot;&gt;WDMyBook 8Tb Image2&lt;/a&gt;&lt;/li&gt;
		&lt;li&gt;&lt;a href=&quot;/images/8TbImg3.jpg&quot; target=&quot;_blank&quot;&gt;WDMyBook 8Tb Image3&lt;/a&gt;&lt;/li&gt;
		&lt;li&gt;&lt;a href=&quot;/images/8TbImg4.jpg&quot; target=&quot;_blank&quot;&gt;WDMyBook 8Tb Image4&lt;/a&gt;&lt;/li&gt;
		&lt;li&gt;&lt;a href=&quot;/images/8TbImg5.jpg&quot; target=&quot;_blank&quot;&gt;WDMyBook 8Tb Image5&lt;/a&gt;&lt;/li&gt;
		&lt;li&gt;&lt;a href=&quot;/images/8TbImg6.jpg&quot; target=&quot;_blank&quot;&gt;WDMyBook 8Tb Image6&lt;/a&gt;&lt;/li&gt;
		&lt;li&gt;&lt;a href=&quot;/images/8TbImg7.jpg&quot; target=&quot;_blank&quot;&gt;WDMyBook 8Tb Image7&lt;/a&gt;&lt;/li&gt;
		&lt;li&gt;&lt;a href=&quot;/images/8TbImg8.jpg&quot; target=&quot;_blank&quot;&gt;WDMyBook 8Tb Image8&lt;/a&gt;&lt;/li&gt;
		&lt;li&gt;&lt;a href=&quot;/images/8TbImg9.jpg&quot; target=&quot;_blank&quot;&gt;WDMyBook 8Tb Image9&lt;/a&gt;&lt;/li&gt;
		&lt;li&gt;&lt;a href=&quot;/images/8TbImg10.jpg&quot; target=&quot;_blank&quot;&gt;WDMyBook 8Tb Image10&lt;/a&gt;&lt;/li&gt;
	&lt;/ul&gt;
&lt;/p&gt;

&lt;p&gt;After cleaning some dust off the SATA3 drive, I installed it internally in my desktop computer, and it worked flawlessly. What is more the long delay when accessing the disk was no longer there. I subsequently learned from handling this disk that when plugged into power, the platters spin continuously. It's an interesting effect actually, because when you handle a powered disk like this, it has the motion of a gyroscope (which is what it is, with an internal part that is spinning at high speed). I was thrilled by these events, and decided to look into ways of converting all my external MyBook USB3 disks into internal SATA3 disks.&lt;/p&gt;

&lt;h3&gt;SATA3 Drive Enclosure&lt;/h3&gt;
&lt;p&gt;&lt;a name=&quot;Sata3DriveEnclosure&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;This journey next led me to read up on disk drive enclosures. Many of them use USB3 for connecting the computer to the (external) enclosure, and this didn't interest me. What did catch my eye were references to a 'port multiplier' circuit using an eSATA connection between computer and external drive enclosure. I had no experience at all with drive enclosures, but this piqued my curiosity because it sounded exactly like what I wanted, more SATA3 connections without using additional PCIe lanes. I found a likely drive enclosure on &lt;u&gt;NewEgg&lt;/u&gt;, the &lt;a href=&quot;http://www.newegg.com/Product/Product.aspx?Item=N82E16816111455&quot; target=&quot;_blank&quot;&gt;Sans Digital TR4M6GNC&lt;/a&gt; , and because it was so inexpensive ($85) I just took the chance and bought it.&lt;/p&gt;

&lt;p&gt;My desktop machine has a couple 6Gbs eSATA connectors which come directly off the motherboard as headers. When the &lt;b&gt;Sans Digital&lt;/b&gt; enclosure arrived, it didn't work. It powered up correctly, and drives that I put inside it powered up, but there was nothing I could do to make the drive become recognized on my computer (and I tried many things, including software driver updates). I entertained the possibility that my eSATA headers were malfuntioning, as several other things were not working correctly on this computer, so I saw a very inexpensive (port multiplier) &lt;a href=&quot;http://www.newegg.com/Product/Product.aspx?Item=9SIA2W03ZK2940&quot; target=&quot;_blank&quot;&gt;eSATA expansion card&lt;/a&gt; and bought it. When the card arrived, I tried it in my primary desktop, as well as the secondary computer I built recently, but nothing worked. After reading other buyer comments on &lt;u&gt;Amazon&lt;/u&gt; concerning this particular enclosure, I concluded it was probably defective, and that it had a high incidence of failure (due to something called an eSATA repeater).&lt;/p&gt;

&lt;p&gt;I returned the &lt;b&gt;Sans Digital&lt;/b&gt; product for a refund (but kept the eSATA expansion card to use with my secondary computer), and took a chance with another enclosure which had good customer reviews on &lt;u&gt;Amazon&lt;/u&gt;, the &lt;a href=&quot;https://www.amazon.com/dp/B003X26VV4/ref=psdc_160354011_t1_B004WNLOF6&quot; target=&quot;_blank&quot;&gt;Mediasonic Probox HF2-SU3S2&lt;/a&gt;. This drive enclosure did work correctly, right out of the box, with my desktop 6Gbs eSATA connectors as well as the expansion card, and it worked correctly both in my Windows7 machine and my secondary Linux box. I was of course thrilled by this, so I picked up a &lt;a href=&quot;https://www.amazon.com/StarTech-6-Feet-Shielded-External-ESATA6/dp/B000ENYXZ6/ref=pd_sim_147_2&quot; target=&quot;_blank&quot;&gt;slightly longer 6ft eSATA cable from Amazon&lt;/a&gt; (the drive enclosure comes with a 3ft eSATA cable) , and began the process of converting my other MyBook drives from USB3 to SATA3. One benefit of using the &lt;b&gt;Mediasonic&lt;/b&gt; enclosure is that the maximum size drive recognized is 8Tb, versus 6Tb for the &lt;b&gt;Sans Digital&lt;/b&gt; enclosure, so &lt;b&gt;Mediasonic&lt;/b&gt; offers a slightly larger capacity.&lt;/p&gt;

&lt;p&gt;When using the &lt;b&gt;Mediasonic Probox&lt;/b&gt; enclosure, you have to read the instructions, because there are 3 buttons and several modes of operation. Once I had set the interface to eSATA, and the Sync light to orange, the enclosure worked without issue (and I keep the fan setting on high at all times). There are customer comments on &lt;u&gt;Amazon&lt;/u&gt; which describe these controls in great detail. Windows7 doesn't always recognize hot-swapped SATA3 drives (you may need to reboot), but that seems to be a Microsoft issue, because Linux recognizes the drives the second they are connected. In every respect the drives behave identically in the external drive enclosure and port multiplier circuitry as they would when connected inside a computer case (with internal SATA3 connections).&lt;/p&gt;

&lt;p&gt;The only other thing worth noting here is that the &lt;b&gt;Western Digital&lt;/b&gt; USB3 (external) drives provide some kind of control processing which allows drives larger than 2Tb to be fully utilized even though it was not initialized using GPT. The geeks among us know that Microsoft windows cannot see disk-drive space beyond 2Tb unless it is initialized using GUID Partition Table (GPT). Two of my three drives were not initialized using GPT, and I would have lost my data if I had not tranferred the drives over empty. When adding those two drives as SATA3, they both had to be reinitialized with GPT, so any data on them would have been lost. Also just an FYI, when initializing a drive as GPT, a 120Mb partition is created (called the Microsoft Reserved Partition), and this can be safely deleted if the drive won't be used as a boot disk.&lt;/p&gt;

&lt;h3&gt;Disassembling My Remaining MyBook USB3 Drives&lt;/h3&gt;
&lt;p&gt;&lt;a name=&quot;RemainingMyBookDisassemblies&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;I don't want to get too long-winded with this blog-post, so I'll just provide the photos I took, and say that each of the &lt;b&gt;Western Digital&lt;/b&gt; MyBooks was slightly different. However the approach to disassembling them was basically the same - get a screwdriver under the ventilation slats and pry, then get a second screwdriver in there to pry and lift, and use plyers to pull the ventilation slats up and away from the enclosure. Be careful not to jam the screwdrivers down into the enclosure or you might damage the disk-drive, and definitely put goggles on in case something flies up into your face.&lt;/p&gt;
&lt;p&gt;3Tb WD MyBook Photos
	&lt;ul style=&quot;list-style-type: none;&quot;&gt;
		&lt;li&gt;&lt;a href=&quot;/images/3TbImg1.jpg&quot; target=&quot;_blank&quot;&gt;WDMyBook 3Tb Image1&lt;/a&gt;&lt;/li&gt;
		&lt;li&gt;&lt;a href=&quot;/images/3TbImg2.jpg&quot; target=&quot;_blank&quot;&gt;WDMyBook 3Tb Image2&lt;/a&gt;&lt;/li&gt;
		&lt;li&gt;&lt;a href=&quot;/images/3TbImg3.jpg&quot; target=&quot;_blank&quot;&gt;WDMyBook 3Tb Image3&lt;/a&gt;&lt;/li&gt;
		&lt;li&gt;&lt;a href=&quot;/images/3TbImg4.jpg&quot; target=&quot;_blank&quot;&gt;WDMyBook 3Tb Image4&lt;/a&gt;&lt;/li&gt;
		&lt;li&gt;&lt;a href=&quot;/images/3TbImg5.jpg&quot; target=&quot;_blank&quot;&gt;WDMyBook 3Tb Image5&lt;/a&gt;&lt;/li&gt;
		&lt;li&gt;&lt;a href=&quot;/images/3TbImg6.jpg&quot; target=&quot;_blank&quot;&gt;WDMyBook 3Tb Image6&lt;/a&gt;&lt;/li&gt;
		&lt;li&gt;&lt;a href=&quot;/images/3TbImg7.jpg&quot; target=&quot;_blank&quot;&gt;WDMyBook 3Tb Image7&lt;/a&gt;&lt;/li&gt;
		&lt;li&gt;&lt;a href=&quot;/images/3TbImg8.jpg&quot; target=&quot;_blank&quot;&gt;WDMyBook 3Tb Image8&lt;/a&gt;&lt;/li&gt;
		&lt;li&gt;&lt;a href=&quot;/images/3TbImg9.jpg&quot; target=&quot;_blank&quot;&gt;WDMyBook 3Tb Image9&lt;/a&gt;&lt;/li&gt;
	&lt;/ul&gt;
&lt;/p&gt;
&lt;p&gt;4Tb WD MyBook Photos
	&lt;ul style=&quot;list-style-type: none;&quot;&gt;
		&lt;li&gt;&lt;a href=&quot;/images/4TbImg1.jpg&quot; target=&quot;_blank&quot;&gt;WDMyBook 4Tb Image1&lt;/a&gt;&lt;/li&gt;
		&lt;li&gt;&lt;a href=&quot;/images/4TbImg2.jpg&quot; target=&quot;_blank&quot;&gt;WDMyBook 4Tb Image2&lt;/a&gt;&lt;/li&gt;
		&lt;li&gt;&lt;a href=&quot;/images/4TbImg3.jpg&quot; target=&quot;_blank&quot;&gt;WDMyBook 4Tb Image3&lt;/a&gt;&lt;/li&gt;
		&lt;li&gt;&lt;a href=&quot;/images/4TbImg4.jpg&quot; target=&quot;_blank&quot;&gt;WDMyBook 4Tb Image4&lt;/a&gt;&lt;/li&gt;
		&lt;li&gt;&lt;a href=&quot;/images/4TbImg5.jpg&quot; target=&quot;_blank&quot;&gt;WDMyBook 4Tb Image5&lt;/a&gt;&lt;/li&gt;
		&lt;li&gt;&lt;a href=&quot;/images/4TbImg6.jpg&quot; target=&quot;_blank&quot;&gt;WDMyBook 4Tb Image6&lt;/a&gt;&lt;/li&gt;
	&lt;/ul&gt;
&lt;/p&gt;
&lt;p&gt;Mediasonic Probox Photos
	&lt;ul style=&quot;list-style-type: none;&quot;&gt;
		&lt;li&gt;&lt;a href=&quot;/images/ProboxImg1.jpg&quot; target=&quot;_blank&quot;&gt;Mediasonic Probox Image1&lt;/a&gt;&lt;/li&gt;
		&lt;li&gt;&lt;a href=&quot;/images/ProboxImg2.jpg&quot; target=&quot;_blank&quot;&gt;Mediasonic Probox Image2&lt;/a&gt;&lt;/li&gt;
		&lt;li&gt;&lt;a href=&quot;/images/ProboxImg3.jpg&quot; target=&quot;_blank&quot;&gt;Mediasonic Probox Image3&lt;/a&gt;&lt;/li&gt;
		&lt;li&gt;&lt;a href=&quot;/images/ProboxImg4.jpg&quot; target=&quot;_blank&quot;&gt;Mediasonic Probox Image4&lt;/a&gt;&lt;/li&gt;
		&lt;li&gt;&lt;a href=&quot;/images/ProboxImg5.jpg&quot; target=&quot;_blank&quot;&gt;Mediasonic Probox Image5&lt;/a&gt;&lt;/li&gt;
		&lt;li&gt;&lt;a href=&quot;/images/ProboxImg6.jpg&quot; target=&quot;_blank&quot;&gt;Mediasonic Probox Image6&lt;/a&gt;&lt;/li&gt;
		&lt;li&gt;&lt;a href=&quot;/images/ProboxImg7.jpg&quot; target=&quot;_blank&quot;&gt;Mediasonic Probox Image7&lt;/a&gt;&lt;/li&gt;
		&lt;li&gt;&lt;a href=&quot;/images/ProboxImg8.jpg&quot; target=&quot;_blank&quot;&gt;Mediasonic Probox Image8&lt;/a&gt;&lt;/li&gt;
		&lt;li&gt;&lt;a href=&quot;/images/ProboxImg9.jpg&quot; target=&quot;_blank&quot;&gt;Mediasonic Probox Image9&lt;/a&gt;&lt;/li&gt;
	&lt;/ul&gt;
&lt;/p&gt;

&lt;div&gt;&amp;nbsp;&lt;/div&gt;
&lt;p&gt;-R. Foreman&lt;/p&gt;
&lt;div&gt;&amp;nbsp;&lt;/div&gt;</content><author><name></name></author><summary type="html">MyBook Transformation, External USB3 to Internal SATA3 January 10, 2017 External USB3 disk-drives have become popular in the last few years, primarily due to their low cost and high capacity. I speak from experience, as I own three of these, a 3TeraByte drive purchased about 5 years ago, another 4TeraByte drive purchased 3 years ago, and finally an 8TeraByte drive acquired within the last month. These work about as advertised, however there were two issues which over time began to become quite annoying. Eventually this situation led to rash measures, the destruction of the external protective casing of the Western Digital Mybook to expose the SATA3 internal disk-drive inside. The first annoyance was a rather lengthy delay (10 seconds or more) to access the drive after some period of inactivity. Even with slow internal disk-drives you don't have to wait more than 1/2 second to get a response, ever, under any circumstance. I've never actually learned the reason for this. The problem could my motherboard/CPU pair and the fact that they don't have any native USB3 support, and PCIe lanes are needed to create USB3 ports. It could also be the USB3-SATA3 circuit inside the MyBook has some kind of protection mechanism which prevents the drive from spinning up too fast, or perhaps they're kept at 0 RPM when not in use and require extra time to spin up to speed. I don't know what the issue was, and I never spent any time researching other peoples' experiences. However, I don't enjoy accessing a disk-drive and sitting for part of a minute watching nothing, because it makes me think something is very wrong with my computer hardware. The second troubling circumstance was that adding so many USB3 connections began to cause operational problems with my motherboard. After I had added a couple PCIe expansion cards which created a total of 8 USB3 ports, other parts of the motherboard began to experience failures. For example sound stopped working, the USB3 headers stopped working, and the boot process began failing in random ways. After removing the USB3 expansion cards, the failures disappeared. In fact after going through the process I describe below, I can happily say that the computer boot speed has increased by a factor of 10 or more, and all the USB3 motherboard headers are now fully functional. I can only surmise that I had run into a PCIe lane limit, a limitation of the chipset and CPU being used. The MyBook Dissassembly For the afore-mentioned reasons, I began to look at ways of eliminating my external USB3 devices (at least the powered ones, such as mass storage devices). A modest amount of research revealed that other people had deconstructed their MyBook cases and found an internal SATA3 drive. I got a wild hair one day and decided to just go ahead and do this, using my most recent purchase, the 8TeraByte drive. Be aware that trying this would probably void any warranty you might have on these external drives. Before beginning, I disconnected all cables (power and data) from the MyBook device, and used protective eyewear in case plastic pieces came flying up at my face. I began by prying at the fan vents along the edges, ever so gently so as not to damage the contents of the case. Eventually I simply broke the venting slats and tore them away, on both sides of the case. To do this I used a couple screw-drivers as prybars, and some pliers to tear away the plastic. After that I learned there was an internal plastic sleeve that was moving freely, and I slid this out and away from the case. Below I've posted photos at various stages of this process, and I know these aren't the most exciting pictures, but they may help someone going through this procedure at some point. After pulling the drive free from the case, I found there was rubber bumper material and retaining screws which could be removed. I also found that the USB3-SATA3 converter circuit board was held in place by a single screw, and once removed the drive itself was a simple 3.5 inch SATA platter-based disk-drive. WDMyBook 8Tb Image1 WDMyBook 8Tb Image2 WDMyBook 8Tb Image3 WDMyBook 8Tb Image4 WDMyBook 8Tb Image5 WDMyBook 8Tb Image6 WDMyBook 8Tb Image7 WDMyBook 8Tb Image8 WDMyBook 8Tb Image9 WDMyBook 8Tb Image10 After cleaning some dust off the SATA3 drive, I installed it internally in my desktop computer, and it worked flawlessly. What is more the long delay when accessing the disk was no longer there. I subsequently learned from handling this disk that when plugged into power, the platters spin continuously. It's an interesting effect actually, because when you handle a powered disk like this, it has the motion of a gyroscope (which is what it is, with an internal part that is spinning at high speed). I was thrilled by these events, and decided to look into ways of converting all my external MyBook USB3 disks into internal SATA3 disks. SATA3 Drive Enclosure This journey next led me to read up on disk drive enclosures. Many of them use USB3 for connecting the computer to the (external) enclosure, and this didn't interest me. What did catch my eye were references to a 'port multiplier' circuit using an eSATA connection between computer and external drive enclosure. I had no experience at all with drive enclosures, but this piqued my curiosity because it sounded exactly like what I wanted, more SATA3 connections without using additional PCIe lanes. I found a likely drive enclosure on NewEgg, the Sans Digital TR4M6GNC , and because it was so inexpensive ($85) I just took the chance and bought it. My desktop machine has a couple 6Gbs eSATA connectors which come directly off the motherboard as headers. When the Sans Digital enclosure arrived, it didn't work. It powered up correctly, and drives that I put inside it powered up, but there was nothing I could do to make the drive become recognized on my computer (and I tried many things, including software driver updates). I entertained the possibility that my eSATA headers were malfuntioning, as several other things were not working correctly on this computer, so I saw a very inexpensive (port multiplier) eSATA expansion card and bought it. When the card arrived, I tried it in my primary desktop, as well as the secondary computer I built recently, but nothing worked. After reading other buyer comments on Amazon concerning this particular enclosure, I concluded it was probably defective, and that it had a high incidence of failure (due to something called an eSATA repeater). I returned the Sans Digital product for a refund (but kept the eSATA expansion card to use with my secondary computer), and took a chance with another enclosure which had good customer reviews on Amazon, the Mediasonic Probox HF2-SU3S2. This drive enclosure did work correctly, right out of the box, with my desktop 6Gbs eSATA connectors as well as the expansion card, and it worked correctly both in my Windows7 machine and my secondary Linux box. I was of course thrilled by this, so I picked up a slightly longer 6ft eSATA cable from Amazon (the drive enclosure comes with a 3ft eSATA cable) , and began the process of converting my other MyBook drives from USB3 to SATA3. One benefit of using the Mediasonic enclosure is that the maximum size drive recognized is 8Tb, versus 6Tb for the Sans Digital enclosure, so Mediasonic offers a slightly larger capacity. When using the Mediasonic Probox enclosure, you have to read the instructions, because there are 3 buttons and several modes of operation. Once I had set the interface to eSATA, and the Sync light to orange, the enclosure worked without issue (and I keep the fan setting on high at all times). There are customer comments on Amazon which describe these controls in great detail. Windows7 doesn't always recognize hot-swapped SATA3 drives (you may need to reboot), but that seems to be a Microsoft issue, because Linux recognizes the drives the second they are connected. In every respect the drives behave identically in the external drive enclosure and port multiplier circuitry as they would when connected inside a computer case (with internal SATA3 connections). The only other thing worth noting here is that the Western Digital USB3 (external) drives provide some kind of control processing which allows drives larger than 2Tb to be fully utilized even though it was not initialized using GPT. The geeks among us know that Microsoft windows cannot see disk-drive space beyond 2Tb unless it is initialized using GUID Partition Table (GPT). Two of my three drives were not initialized using GPT, and I would have lost my data if I had not tranferred the drives over empty. When adding those two drives as SATA3, they both had to be reinitialized with GPT, so any data on them would have been lost. Also just an FYI, when initializing a drive as GPT, a 120Mb partition is created (called the Microsoft Reserved Partition), and this can be safely deleted if the drive won't be used as a boot disk. Disassembling My Remaining MyBook USB3 Drives I don't want to get too long-winded with this blog-post, so I'll just provide the photos I took, and say that each of the Western Digital MyBooks was slightly different. However the approach to disassembling them was basically the same - get a screwdriver under the ventilation slats and pry, then get a second screwdriver in there to pry and lift, and use plyers to pull the ventilation slats up and away from the enclosure. Be careful not to jam the screwdrivers down into the enclosure or you might damage the disk-drive, and definitely put goggles on in case something flies up into your face. 3Tb WD MyBook Photos WDMyBook 3Tb Image1 WDMyBook 3Tb Image2 WDMyBook 3Tb Image3 WDMyBook 3Tb Image4 WDMyBook 3Tb Image5 WDMyBook 3Tb Image6 WDMyBook 3Tb Image7 WDMyBook 3Tb Image8 WDMyBook 3Tb Image9 4Tb WD MyBook Photos WDMyBook 4Tb Image1 WDMyBook 4Tb Image2 WDMyBook 4Tb Image3 WDMyBook 4Tb Image4 WDMyBook 4Tb Image5 WDMyBook 4Tb Image6 Mediasonic Probox Photos Mediasonic Probox Image1 Mediasonic Probox Image2 Mediasonic Probox Image3 Mediasonic Probox Image4 Mediasonic Probox Image5 Mediasonic Probox Image6 Mediasonic Probox Image7 Mediasonic Probox Image8 Mediasonic Probox Image9 &amp;nbsp; -R. Foreman &amp;nbsp;</summary></entry><entry><title type="html">Monitor WAN Traffic with OpenWRT</title><link href="/posts/2017-1-2-wanmonitor" rel="alternate" type="text/html" title="Monitor WAN Traffic with OpenWRT" /><published>2017-01-02T00:00:00-07:00</published><updated>2017-01-02T00:00:00-07:00</updated><id>/posts/wanmonitor</id><content type="html" xml:base="/posts/2017-1-2-wanmonitor">&lt;h2&gt;Watching my WAN with OpenWRT&lt;/h2&gt;
&lt;h5&gt;January 2, 2017&lt;/h5&gt;
&lt;p class=&quot;lead&quot;&gt;Since I started working with &lt;a href=&quot;https://openwrt.org/&quot; target=&quot;_blank&quot;&gt;OpenWRT&lt;/a&gt; a few years ago, one thing I've always been curious about is seeing what kind of &lt;u&gt;uninvited traffic&lt;/u&gt; I am getting on the internet (WAN, or Wide Area Network) side of my router. The WAN side of a router is like your front-door, and I think it's a natural thing to wonder who is there fiddling with the lock. Sadly most people don't have the technical knowledge to even set this kind of thing up, let alone decipher the traffic. I am slowly getting to the point where I can do this, and I'll lay out a few approaches to setting up this kind of traffic monitor.&lt;/p&gt;

&lt;p&gt;A common approach you find people talk about is to &lt;a href=&quot;http://www.ayomaonline.com/security/analyzing-network-traffic-with-openwrt/&quot; target=&quot;_blank&quot;&gt;alter your firewall so that packets are mirrored to another machine&lt;/a&gt;. While this works, I'm not a big fan of this method, primarily because the router firewall is so important to your local network. Nearly all the computers on my LAN &lt;b&gt;do not&lt;/b&gt; have their own firewall, so the router firewall is the only thing standing between each of them and some very ugly things on the internet. &lt;u&gt;Firewalls are complex&lt;/u&gt;, despite what the whiz-kid down the street tells you, and if you muck up your router firewall it can be difficult to diagnose and correct. Fortunately there are other ways to obtain the WAN traffic.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/NetworkConfig.jpg&quot; alt=&quot;Local Area Network configuration, showing monitoring computer and internet cloud.&quot; /&gt;&lt;/p&gt;

&lt;h3&gt;TcpDump and Netcat&lt;/h3&gt;
&lt;p&gt;The idea here is somehow direct a copy of your WAN packets to a secondary machine. While modern consumer-grade routers are fairly robust, they are still nowhere near as powerful as a full-power desktop or laptop machine, so it's advisable to perform analysis and collection of data on one of these. &lt;u&gt;TcpDump&lt;/u&gt; is a great tool for dumping (to StdOut, or a console terminal) a copy of your packet stream on a particular interface. In the Linux world they call this a &quot;Tee&quot; because it makes a duplicate without interrupting the original stream. The other utility I use is called &lt;u&gt;Netcat&lt;/u&gt;, which does nothing except move data from one network endpoint to another. With these two tools, you can mirror data from your router's WAN interface to another computer.&lt;/p&gt;

&lt;p&gt;OpenWRT may have some built-in functionality for Netcat, but I went ahead and installed everything from package repositories. From an OpenWRT command-line, the following commands will install everything needed.&lt;/p&gt;
&lt;pre&gt;&amp;gt; opkg update
&amp;gt; opkg install netcat
&amp;gt; opkg install tcpdump&lt;/pre&gt;

&lt;p&gt;I can also look at the interfaces on my OpenWRT device and learn their IP addresses using the &lt;b&gt;ifconfig&lt;/b&gt; command.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/images/OpenWrtIPs.gif&quot; alt=&quot;Display of IP addresses for eth0 and br-lan. Gateway br-lan IP address is 192.168.1.1&quot; /&gt;&lt;/p&gt;

&lt;p&gt;From experience I know the br-lan interface (bridged-lan) is the set of connections allowing my wired and wireless devices to connect to my router. The other interface eth0 is the WAN, or the internet side of the router. If you run the following command at an &lt;b&gt;OpenWRT terminal&lt;/b&gt;, it will dump all your WAN traffic to the screen (until you hit ctrl-c). The command options listed there are basically to optimize for speed and efficiency, and to perform the raw packet dump to the StdOut terminal interface.&lt;/p&gt;
&lt;pre&gt;&amp;gt; tcpdump -s 0 -U -n -w - -i eth0&lt;/pre&gt;

&lt;p&gt;If my monitoring computer is on 192.168.1.204 and I wish to receive the data on port 61000, then I would run this command from OpenWRT, which pipes the output from tcpdump into the netcat utility which will then transfer the data over to the other machine.&lt;/p&gt;
&lt;pre&gt;&amp;gt; tcpdump -s 0 -U -n -w - -i eth0 | netcat 192.168.1.204 61000&lt;/pre&gt;

&lt;p&gt;On the &lt;b&gt;monitoring computer&lt;/b&gt;, you would receive the data with a command like this, which uses the netcat -l or listen option.&lt;/p&gt;
&lt;pre&gt;&amp;gt; netcat -l -p 61000&lt;/pre&gt;

&lt;p&gt;On the monitoring computer, to pipe the data into the wireshark program for analysis, the command becomes this.&lt;/p&gt;
&lt;pre&gt;&amp;gt; netcat -l -p 61000 | wireshark -k -i - &amp;amp;&lt;/pre&gt;

&lt;p&gt;The only real gotcha is that you have a TCP connection between OpenWRT and your monitoring computer, so the endpoint has to be &lt;u&gt;listening first&lt;/u&gt;, and then after that you can run the command to mirror the WAN data. This ordering might not be important if we sent the Netcat data using UDP, since it is connectionless, but we used TCP so the order is important (literally Netcat will stop running without a TCP endpoint to connect to). So the correct order to run these is as follows:
	&lt;ul style=&quot;list-style-type: none;&quot;&gt;
		&lt;li&gt;&lt;u&gt;Run on monitoring computer first&lt;/u&gt;: netcat -l -p 61000 | wireshark -k -i - &amp;amp;&lt;/li&gt;
		&lt;li&gt;&lt;u&gt;Run on OpenWRT router second&lt;/u&gt;: tcpdump -s 0 -U -n -w - -i eth0 not port 22 | netcat 192.168.1.204 61000&lt;/li&gt;
	&lt;/ul&gt;
&lt;/p&gt;
&lt;p&gt;Of course this example assumes you have both netcat and wireshark available on the monitoring computer, which would be the case for Kali Linux in a default setup. This approach works great, but it's a little clunky when you're pressed for time. Also be aware that Netcat does not provide any encryption security, in case that's an issue. Next I'll show an approach using a single-line command from the monitoring computer.&lt;/p&gt;

&lt;h3&gt;SSH, the Secure Shell&lt;/h3&gt;
&lt;p&gt;This approach uses the SSH utility to connect between the monitoring computer and OpenWRT router, and it has some advantages over the TcpDump/Netcat approach, but it does require a slight bit of setup. All the activity in this section takes place in the monitoring computer. Also assume that my gateway, the OpenWRT router, has IP address 192.168.1.1 when viewed from any device on my LAN. You should initially connect to OpenWRT using SSH to establish the RSA fingerprint. SSH will ask you for your OpenWRT password and whether you trust the connection.&lt;/p&gt;
&lt;pre&gt;&amp;gt; ssh root@192.168.1.1&lt;/pre&gt;

&lt;p&gt;SSH offers extreme security by the use of public-private encryption key-files, but this is slight overkill when you're on a home LAN. SSH by default does not allow you to use a password as a command-line parameter, but there is another utility named sshpass which does.&lt;/p&gt;
&lt;pre&gt;&amp;gt; apt-get install sshpass&lt;/pre&gt;

&lt;p&gt;Now to log into OpenWRT you would issue a command like this.&lt;/p&gt;
&lt;pre&gt;&amp;gt; sshpass -p your_password ssh root@192.168.1.1&lt;/pre&gt;

&lt;p&gt;That however is a bad idea, because your plaintext password will show up not only in your bash history but also appears to anyone else on the computer who runs the ps command. The way to hide your password is to first copy your password to a file in a secure location (such as your profile directory). Here is the sequence of commands, including the new improved OpenWRT login command.&lt;/p&gt;
&lt;pre&gt;&amp;gt; echo your_password &amp;gt; ~/.openwrtpass &amp;amp; history -r
&amp;gt; sshpass -f ~/.openwrtpass ssh root@192.168.1.1&lt;/pre&gt;

&lt;p&gt;SSH is a very old and well known service which runs (by default) on port 22. OpenWRT has a particular SSH implementation called DropBear, which runs by default when you flash your router, and which only listens for connections from the LAN side, so DropBear is what we're connecting to when we run these SSH commands from our monitoring computer. SSH also has some very convenient functionality in that you can run any command you want on the remote host once the shell is established. Here is an example.&lt;/p&gt;
&lt;pre&gt;&amp;gt; sshpass -f ~/.openwrtpass ssh root@192.168.1.1 &quot;tcpdump -s 0 -U -n -w - -i eth0&quot;&lt;/pre&gt;

&lt;p&gt;When the above command is run from the monitoring computer, the tcpdump sub-command is executed on OpenWRT once the shell is established. If you ran the above command from the monitoring computer you would see the raw WAN packets output to your terminal (until you typed ctrl-c). Finally, you can pipe those raw WAN packets into wireshark for real-time analysis.&lt;/p&gt;
&lt;pre&gt;&amp;gt; sshpass -f ~/.openwrtpass ssh root@192.168.1.1 &quot;tcpdump -s 0 -U -n -w - -i eth0&quot; | wireshark -k -i - &amp;amp;&lt;/pre&gt;

&lt;p&gt;This is the kind of one-line functionality that could easily be added as a shell alias, or put into a .desktop shortcut file, or any other kind of shell launch utility you might be using. This also has the advantage of being a fully encrypted connection between the monitor and OpenWRT. For some good video instruction on using SSH here are several Hak5 sessions which I bookmarked. The first two cover much of the basic-intermediate stuff, and the last two are a little more advanced.
	&lt;ul style=&quot;list-style-type: none;&quot;&gt;
		&lt;li&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=g_Row8zEJZc#t=01m50s&quot; target=&quot;_blank&quot;&gt;SSH Forwarding: Local vs Remote with examples&lt;/a&gt;&lt;/li&gt;
		&lt;li&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=nqedV1EdO8Q#t=00m12s&quot; target=&quot;_blank&quot;&gt;Maintaining Persistent SSH tunnels in Linux&lt;/a&gt;&lt;/li&gt;
		&lt;li&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=J798iStWLOM#t=04m55s&quot; target=&quot;_blank&quot;&gt;Explaining NAT Traversal with SSH proxies&lt;/a&gt;&lt;/li&gt;
		&lt;li&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=i8rpxtNL24w#t=00m14s&quot; target=&quot;_blank&quot;&gt;Setting up persistent reverse shells through relay proxies&lt;/a&gt;&lt;/li&gt;
	&lt;/ul&gt;
&lt;/p&gt;

&lt;div&gt;&amp;nbsp;&lt;/div&gt;
&lt;p&gt;-R. Foreman&lt;/p&gt;
&lt;div&gt;&amp;nbsp;&lt;/div&gt;</content><author><name></name></author><summary type="html">Watching my WAN with OpenWRT January 2, 2017 Since I started working with OpenWRT a few years ago, one thing I've always been curious about is seeing what kind of uninvited traffic I am getting on the internet (WAN, or Wide Area Network) side of my router. The WAN side of a router is like your front-door, and I think it's a natural thing to wonder who is there fiddling with the lock. Sadly most people don't have the technical knowledge to even set this kind of thing up, let alone decipher the traffic. I am slowly getting to the point where I can do this, and I'll lay out a few approaches to setting up this kind of traffic monitor. A common approach you find people talk about is to alter your firewall so that packets are mirrored to another machine. While this works, I'm not a big fan of this method, primarily because the router firewall is so important to your local network. Nearly all the computers on my LAN do not have their own firewall, so the router firewall is the only thing standing between each of them and some very ugly things on the internet. Firewalls are complex, despite what the whiz-kid down the street tells you, and if you muck up your router firewall it can be difficult to diagnose and correct. Fortunately there are other ways to obtain the WAN traffic. TcpDump and Netcat The idea here is somehow direct a copy of your WAN packets to a secondary machine. While modern consumer-grade routers are fairly robust, they are still nowhere near as powerful as a full-power desktop or laptop machine, so it's advisable to perform analysis and collection of data on one of these. TcpDump is a great tool for dumping (to StdOut, or a console terminal) a copy of your packet stream on a particular interface. In the Linux world they call this a &quot;Tee&quot; because it makes a duplicate without interrupting the original stream. The other utility I use is called Netcat, which does nothing except move data from one network endpoint to another. With these two tools, you can mirror data from your router's WAN interface to another computer. OpenWRT may have some built-in functionality for Netcat, but I went ahead and installed everything from package repositories. From an OpenWRT command-line, the following commands will install everything needed. &amp;gt; opkg update &amp;gt; opkg install netcat &amp;gt; opkg install tcpdump I can also look at the interfaces on my OpenWRT device and learn their IP addresses using the ifconfig command. From experience I know the br-lan interface (bridged-lan) is the set of connections allowing my wired and wireless devices to connect to my router. The other interface eth0 is the WAN, or the internet side of the router. If you run the following command at an OpenWRT terminal, it will dump all your WAN traffic to the screen (until you hit ctrl-c). The command options listed there are basically to optimize for speed and efficiency, and to perform the raw packet dump to the StdOut terminal interface. &amp;gt; tcpdump -s 0 -U -n -w - -i eth0 If my monitoring computer is on 192.168.1.204 and I wish to receive the data on port 61000, then I would run this command from OpenWRT, which pipes the output from tcpdump into the netcat utility which will then transfer the data over to the other machine. &amp;gt; tcpdump -s 0 -U -n -w - -i eth0 | netcat 192.168.1.204 61000 On the monitoring computer, you would receive the data with a command like this, which uses the netcat -l or listen option. &amp;gt; netcat -l -p 61000 On the monitoring computer, to pipe the data into the wireshark program for analysis, the command becomes this. &amp;gt; netcat -l -p 61000 | wireshark -k -i - &amp;amp; The only real gotcha is that you have a TCP connection between OpenWRT and your monitoring computer, so the endpoint has to be listening first, and then after that you can run the command to mirror the WAN data. This ordering might not be important if we sent the Netcat data using UDP, since it is connectionless, but we used TCP so the order is important (literally Netcat will stop running without a TCP endpoint to connect to). So the correct order to run these is as follows: Run on monitoring computer first: netcat -l -p 61000 | wireshark -k -i - &amp;amp; Run on OpenWRT router second: tcpdump -s 0 -U -n -w - -i eth0 not port 22 | netcat 192.168.1.204 61000 Of course this example assumes you have both netcat and wireshark available on the monitoring computer, which would be the case for Kali Linux in a default setup. This approach works great, but it's a little clunky when you're pressed for time. Also be aware that Netcat does not provide any encryption security, in case that's an issue. Next I'll show an approach using a single-line command from the monitoring computer. SSH, the Secure Shell This approach uses the SSH utility to connect between the monitoring computer and OpenWRT router, and it has some advantages over the TcpDump/Netcat approach, but it does require a slight bit of setup. All the activity in this section takes place in the monitoring computer. Also assume that my gateway, the OpenWRT router, has IP address 192.168.1.1 when viewed from any device on my LAN. You should initially connect to OpenWRT using SSH to establish the RSA fingerprint. SSH will ask you for your OpenWRT password and whether you trust the connection. &amp;gt; ssh root@192.168.1.1 SSH offers extreme security by the use of public-private encryption key-files, but this is slight overkill when you're on a home LAN. SSH by default does not allow you to use a password as a command-line parameter, but there is another utility named sshpass which does. &amp;gt; apt-get install sshpass Now to log into OpenWRT you would issue a command like this. &amp;gt; sshpass -p your_password ssh root@192.168.1.1 That however is a bad idea, because your plaintext password will show up not only in your bash history but also appears to anyone else on the computer who runs the ps command. The way to hide your password is to first copy your password to a file in a secure location (such as your profile directory). Here is the sequence of commands, including the new improved OpenWRT login command. &amp;gt; echo your_password &amp;gt; ~/.openwrtpass &amp;amp; history -r &amp;gt; sshpass -f ~/.openwrtpass ssh root@192.168.1.1 SSH is a very old and well known service which runs (by default) on port 22. OpenWRT has a particular SSH implementation called DropBear, which runs by default when you flash your router, and which only listens for connections from the LAN side, so DropBear is what we're connecting to when we run these SSH commands from our monitoring computer. SSH also has some very convenient functionality in that you can run any command you want on the remote host once the shell is established. Here is an example. &amp;gt; sshpass -f ~/.openwrtpass ssh root@192.168.1.1 &quot;tcpdump -s 0 -U -n -w - -i eth0&quot; When the above command is run from the monitoring computer, the tcpdump sub-command is executed on OpenWRT once the shell is established. If you ran the above command from the monitoring computer you would see the raw WAN packets output to your terminal (until you typed ctrl-c). Finally, you can pipe those raw WAN packets into wireshark for real-time analysis. &amp;gt; sshpass -f ~/.openwrtpass ssh root@192.168.1.1 &quot;tcpdump -s 0 -U -n -w - -i eth0&quot; | wireshark -k -i - &amp;amp; This is the kind of one-line functionality that could easily be added as a shell alias, or put into a .desktop shortcut file, or any other kind of shell launch utility you might be using. This also has the advantage of being a fully encrypted connection between the monitor and OpenWRT. For some good video instruction on using SSH here are several Hak5 sessions which I bookmarked. The first two cover much of the basic-intermediate stuff, and the last two are a little more advanced. SSH Forwarding: Local vs Remote with examples Maintaining Persistent SSH tunnels in Linux Explaining NAT Traversal with SSH proxies Setting up persistent reverse shells through relay proxies &amp;nbsp; -R. Foreman &amp;nbsp;</summary></entry><entry><title type="html">Selenium for Browser Leverage</title><link href="/posts/2016-12-27-seleniumbrowser" rel="alternate" type="text/html" title="Selenium for Browser Leverage" /><published>2016-12-27T00:00:00-07:00</published><updated>2016-12-27T00:00:00-07:00</updated><id>/posts/seleniumbrowser</id><content type="html" xml:base="/posts/2016-12-27-seleniumbrowser">&lt;h2&gt;Selenium for Browser Leverage&lt;/h2&gt;
&lt;p&gt;Republished from a &lt;a href=&quot;https://4draft.wordpress.com/2016/08/25/selenium-for-browser-leverage/&quot; target=&quot;_blank&quot;&gt;prior blogpost&lt;/a&gt; in August of this year&lt;/p&gt;
&lt;h5&gt;December 27, 2016&lt;/h5&gt;
&lt;p class=&quot;lead&quot;&gt;The technical luxuries just do not stop rolling in. I was out recently researching Chrome extensions, with the intention of performing browser automation, when I ran into a framework called &lt;a href=&quot;http://www.seleniumhq.org/docs/&quot; target=&quot;_blank&quot;&gt;Selenium&lt;/a&gt; which makes this kind of task &lt;u&gt;vastly&lt;/u&gt; easier to code. Chrome extensions do involve a fair amount of javascript coding. With Selenium however, not only was I able to pick the programming language from about half a dozen choices, but I was able to do just what I wanted done in under 20 lines of Python. In the case of Chrome, the server part of the browser driver is built by the Chrome development team, so I know the method calls will work as advertised. It gets even better though, since the &lt;a href=&quot;https://w3c.github.io/webdriver/webdriver-spec.html&quot; target=&quot;_blank&quot;&gt;Selenium 'wire protocol'&lt;/a&gt; is now a draft standard published by the W3C (WWW Consortium). I'm getting all kind of warm fuzzy feelings that this framework has heavy-weight industry support, and it won't go away anytime soon so my efforts won't be wasted.&lt;/p&gt;

&lt;p&gt;The official purpose for the Selenium framework is to perform QA testing on web applications and various browsers, on various operating platforms. I have a slightly different usage in mind, in that I am a fiend for creating browser launchers. These are short scripts which launch a browser, navigate to one or more pages, filling in textual form fields where needed, clicking buttons or otherwise submitting forms, and generally getting me logged into different web services which I use. There are a couple reasons I have for doing this. For one it is just butt-simple, especially when I am very busy with other things, to simply click a button and be logged in somewhere. The second reason is computer security, and unless you live under a rock you've noticed this is a hot topic right now (in fact for several years running). Your browser can be easily hooked using XSS (cross-site scripting), and then your cookies are exposed to an attacker. If you stay logged into online services then it is trivial for bad people to get your session cookies, and then they can just change your password, and you don't want to get pwned.&lt;/p&gt;

&lt;h3&gt;Setup and Usage&lt;/h3&gt;
&lt;p&gt;So the idea behind a browser launcher is to get logged in quickly, as needed, and then log out immediately when finished. Otherwise you spend half your time fumbling about navigating a web browser and looking for URLs and passwords. Actually there was a third reason I like to do this, and that is to stay abreast of webpage and browser technologies. Setting up these scripts involves examining the structure of a webpage and its elements. How easy is it to set up and use Selenium? From the documentation, here are the requirements.&lt;/p&gt;
&lt;ul style=&quot;list-style-position: inside;&quot;&gt;
	&lt;li&gt;Chrome browser, installed in the default location&lt;/li&gt;
	&lt;li&gt;Language bindings provided by the Selenium project&lt;/li&gt;
	&lt;li&gt;A browser driver executable provided by the Chromium project&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The first item on the list should be obvious. See &lt;a href=&quot;https://github.com/SeleniumHQ/selenium/wiki/ChromeDriver&quot; target=&quot;_blank&quot;&gt;the Selenium wiki&lt;/a&gt; for official documentation. The second item, in the case of Python, is obtained by installing the selenium package with the following command.&lt;/p&gt;
&lt;pre&gt;&amp;gt; pip install selenium&lt;/pre&gt;
&lt;p&gt;The third item on the list can be obtained from &lt;a href=&quot;https://sites.google.com/a/chromium.org/chromedriver/&quot; target=&quot;_blank&quot;&gt;the Chrome developers&lt;/a&gt;. Your mileage may vary, but I believe it is wise to use the 64-bit version of this executable if you are using 64-bit Python. That's all for the setup. For me the hard part was the gymnastics involved in launching the correct things, with the correct environment. I have two versions of Python installed on my (windows) computer, so for testing Python scripts from a command-line, I created the following shortcut.&lt;/p&gt;
&lt;pre&gt;C:\Windows\System32\cmd.exe /k &quot;set Path=%SystemRoot%\system32;%SystemRoot%;%SystemRoot%\System32\Wbem;C:\ProgramsDev1\Python_x64_2711;C:\ProgramsDev1\Python_x64_2711\Scripts; &amp;amp; E: &amp;amp; cd E:\PythonProjects\ChromeLaunchScripts&quot;&lt;/pre&gt;

&lt;p&gt;This just opens a DOS-box, sets the Path environment variable to the correct version of Python (in this case version 2.711), then changes my current working directory to E:\PythonProjects\ChromeLaunchScripts\ , which is where I store my launcher scripts. I also put the chromedriver.exe file in the same directory.&lt;/p&gt;
&lt;p&gt;Here is what a typical script looks like, to automate the Chrome browser in Python.&lt;/p&gt;
&lt;pre&gt;&lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;selenium&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; webdriver
&lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;selenium.webdriver.common.keys&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; Keys

options &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; webdriver&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;ChromeOptions()
options&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;add_argument(&lt;span class=&quot;s&quot;&gt;&amp;#39;--no-sandbox&amp;#39;&lt;/span&gt;)
options&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;add_argument(&lt;span class=&quot;s&quot;&gt;&amp;#39;--disable-gpu&amp;#39;&lt;/span&gt;)
options&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;add_argument(&lt;span class=&quot;s&quot;&gt;&amp;quot;--window-size=1762,1200&amp;quot;&lt;/span&gt;)
options&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;add_argument(&lt;span class=&quot;s&quot;&gt;&amp;quot;--window-position=102,0&amp;quot;&lt;/span&gt;)

driver &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; webdriver&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;Chrome(chrome_options&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;options)
driver&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;get(&lt;span class=&quot;s&quot;&gt;&amp;#39;https://wordpress.com/wp-login.php&amp;#39;&lt;/span&gt;);

logincss &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;#39;form#loginform input#user_login&amp;#39;&lt;/span&gt;
login &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; driver&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;find_element_by_css_selector(logincss)
login&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;send_keys(&lt;span class=&quot;s&quot;&gt;&amp;#39;4draft&amp;#39;&lt;/span&gt;)

pwdcss &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;#39;form#loginform input#user_pass&amp;#39;&lt;/span&gt;
pwd &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; driver&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;find_element_by_css_selector(pwdcss)
pwd&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;send_keys(&lt;span class=&quot;s&quot;&gt;&amp;#39;my password&amp;#39;&lt;/span&gt;)

formcss &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;#39;form#loginform input.button&amp;#39;&lt;/span&gt;
form &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; driver&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;find_element_by_css_selector(formcss)
form&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;submit()

driver&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;close()
&lt;/pre&gt;

&lt;p&gt;From the command environment, run the script by issuing the command&lt;/p&gt;
&lt;pre&gt;&amp;gt; Python scriptname.py&lt;/pre&gt;
&lt;p&gt;&lt;img src=&quot;/images/SeleniumImg0.jpg&quot; alt=&quot;Command box executing python test1.py&quot; /&gt;&lt;/p&gt;

&lt;p&gt;There isn't much in this basic script. They tell you to close the driver when you're finished with it, but the truth is that this sequence of steps goes so fast you may not even have a chance to see the browser opening. Because of that, and also because my intention is to have the browser remain open after the script finishes, I usually don't call driver.close() .&lt;/p&gt;

&lt;p&gt;Obviously there are other functions you can call to customize the script. In fact Selenium has a rich API for driving the browser navigation. After looking around the documentation, this is the best &lt;a href=&quot;http://seleniumhq.github.io/selenium/docs/api/javascript/module/selenium-webdriver/&quot; target=&quot;_blank&quot;&gt;API listing&lt;/a&gt; that I found. If you look closely you'll noticed the language used here is javascript, but all the method names, parameters, class heirarchies, and example usage are provided. You'll have to translate these to your own language of choice. You can click the 'View Source' link in the upper-right corner to view the actual source code on github. There is quite a lot of functionality there, and much of it that I will probably never use.&lt;/p&gt;

&lt;p&gt;I also looked into ways of setting up single-click launchers for these scripts, since I don't always like to work from a command-line. My goal was a single-click launch, without having a DOS-box appear, and which could be run as a short-cut from another location. On MSWindows, this could be done using &lt;u&gt;AutoIt&lt;/u&gt;. It could also be done using &lt;u&gt;PowerShell&lt;/u&gt;, however I always hear people complaining about executing PowerShell scripts directly from the shell; apparently this is just too much power. For simplicity I turned to a &lt;u&gt;Visual Basic&lt;/u&gt; script, such as this one.&lt;/p&gt;

&lt;pre&gt;&lt;span class=&quot;k&quot;&gt;Set&lt;/span&gt; ShellObj &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; CreateObject (&lt;span class=&quot;s&quot;&gt;&amp;quot;Wscript.Shell&amp;quot;&lt;/span&gt;)
&lt;span class=&quot;k&quot;&gt;Dim&lt;/span&gt; strArgs
strArgs &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;quot;setenv.bat scriptname.py&amp;quot;&lt;/span&gt;
ShellObj.Run strArgs, &lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;, &lt;span class=&quot;k&quot;&gt;true&lt;/span&gt;
&lt;/pre&gt;

&lt;p&gt;The setenv.bat file will generically set up the environment, much like I did in the Python command short-cut created earlier. Here are the contents of setenv.bat&lt;/p&gt;
&lt;pre&gt;set Path=%SystemRoot%\system32;%SystemRoot%;%SystemRoot%\System32\Wbem;C:\ProgramsDev1\Python_x64_2711;C:\ProgramsDev1\Python_x64_2711\Scripts;
E:
cd E:\PythonProjects\ChromeLaunchScripts
python %1&lt;/pre&gt;

&lt;p&gt;So what happens is the launcher.vbs script, when double-clicked from the Windows shell, will open an invisible DOS-box and execute setenv.bat , passing in scriptname.py as its only parameter; setenv.bat then creates the correct environment for running Python scripts, and then runs the Python script that was passed in as a parameter. I have all these files in the same directory by the way. Now I can create a short-cut to the .vbs launcher file and place it anywhere on my system. In fact I have a system toolbar on my desktop, and I can execute the .vbs files from a menu entry.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/images/SeleniumImg2.jpg&quot; alt=&quot;System toolbar for launching shortcuts.&quot; /&gt;&lt;/p&gt;

&lt;h3&gt;Linux&lt;/h3&gt;
&lt;p&gt;For Linux, the setup and usage is identical to what I just described for the MSWindows system. This was in fact one of my goals, to use both a browser (Chrome) and a script language (Python) which work consistently the same across multiple operating environments. Note that in Linux, Selenium had difficulty figuring out where the chromedriver was located, so I had to place it on the system path, whereas in Windows I could place chromedriver in the same directory where the Python script was launched from. The big difference in Linux is in how to setup shortcuts and launchers, since these are somewhat dependent on your Linux distribution. I plan on writing an article which gives details on setting up a top-panel launcher menu in Gnome3 as a Gnome Shell Extension.&lt;/p&gt;

&lt;p&gt;I said earlier that in my Python automation scripts I decided to not call the driver.close() function. This is my choice, but it does lead to another problem (see the following image).&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/images/SeleniumImg1.jpg&quot; alt=&quot;Windows processes list, showing multiple chromedriver.exe open in memory.&quot; /&gt;&lt;/p&gt;

&lt;p&gt;After numerous invocations of your launcher scripts, you will end up with numerous orphaned chromedriver executables in memory, since they were never closed properly. The Selenium people never provided the functionality to close the driver while leaving the browser running, since it was never viewed as necessary for browser-webapp QA testing. As a result I was left to my own devices, and I have created some boiler-plate Python code which I add to every automation script. This additional Python code, shown below, simply identifies the chromedriver in memory and kills it, and this executes after the automation code finishes.&lt;/p&gt;

&lt;pre&gt;&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;os&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;signal&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;ctypes&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;linuxkill&lt;/span&gt;(pstring):
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; line &lt;span class=&quot;k&quot;&gt;in&lt;/span&gt; os&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;popen(&lt;span class=&quot;s&quot;&gt;&amp;quot;ps ax | grep &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; pstring &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;quot; | grep -v grep&amp;quot;&lt;/span&gt;):
        fields &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; line&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;split()
        pid &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; fields[&lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;]
        os&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;kill(&lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;(pid), signal&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;SIGKILL)

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;winkill&lt;/span&gt;(pstring):
    &lt;span class=&quot;nb&quot;&gt;print&lt;/span&gt; pstring
    PyIds &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; [&lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;(line&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;split()[&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;]) &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; line &lt;span class=&quot;k&quot;&gt;in&lt;/span&gt; os&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;popen(&lt;span class=&quot;s&quot;&gt;&amp;#39;tasklist&amp;#39;&lt;/span&gt;)&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;readlines()[&lt;span class=&quot;m&quot;&gt;3&lt;/span&gt;:] &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; line&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;split()[&lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;] &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; pstring]
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; pid &lt;span class=&quot;k&quot;&gt;in&lt;/span&gt; PyIds:
        &lt;span class=&quot;c&quot;&gt;#print pid&lt;/span&gt;
        os&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;system(&lt;span class=&quot;s&quot;&gt;&amp;quot;taskkill /F /pid %i&amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; pid)

&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; os&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;name &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;#39;nt&amp;#39;&lt;/span&gt;:
    winkill(&lt;span class=&quot;s&quot;&gt;&amp;#39;chromedriver.exe&amp;#39;&lt;/span&gt;)
&lt;span class=&quot;k&quot;&gt;elif&lt;/span&gt; os&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;name &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;#39;posix&amp;#39;&lt;/span&gt;:
    linuxkill(&lt;span class=&quot;s&quot;&gt;&amp;#39;chromedriver&amp;#39;&lt;/span&gt;)
&lt;/pre&gt;

&lt;p&gt;The three import lines go at the very top of the automation script file, and the rest of the code can go at the very bottom of the file. I have never tested this on an Android or MacOS system, but I imagine they work very much like it does on Linux, since Android and MacOS are both built on a Linux kernel.&lt;/p&gt;

&lt;p&gt;In case anyone is curious about toying with Selenium, I did some preliminary work using Notepad++ , since it performs syntax-highlighting on Python files, and code-folding as well. Later I moved to using Eclipse+Pydev for the code-completion (like intellisense) and library integration. Finally, if you are learning Selenium in the Python language, here is a &lt;a href=&quot;http://selenium-python.readthedocs.io/index.html&quot; target=&quot;_blank&quot;&gt;great site&lt;/a&gt; to use for a reference.&lt;/p&gt;

&lt;div&gt;&amp;nbsp;&lt;/div&gt;
&lt;p&gt;-R. Foreman&lt;/p&gt;
&lt;div&gt;&amp;nbsp;&lt;/div&gt;</content><author><name></name></author><summary type="html">Selenium for Browser Leverage Republished from a prior blogpost in August of this year December 27, 2016 The technical luxuries just do not stop rolling in. I was out recently researching Chrome extensions, with the intention of performing browser automation, when I ran into a framework called Selenium which makes this kind of task vastly easier to code. Chrome extensions do involve a fair amount of javascript coding. With Selenium however, not only was I able to pick the programming language from about half a dozen choices, but I was able to do just what I wanted done in under 20 lines of Python. In the case of Chrome, the server part of the browser driver is built by the Chrome development team, so I know the method calls will work as advertised. It gets even better though, since the Selenium 'wire protocol' is now a draft standard published by the W3C (WWW Consortium). I'm getting all kind of warm fuzzy feelings that this framework has heavy-weight industry support, and it won't go away anytime soon so my efforts won't be wasted. The official purpose for the Selenium framework is to perform QA testing on web applications and various browsers, on various operating platforms. I have a slightly different usage in mind, in that I am a fiend for creating browser launchers. These are short scripts which launch a browser, navigate to one or more pages, filling in textual form fields where needed, clicking buttons or otherwise submitting forms, and generally getting me logged into different web services which I use. There are a couple reasons I have for doing this. For one it is just butt-simple, especially when I am very busy with other things, to simply click a button and be logged in somewhere. The second reason is computer security, and unless you live under a rock you've noticed this is a hot topic right now (in fact for several years running). Your browser can be easily hooked using XSS (cross-site scripting), and then your cookies are exposed to an attacker. If you stay logged into online services then it is trivial for bad people to get your session cookies, and then they can just change your password, and you don't want to get pwned. Setup and Usage So the idea behind a browser launcher is to get logged in quickly, as needed, and then log out immediately when finished. Otherwise you spend half your time fumbling about navigating a web browser and looking for URLs and passwords. Actually there was a third reason I like to do this, and that is to stay abreast of webpage and browser technologies. Setting up these scripts involves examining the structure of a webpage and its elements. How easy is it to set up and use Selenium? From the documentation, here are the requirements. Chrome browser, installed in the default location Language bindings provided by the Selenium project A browser driver executable provided by the Chromium project The first item on the list should be obvious. See the Selenium wiki for official documentation. The second item, in the case of Python, is obtained by installing the selenium package with the following command. &amp;gt; pip install selenium The third item on the list can be obtained from the Chrome developers. Your mileage may vary, but I believe it is wise to use the 64-bit version of this executable if you are using 64-bit Python. That's all for the setup. For me the hard part was the gymnastics involved in launching the correct things, with the correct environment. I have two versions of Python installed on my (windows) computer, so for testing Python scripts from a command-line, I created the following shortcut. C:\Windows\System32\cmd.exe /k &quot;set Path=%SystemRoot%\system32;%SystemRoot%;%SystemRoot%\System32\Wbem;C:\ProgramsDev1\Python_x64_2711;C:\ProgramsDev1\Python_x64_2711\Scripts; &amp;amp; E: &amp;amp; cd E:\PythonProjects\ChromeLaunchScripts&quot; This just opens a DOS-box, sets the Path environment variable to the correct version of Python (in this case version 2.711), then changes my current working directory to E:\PythonProjects\ChromeLaunchScripts\ , which is where I store my launcher scripts. I also put the chromedriver.exe file in the same directory. Here is what a typical script looks like, to automate the Chrome browser in Python. from selenium import webdriver from selenium.webdriver.common.keys import Keys options = webdriver.ChromeOptions() options.add_argument(&amp;#39;--no-sandbox&amp;#39;) options.add_argument(&amp;#39;--disable-gpu&amp;#39;) options.add_argument(&amp;quot;--window-size=1762,1200&amp;quot;) options.add_argument(&amp;quot;--window-position=102,0&amp;quot;) driver = webdriver.Chrome(chrome_options=options) driver.get(&amp;#39;https://wordpress.com/wp-login.php&amp;#39;); logincss = &amp;#39;form#loginform input#user_login&amp;#39; login = driver.find_element_by_css_selector(logincss) login.send_keys(&amp;#39;4draft&amp;#39;) pwdcss = &amp;#39;form#loginform input#user_pass&amp;#39; pwd = driver.find_element_by_css_selector(pwdcss) pwd.send_keys(&amp;#39;my password&amp;#39;) formcss = &amp;#39;form#loginform input.button&amp;#39; form = driver.find_element_by_css_selector(formcss) form.submit() driver.close() From the command environment, run the script by issuing the command &amp;gt; Python scriptname.py There isn't much in this basic script. They tell you to close the driver when you're finished with it, but the truth is that this sequence of steps goes so fast you may not even have a chance to see the browser opening. Because of that, and also because my intention is to have the browser remain open after the script finishes, I usually don't call driver.close() . Obviously there are other functions you can call to customize the script. In fact Selenium has a rich API for driving the browser navigation. After looking around the documentation, this is the best API listing that I found. If you look closely you'll noticed the language used here is javascript, but all the method names, parameters, class heirarchies, and example usage are provided. You'll have to translate these to your own language of choice. You can click the 'View Source' link in the upper-right corner to view the actual source code on github. There is quite a lot of functionality there, and much of it that I will probably never use. I also looked into ways of setting up single-click launchers for these scripts, since I don't always like to work from a command-line. My goal was a single-click launch, without having a DOS-box appear, and which could be run as a short-cut from another location. On MSWindows, this could be done using AutoIt. It could also be done using PowerShell, however I always hear people complaining about executing PowerShell scripts directly from the shell; apparently this is just too much power. For simplicity I turned to a Visual Basic script, such as this one. Set ShellObj = CreateObject (&amp;quot;Wscript.Shell&amp;quot;) Dim strArgs strArgs = &amp;quot;setenv.bat scriptname.py&amp;quot; ShellObj.Run strArgs, 0, true The setenv.bat file will generically set up the environment, much like I did in the Python command short-cut created earlier. Here are the contents of setenv.bat set Path=%SystemRoot%\system32;%SystemRoot%;%SystemRoot%\System32\Wbem;C:\ProgramsDev1\Python_x64_2711;C:\ProgramsDev1\Python_x64_2711\Scripts; E: cd E:\PythonProjects\ChromeLaunchScripts python %1 So what happens is the launcher.vbs script, when double-clicked from the Windows shell, will open an invisible DOS-box and execute setenv.bat , passing in scriptname.py as its only parameter; setenv.bat then creates the correct environment for running Python scripts, and then runs the Python script that was passed in as a parameter. I have all these files in the same directory by the way. Now I can create a short-cut to the .vbs launcher file and place it anywhere on my system. In fact I have a system toolbar on my desktop, and I can execute the .vbs files from a menu entry. Linux For Linux, the setup and usage is identical to what I just described for the MSWindows system. This was in fact one of my goals, to use both a browser (Chrome) and a script language (Python) which work consistently the same across multiple operating environments. Note that in Linux, Selenium had difficulty figuring out where the chromedriver was located, so I had to place it on the system path, whereas in Windows I could place chromedriver in the same directory where the Python script was launched from. The big difference in Linux is in how to setup shortcuts and launchers, since these are somewhat dependent on your Linux distribution. I plan on writing an article which gives details on setting up a top-panel launcher menu in Gnome3 as a Gnome Shell Extension. I said earlier that in my Python automation scripts I decided to not call the driver.close() function. This is my choice, but it does lead to another problem (see the following image). After numerous invocations of your launcher scripts, you will end up with numerous orphaned chromedriver executables in memory, since they were never closed properly. The Selenium people never provided the functionality to close the driver while leaving the browser running, since it was never viewed as necessary for browser-webapp QA testing. As a result I was left to my own devices, and I have created some boiler-plate Python code which I add to every automation script. This additional Python code, shown below, simply identifies the chromedriver in memory and kills it, and this executes after the automation code finishes. import os import signal import ctypes def linuxkill(pstring): for line in os.popen(&amp;quot;ps ax | grep &amp;quot; + pstring + &amp;quot; | grep -v grep&amp;quot;): fields = line.split() pid = fields[0] os.kill(int(pid), signal.SIGKILL) def winkill(pstring): print pstring PyIds = [int(line.split()[1]) for line in os.popen(&amp;#39;tasklist&amp;#39;).readlines()[3:] if line.split()[0] == pstring] for pid in PyIds: #print pid os.system(&amp;quot;taskkill /F /pid %i&amp;quot; % pid) if os.name == &amp;#39;nt&amp;#39;: winkill(&amp;#39;chromedriver.exe&amp;#39;) elif os.name == &amp;#39;posix&amp;#39;: linuxkill(&amp;#39;chromedriver&amp;#39;) The three import lines go at the very top of the automation script file, and the rest of the code can go at the very bottom of the file. I have never tested this on an Android or MacOS system, but I imagine they work very much like it does on Linux, since Android and MacOS are both built on a Linux kernel. In case anyone is curious about toying with Selenium, I did some preliminary work using Notepad++ , since it performs syntax-highlighting on Python files, and code-folding as well. Later I moved to using Eclipse+Pydev for the code-completion (like intellisense) and library integration. Finally, if you are learning Selenium in the Python language, here is a great site to use for a reference. &amp;nbsp; -R. Foreman &amp;nbsp;</summary></entry></feed>